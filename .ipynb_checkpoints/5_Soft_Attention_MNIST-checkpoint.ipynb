{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Soft Attention MNIST\n",
    "\n",
    "This is jupyter notebook for `Soft Attention` from paper [Show, Attend and Tell](https://arxiv.org/abs/1502.03044). \n",
    "This Algorithm will be tested by `MNIST dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "img_size = 28\n",
    "img_flat_size = img_size * img_size\n",
    "\n",
    "# labels: 0 - 9\n",
    "num_label = 10\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "# Parameters for optimizer\n",
    "learning_rate = 5e-4\n",
    "epsilon = 1e-8\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Parameter for LSTM\n",
    "lstm_size = 512\n",
    "step_size = img_size\n",
    "flatten_size = img_size\n",
    "\n",
    "validation_ratio = 0.1\n",
    "gpu_fraction = 0.3\n",
    "\n",
    "# parameter for attention\n",
    "img_fraction_size = 4\n",
    "stride = 2\n",
    "\n",
    "len_horizontal = int((img_size - img_fraction_size) / stride + 1)\n",
    "len_vertical   = int((img_size - img_fraction_size) / stride + 1)\n",
    "len_stack = len_horizontal * len_vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4bfeda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting example image\n",
    "img = mnist.train.images[0]\n",
    "img_resize = img.reshape((img_size, img_size))\n",
    "plt.imshow(img_resize, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Sample Image Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bd2be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(len_vertical, len_horizontal)\n",
    "\n",
    "img_fraction = np.zeros([img_fraction_size, img_fraction_size, len_stack])\n",
    "index_fraction = 0\n",
    "for i in range(len_vertical):\n",
    "    start_v = stride * i\n",
    "    for j in range(len_horizontal):\n",
    "        start_h = stride * j\n",
    "                \n",
    "        img_fraction[:,:,index_fraction] = img_resize[start_v : start_v + img_fraction_size, \n",
    "                                                      start_h : start_h + img_fraction_size]\n",
    "        \n",
    "        ax[i, j].imshow(img_fraction[:,:,index_fraction], cmap = 'gray')\n",
    "        ax[i, j].axis('off')\n",
    "        \n",
    "        index_fraction += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)\n",
    "\n",
    "# Convolution and pooling\n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# LSTM function\n",
    "Wf = tf.Variable(xavier_initializer([flatten_size + lstm_size, lstm_size]))\n",
    "bf = tf.Variable(xavier_initializer([lstm_size]))\n",
    "Wi = tf.Variable(xavier_initializer([flatten_size + lstm_size, lstm_size]))\n",
    "bi = tf.Variable(xavier_initializer([lstm_size]))\n",
    "Wc = tf.Variable(xavier_initializer([flatten_size + lstm_size, lstm_size]))\n",
    "bc = tf.Variable(xavier_initializer([lstm_size]))\n",
    "Wo = tf.Variable(xavier_initializer([flatten_size + lstm_size, lstm_size]))\n",
    "bo = tf.Variable(xavier_initializer([lstm_size])) \n",
    "\n",
    "def LSTM_cell(C_prev, h_prev, x_lstm):\n",
    "    input_concat = tf.concat([x_lstm, h_prev], 1)\n",
    "    f = tf.sigmoid(tf.matmul(input_concat, Wf[0]) + bf)\n",
    "    i = tf.sigmoid(tf.matmul(input_concat, Wi[0]) + bi)\n",
    "    c = tf.tanh(tf.matmul(input_concat, Wc[0]) + bc)\n",
    "    o = tf.sigmoid(tf.matmul(input_concat, Wo[0]) + bo)\n",
    "    \n",
    "    C_t = tf.multiply(f, C_prev) + tf.multiply(i, c)\n",
    "    h_t = tf.multiply(o, tf.tanh(C_t))\n",
    "    \n",
    "    return C_t, h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Attention Network!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "# Input \n",
    "x_image  = tf.placeholder(tf.float32, shape = [None, img_fraction_size, img_fraction_size, len_stack])\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, num_label])\n",
    "\n",
    "x_unstack = tf.unstack(x_image, axis = 3)\n",
    "\n",
    "# Convolution variables\n",
    "w_conv1 = weight_variable([2, 2, 1, 64])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "conv_list = []\n",
    "for i in range(len_stack):\n",
    "    x_conv = tf.reshape(x_unstack[i], (-1, img_fraction_size, img_fraction_size, 1))\n",
    "    conv_result = tf.nn.relu(conv2d(x_conv, w_conv1, 2) + b_conv1)\n",
    "    conv_result_flat = tf.contrib.layers.flatten(conv_result)\n",
    "    conv_list.append(conv_result_flat)\n",
    "\n",
    "len_conv = int(conv_list[0].get_shape()[1])\n",
    "\n",
    "Wa = tf.Variable(xavier_initializer([len_conv, 1]))\n",
    "\n",
    "m_list = []\n",
    "for i in range(len(x_unstack)):\n",
    "    m = tf.tanh(tf.matmul(conv_list[i], Wa))\n",
    "    m_list.append(m)\n",
    "\n",
    "m_stack = tf.stack(m_list, axis = 2)\n",
    "m_stack_reshape = tf.reshape(m_stack, (-1, len_stack))\n",
    "\n",
    "# Get alpha \n",
    "alpha = tf.nn.softmax(m_stack_reshape)\n",
    "\n",
    "z_list = []\n",
    "\n",
    "for i in range(len_stack):\n",
    "    z_list.append(tf.multiply(conv_list[i], tf.slice(alpha, (0, i), (-1, 1))))\n",
    "\n",
    "z_stack = tf.stack(z_list, axis = 2)\n",
    "z = tf.reduce_sum(z_stack, axis = 2)\n",
    "\n",
    "Wz = tf.Variable(xavier_initializer([len_conv, 10]))\n",
    "bz = tf.Variable(xavier_initializer([10]))\n",
    "\n",
    "output = tf.nn.softmax(tf.matmul(z, Wz)+bz)\n",
    "\n",
    "# input_flat = tf.reshape(x_image,[-1, step_size , flatten_size])\n",
    "# input_unstack = tf.unstack(input_flat, axis = 1)\n",
    "\n",
    "# rnn_batch_size = tf.shape(input_flat)[0]\n",
    "# rnn_step_size = tf.shape(input_flat)[1]\n",
    "\n",
    "# # Initial lstm cell state and output \n",
    "# rnn_state = tf.zeros([rnn_batch_size, lstm_size], tf.float32)\n",
    "# rnn_out = tf.zeros([rnn_batch_size, lstm_size], tf.float32)\n",
    "\n",
    "# #################################### Attention!!! ####################################\n",
    "# for i in range(len(input_unstack)):\n",
    "#     rnn_state, rnn_out = LSTM_cell(rnn_state, rnn_out, input_unstack[i])\n",
    "\n",
    "# ######################################################################################\n",
    "# rnn_out = tf.reshape(rnn_out ,shape = [-1, lstm_size])\n",
    "\n",
    "# # Densely connect layer variables \n",
    "# w_fc1 = weight_variable([lstm_size, 256])\n",
    "# b_fc1 = bias_variable([256])\n",
    "\n",
    "# w_fc2 = weight_variable([256, num_label])\n",
    "# b_fc2 = bias_variable([num_label])\n",
    "\n",
    "# # Fully Connected Layer\n",
    "# h_fc1 = tf.nn.relu(tf.matmul(rnn_out, w_fc1)+b_fc1)\n",
    "# output = tf.matmul(h_fc1, w_fc2)+b_fc2\n",
    "\n",
    "# Training \n",
    "Loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y_target, logits = output)\n",
    "Cost = tf.reduce_mean(Loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon = epsilon).minimize(Cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_target,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (60000, 784)\n",
      "Testing set: (9000, 784)\n",
      "Validation set: (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for train, test, validation\n",
    "\n",
    "test_len = mnist.test.images.shape[0]\n",
    "validation_len = int(test_len * validation_ratio)\n",
    "\n",
    "train_x = mnist.train.images\n",
    "test_x = mnist.test.images[validation_len : test_len, :]\n",
    "validation_x = mnist.test.images[ : validation_len, :]\n",
    "\n",
    "train_y = mnist.train.labels\n",
    "test_y = mnist.test.labels[validation_len : test_len]\n",
    "validation_y = mnist.test.labels[ : validation_len]\n",
    "\n",
    "print(\"Training set: \" + str(train_x.shape))\n",
    "print(\"Testing set: \" + str(test_x.shape))\n",
    "print(\"Validation set: \" + str(validation_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "data = np.insert(train_x, img_flat_size, train_y, axis = 1)\n",
    "len_data = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 0/60000 / Cost: 0.73434 / Training Accuracy: 0.105469\n",
      "Epoch: 1 / Batch: 512/60000 / Cost: 0.734473 / Training Accuracy: 0.101563\n",
      "Epoch: 1 / Batch: 1024/60000 / Cost: 0.734384 / Training Accuracy: 0.103516\n",
      "Epoch: 1 / Batch: 1536/60000 / Cost: 0.734361 / Training Accuracy: 0.115234\n",
      "Epoch: 1 / Batch: 2048/60000 / Cost: 0.734449 / Training Accuracy: 0.111328\n",
      "Epoch: 1 / Batch: 2560/60000 / Cost: 0.734583 / Training Accuracy: 0.0839844\n",
      "Epoch: 1 / Batch: 3072/60000 / Cost: 0.734399 / Training Accuracy: 0.125\n",
      "Epoch: 1 / Batch: 3584/60000 / Cost: 0.734409 / Training Accuracy: 0.0976563\n",
      "Epoch: 1 / Batch: 4096/60000 / Cost: 0.73449 / Training Accuracy: 0.111328\n",
      "Epoch: 1 / Batch: 4608/60000 / Cost: 0.734348 / Training Accuracy: 0.111328\n",
      "Epoch: 1 / Batch: 5120/60000 / Cost: 0.734442 / Training Accuracy: 0.107422\n",
      "Epoch: 1 / Batch: 5632/60000 / Cost: 0.734401 / Training Accuracy: 0.0898438\n",
      "Epoch: 1 / Batch: 6144/60000 / Cost: 0.734346 / Training Accuracy: 0.0859375\n",
      "Epoch: 1 / Batch: 6656/60000 / Cost: 0.734469 / Training Accuracy: 0.103516\n",
      "Epoch: 1 / Batch: 7168/60000 / Cost: 0.73426 / Training Accuracy: 0.109375\n",
      "Epoch: 1 / Batch: 7680/60000 / Cost: 0.734427 / Training Accuracy: 0.0917969\n",
      "Epoch: 1 / Batch: 8192/60000 / Cost: 0.734425 / Training Accuracy: 0.103516\n",
      "Epoch: 1 / Batch: 8704/60000 / Cost: 0.734341 / Training Accuracy: 0.101563\n",
      "Epoch: 1 / Batch: 9216/60000 / Cost: 0.734191 / Training Accuracy: 0.107422\n",
      "Epoch: 1 / Batch: 9728/60000 / Cost: 0.73448 / Training Accuracy: 0.0917969\n",
      "Epoch: 1 / Batch: 10240/60000 / Cost: 0.734486 / Training Accuracy: 0.0898438\n",
      "Epoch: 1 / Batch: 10752/60000 / Cost: 0.734474 / Training Accuracy: 0.103516\n",
      "Epoch: 1 / Batch: 11264/60000 / Cost: 0.734426 / Training Accuracy: 0.0976563\n",
      "Epoch: 1 / Batch: 11776/60000 / Cost: 0.734578 / Training Accuracy: 0.0644531\n",
      "Epoch: 1 / Batch: 12288/60000 / Cost: 0.734522 / Training Accuracy: 0.0683594\n",
      "Epoch: 1 / Batch: 12800/60000 / Cost: 0.734438 / Training Accuracy: 0.0996094\n",
      "Epoch: 1 / Batch: 13312/60000 / Cost: 0.734351 / Training Accuracy: 0.09375\n",
      "Epoch: 1 / Batch: 13824/60000 / Cost: 0.734318 / Training Accuracy: 0.0976563\n",
      "Epoch: 1 / Batch: 14336/60000 / Cost: 0.734393 / Training Accuracy: 0.119141\n",
      "Epoch: 1 / Batch: 14848/60000 / Cost: 0.734361 / Training Accuracy: 0.078125\n",
      "Epoch: 1 / Batch: 15360/60000 / Cost: 0.734384 / Training Accuracy: 0.0917969\n",
      "Epoch: 1 / Batch: 15872/60000 / Cost: 0.734446 / Training Accuracy: 0.0859375\n",
      "Epoch: 1 / Batch: 16384/60000 / Cost: 0.734301 / Training Accuracy: 0.0996094\n",
      "Epoch: 1 / Batch: 16896/60000 / Cost: 0.73443 / Training Accuracy: 0.0976563\n",
      "Epoch: 1 / Batch: 17408/60000 / Cost: 0.734395 / Training Accuracy: 0.105469\n",
      "Epoch: 1 / Batch: 17920/60000 / Cost: 0.734301 / Training Accuracy: 0.107422\n",
      "Epoch: 1 / Batch: 18432/60000 / Cost: 0.734363 / Training Accuracy: 0.134766\n",
      "Epoch: 1 / Batch: 18944/60000 / Cost: 0.734351 / Training Accuracy: 0.160156\n",
      "Epoch: 1 / Batch: 19456/60000 / Cost: 0.734373 / Training Accuracy: 0.189453\n",
      "Epoch: 1 / Batch: 19968/60000 / Cost: 0.734329 / Training Accuracy: 0.193359\n",
      "Epoch: 1 / Batch: 20480/60000 / Cost: 0.734384 / Training Accuracy: 0.148438\n",
      "Epoch: 1 / Batch: 20992/60000 / Cost: 0.734325 / Training Accuracy: 0.166016\n",
      "Epoch: 1 / Batch: 21504/60000 / Cost: 0.734286 / Training Accuracy: 0.164063\n",
      "Epoch: 1 / Batch: 22016/60000 / Cost: 0.734301 / Training Accuracy: 0.183594\n",
      "Epoch: 1 / Batch: 22528/60000 / Cost: 0.734386 / Training Accuracy: 0.146484\n",
      "Epoch: 1 / Batch: 23040/60000 / Cost: 0.734335 / Training Accuracy: 0.146484\n",
      "Epoch: 1 / Batch: 23552/60000 / Cost: 0.73433 / Training Accuracy: 0.164063\n",
      "Epoch: 1 / Batch: 24064/60000 / Cost: 0.73426 / Training Accuracy: 0.166016\n",
      "Epoch: 1 / Batch: 24576/60000 / Cost: 0.734266 / Training Accuracy: 0.175781\n",
      "Epoch: 1 / Batch: 25088/60000 / Cost: 0.734217 / Training Accuracy: 0.167969\n",
      "Epoch: 1 / Batch: 25600/60000 / Cost: 0.734299 / Training Accuracy: 0.175781\n",
      "Epoch: 1 / Batch: 26112/60000 / Cost: 0.734376 / Training Accuracy: 0.125\n",
      "Epoch: 1 / Batch: 26624/60000 / Cost: 0.734393 / Training Accuracy: 0.146484\n",
      "Epoch: 1 / Batch: 27136/60000 / Cost: 0.734331 / Training Accuracy: 0.144531\n",
      "Epoch: 1 / Batch: 27648/60000 / Cost: 0.734244 / Training Accuracy: 0.144531\n",
      "Epoch: 1 / Batch: 28160/60000 / Cost: 0.734374 / Training Accuracy: 0.154297\n",
      "Epoch: 1 / Batch: 28672/60000 / Cost: 0.734378 / Training Accuracy: 0.148438\n",
      "Epoch: 1 / Batch: 29184/60000 / Cost: 0.734172 / Training Accuracy: 0.162109\n",
      "Epoch: 1 / Batch: 29696/60000 / Cost: 0.734309 / Training Accuracy: 0.164063\n",
      "Epoch: 1 / Batch: 30208/60000 / Cost: 0.734354 / Training Accuracy: 0.160156\n",
      "Epoch: 1 / Batch: 30720/60000 / Cost: 0.734316 / Training Accuracy: 0.162109\n",
      "Epoch: 1 / Batch: 31232/60000 / Cost: 0.734336 / Training Accuracy: 0.162109\n",
      "Epoch: 1 / Batch: 31744/60000 / Cost: 0.734302 / Training Accuracy: 0.136719\n",
      "Epoch: 1 / Batch: 32256/60000 / Cost: 0.734256 / Training Accuracy: 0.171875\n",
      "Epoch: 1 / Batch: 32768/60000 / Cost: 0.734209 / Training Accuracy: 0.179688\n",
      "Epoch: 1 / Batch: 33280/60000 / Cost: 0.734353 / Training Accuracy: 0.166016\n",
      "Epoch: 1 / Batch: 33792/60000 / Cost: 0.734181 / Training Accuracy: 0.207031\n",
      "Epoch: 1 / Batch: 34304/60000 / Cost: 0.734343 / Training Accuracy: 0.191406\n",
      "Epoch: 1 / Batch: 34816/60000 / Cost: 0.734294 / Training Accuracy: 0.195313\n",
      "Epoch: 1 / Batch: 35328/60000 / Cost: 0.734241 / Training Accuracy: 0.199219\n",
      "Epoch: 1 / Batch: 35840/60000 / Cost: 0.734231 / Training Accuracy: 0.189453\n",
      "Epoch: 1 / Batch: 36352/60000 / Cost: 0.734303 / Training Accuracy: 0.189453\n",
      "Epoch: 1 / Batch: 36864/60000 / Cost: 0.734382 / Training Accuracy: 0.173828\n",
      "Epoch: 1 / Batch: 37376/60000 / Cost: 0.73431 / Training Accuracy: 0.173828\n",
      "Epoch: 1 / Batch: 37888/60000 / Cost: 0.734251 / Training Accuracy: 0.195313\n",
      "Epoch: 1 / Batch: 38400/60000 / Cost: 0.734372 / Training Accuracy: 0.148438\n",
      "Epoch: 1 / Batch: 38912/60000 / Cost: 0.734186 / Training Accuracy: 0.181641\n",
      "Epoch: 1 / Batch: 39424/60000 / Cost: 0.734274 / Training Accuracy: 0.164063\n",
      "Epoch: 1 / Batch: 39936/60000 / Cost: 0.734312 / Training Accuracy: 0.162109\n",
      "Epoch: 1 / Batch: 40448/60000 / Cost: 0.734191 / Training Accuracy: 0.185547\n",
      "Epoch: 1 / Batch: 40960/60000 / Cost: 0.734146 / Training Accuracy: 0.201172\n",
      "Epoch: 1 / Batch: 41472/60000 / Cost: 0.734259 / Training Accuracy: 0.179688\n",
      "Epoch: 1 / Batch: 41984/60000 / Cost: 0.734151 / Training Accuracy: 0.181641\n",
      "Epoch: 1 / Batch: 42496/60000 / Cost: 0.734291 / Training Accuracy: 0.15625\n",
      "Epoch: 1 / Batch: 43008/60000 / Cost: 0.734186 / Training Accuracy: 0.185547\n",
      "Epoch: 1 / Batch: 43520/60000 / Cost: 0.734152 / Training Accuracy: 0.189453\n",
      "Epoch: 1 / Batch: 44032/60000 / Cost: 0.734127 / Training Accuracy: 0.208984\n",
      "Epoch: 1 / Batch: 44544/60000 / Cost: 0.734205 / Training Accuracy: 0.181641\n",
      "Epoch: 1 / Batch: 45056/60000 / Cost: 0.734209 / Training Accuracy: 0.1875\n",
      "Epoch: 1 / Batch: 45568/60000 / Cost: 0.734233 / Training Accuracy: 0.185547\n",
      "Epoch: 1 / Batch: 46080/60000 / Cost: 0.734169 / Training Accuracy: 0.189453\n",
      "Epoch: 1 / Batch: 46592/60000 / Cost: 0.734203 / Training Accuracy: 0.185547\n",
      "Epoch: 1 / Batch: 47104/60000 / Cost: 0.734183 / Training Accuracy: 0.179688\n",
      "Epoch: 1 / Batch: 47616/60000 / Cost: 0.734039 / Training Accuracy: 0.224609\n",
      "Epoch: 1 / Batch: 48128/60000 / Cost: 0.734206 / Training Accuracy: 0.179688\n",
      "Epoch: 1 / Batch: 48640/60000 / Cost: 0.734126 / Training Accuracy: 0.185547\n",
      "Epoch: 1 / Batch: 49152/60000 / Cost: 0.734147 / Training Accuracy: 0.185547\n",
      "Epoch: 1 / Batch: 49664/60000 / Cost: 0.734139 / Training Accuracy: 0.195313\n",
      "Epoch: 1 / Batch: 50176/60000 / Cost: 0.734175 / Training Accuracy: 0.179688\n",
      "Epoch: 1 / Batch: 50688/60000 / Cost: 0.734137 / Training Accuracy: 0.181641\n",
      "Epoch: 1 / Batch: 51200/60000 / Cost: 0.733971 / Training Accuracy: 0.216797\n",
      "Epoch: 1 / Batch: 51712/60000 / Cost: 0.734142 / Training Accuracy: 0.173828\n",
      "Epoch: 1 / Batch: 52224/60000 / Cost: 0.73398 / Training Accuracy: 0.228516\n",
      "Epoch: 1 / Batch: 52736/60000 / Cost: 0.734138 / Training Accuracy: 0.175781\n",
      "Epoch: 1 / Batch: 53248/60000 / Cost: 0.734215 / Training Accuracy: 0.15625\n",
      "Epoch: 1 / Batch: 53760/60000 / Cost: 0.734052 / Training Accuracy: 0.197266\n",
      "Epoch: 1 / Batch: 54272/60000 / Cost: 0.73406 / Training Accuracy: 0.183594\n",
      "Epoch: 1 / Batch: 54784/60000 / Cost: 0.734114 / Training Accuracy: 0.181641\n",
      "Epoch: 1 / Batch: 55296/60000 / Cost: 0.733931 / Training Accuracy: 0.228516\n",
      "Epoch: 1 / Batch: 55808/60000 / Cost: 0.73408 / Training Accuracy: 0.193359\n",
      "Epoch: 1 / Batch: 56320/60000 / Cost: 0.734064 / Training Accuracy: 0.193359\n",
      "Epoch: 1 / Batch: 56832/60000 / Cost: 0.734063 / Training Accuracy: 0.193359\n",
      "Epoch: 1 / Batch: 57344/60000 / Cost: 0.734025 / Training Accuracy: 0.1875\n",
      "Epoch: 1 / Batch: 57856/60000 / Cost: 0.734054 / Training Accuracy: 0.1875\n",
      "Epoch: 1 / Batch: 58368/60000 / Cost: 0.73393 / Training Accuracy: 0.205078\n",
      "Epoch: 1 / Batch: 58880/60000 / Cost: 0.734248 / Training Accuracy: 0.158203\n",
      "Epoch: 1 / Batch: 59392/60000 / Cost: 0.734133 / Training Accuracy: 0.173828\n",
      "Epoch: 1 / Batch: 59904/60000 / Cost: 0.734108 / Training Accuracy: 0.166667\n",
      "Epoch: 2 / Batch: 0/60000 / Cost: 0.734043 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 512/60000 / Cost: 0.734062 / Training Accuracy: 0.201172\n",
      "Epoch: 2 / Batch: 1024/60000 / Cost: 0.734137 / Training Accuracy: 0.146484\n",
      "Epoch: 2 / Batch: 1536/60000 / Cost: 0.733975 / Training Accuracy: 0.193359\n",
      "Epoch: 2 / Batch: 2048/60000 / Cost: 0.734254 / Training Accuracy: 0.138672\n",
      "Epoch: 2 / Batch: 2560/60000 / Cost: 0.734145 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 3072/60000 / Cost: 0.734045 / Training Accuracy: 0.181641\n",
      "Epoch: 2 / Batch: 3584/60000 / Cost: 0.734025 / Training Accuracy: 0.167969\n",
      "Epoch: 2 / Batch: 4096/60000 / Cost: 0.73411 / Training Accuracy: 0.167969\n",
      "Epoch: 2 / Batch: 4608/60000 / Cost: 0.734018 / Training Accuracy: 0.167969\n",
      "Epoch: 2 / Batch: 5120/60000 / Cost: 0.734153 / Training Accuracy: 0.162109\n",
      "Epoch: 2 / Batch: 5632/60000 / Cost: 0.733786 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 6144/60000 / Cost: 0.734099 / Training Accuracy: 0.166016\n",
      "Epoch: 2 / Batch: 6656/60000 / Cost: 0.73387 / Training Accuracy: 0.1875\n",
      "Epoch: 2 / Batch: 7168/60000 / Cost: 0.734042 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 7680/60000 / Cost: 0.733692 / Training Accuracy: 0.210938\n",
      "Epoch: 2 / Batch: 8192/60000 / Cost: 0.73369 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 8704/60000 / Cost: 0.734007 / Training Accuracy: 0.154297\n",
      "Epoch: 2 / Batch: 9216/60000 / Cost: 0.733774 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 9728/60000 / Cost: 0.734023 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 10240/60000 / Cost: 0.733774 / Training Accuracy: 0.191406\n",
      "Epoch: 2 / Batch: 10752/60000 / Cost: 0.733983 / Training Accuracy: 0.164063\n",
      "Epoch: 2 / Batch: 11264/60000 / Cost: 0.73374 / Training Accuracy: 0.191406\n",
      "Epoch: 2 / Batch: 11776/60000 / Cost: 0.734108 / Training Accuracy: 0.166016\n",
      "Epoch: 2 / Batch: 12288/60000 / Cost: 0.73395 / Training Accuracy: 0.160156\n",
      "Epoch: 2 / Batch: 12800/60000 / Cost: 0.733907 / Training Accuracy: 0.191406\n",
      "Epoch: 2 / Batch: 13312/60000 / Cost: 0.733755 / Training Accuracy: 0.203125\n",
      "Epoch: 2 / Batch: 13824/60000 / Cost: 0.733915 / Training Accuracy: 0.175781\n",
      "Epoch: 2 / Batch: 14336/60000 / Cost: 0.7337 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 14848/60000 / Cost: 0.733916 / Training Accuracy: 0.167969\n",
      "Epoch: 2 / Batch: 15360/60000 / Cost: 0.734019 / Training Accuracy: 0.148438\n",
      "Epoch: 2 / Batch: 15872/60000 / Cost: 0.733786 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 16384/60000 / Cost: 0.73377 / Training Accuracy: 0.179688\n",
      "Epoch: 2 / Batch: 16896/60000 / Cost: 0.733842 / Training Accuracy: 0.175781\n",
      "Epoch: 2 / Batch: 17408/60000 / Cost: 0.733878 / Training Accuracy: 0.152344\n",
      "Epoch: 2 / Batch: 17920/60000 / Cost: 0.733963 / Training Accuracy: 0.167969\n",
      "Epoch: 2 / Batch: 18432/60000 / Cost: 0.733736 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 18944/60000 / Cost: 0.733907 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 19456/60000 / Cost: 0.733734 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 19968/60000 / Cost: 0.733653 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 20480/60000 / Cost: 0.733829 / Training Accuracy: 0.167969\n",
      "Epoch: 2 / Batch: 20992/60000 / Cost: 0.733607 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 21504/60000 / Cost: 0.733675 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 22016/60000 / Cost: 0.733611 / Training Accuracy: 0.181641\n",
      "Epoch: 2 / Batch: 22528/60000 / Cost: 0.733791 / Training Accuracy: 0.185547\n",
      "Epoch: 2 / Batch: 23040/60000 / Cost: 0.733642 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 23552/60000 / Cost: 0.733839 / Training Accuracy: 0.173828\n",
      "Epoch: 2 / Batch: 24064/60000 / Cost: 0.733756 / Training Accuracy: 0.1875\n",
      "Epoch: 2 / Batch: 24576/60000 / Cost: 0.73359 / Training Accuracy: 0.210938\n",
      "Epoch: 2 / Batch: 25088/60000 / Cost: 0.7335 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 25600/60000 / Cost: 0.7335 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 26112/60000 / Cost: 0.733475 / Training Accuracy: 0.208984\n",
      "Epoch: 2 / Batch: 26624/60000 / Cost: 0.733395 / Training Accuracy: 0.214844\n",
      "Epoch: 2 / Batch: 27136/60000 / Cost: 0.733408 / Training Accuracy: 0.193359\n",
      "Epoch: 2 / Batch: 27648/60000 / Cost: 0.733595 / Training Accuracy: 0.183594\n",
      "Epoch: 2 / Batch: 28160/60000 / Cost: 0.733447 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 28672/60000 / Cost: 0.733474 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 29184/60000 / Cost: 0.733594 / Training Accuracy: 0.183594\n",
      "Epoch: 2 / Batch: 29696/60000 / Cost: 0.733477 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 30208/60000 / Cost: 0.733446 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 30720/60000 / Cost: 0.733705 / Training Accuracy: 0.171875\n",
      "Epoch: 2 / Batch: 31232/60000 / Cost: 0.733321 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 31744/60000 / Cost: 0.733144 / Training Accuracy: 0.220703\n",
      "Epoch: 2 / Batch: 32256/60000 / Cost: 0.733505 / Training Accuracy: 0.191406\n",
      "Epoch: 2 / Batch: 32768/60000 / Cost: 0.733804 / Training Accuracy: 0.15625\n",
      "Epoch: 2 / Batch: 33280/60000 / Cost: 0.733436 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 33792/60000 / Cost: 0.733368 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 34304/60000 / Cost: 0.73337 / Training Accuracy: 0.185547\n",
      "Epoch: 2 / Batch: 34816/60000 / Cost: 0.733201 / Training Accuracy: 0.214844\n",
      "Epoch: 2 / Batch: 35328/60000 / Cost: 0.733336 / Training Accuracy: 0.1875\n",
      "Epoch: 2 / Batch: 35840/60000 / Cost: 0.733462 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 36352/60000 / Cost: 0.733391 / Training Accuracy: 0.183594\n",
      "Epoch: 2 / Batch: 36864/60000 / Cost: 0.733294 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 37376/60000 / Cost: 0.733389 / Training Accuracy: 0.183594\n",
      "Epoch: 2 / Batch: 37888/60000 / Cost: 0.732921 / Training Accuracy: 0.220703\n",
      "Epoch: 2 / Batch: 38400/60000 / Cost: 0.733038 / Training Accuracy: 0.205078\n",
      "Epoch: 2 / Batch: 38912/60000 / Cost: 0.733083 / Training Accuracy: 0.203125\n",
      "Epoch: 2 / Batch: 39424/60000 / Cost: 0.733218 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 39936/60000 / Cost: 0.733167 / Training Accuracy: 0.203125\n",
      "Epoch: 2 / Batch: 40448/60000 / Cost: 0.73295 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 40960/60000 / Cost: 0.733439 / Training Accuracy: 0.166016\n",
      "Epoch: 2 / Batch: 41472/60000 / Cost: 0.733174 / Training Accuracy: 0.193359\n",
      "Epoch: 2 / Batch: 41984/60000 / Cost: 0.732924 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 42496/60000 / Cost: 0.733272 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 43008/60000 / Cost: 0.73373 / Training Accuracy: 0.162109\n",
      "Epoch: 2 / Batch: 43520/60000 / Cost: 0.733209 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 44032/60000 / Cost: 0.733386 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 44544/60000 / Cost: 0.733046 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 45056/60000 / Cost: 0.732877 / Training Accuracy: 0.179688\n",
      "Epoch: 2 / Batch: 45568/60000 / Cost: 0.732912 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 46080/60000 / Cost: 0.73288 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 46592/60000 / Cost: 0.732849 / Training Accuracy: 0.201172\n",
      "Epoch: 2 / Batch: 47104/60000 / Cost: 0.733045 / Training Accuracy: 0.191406\n",
      "Epoch: 2 / Batch: 47616/60000 / Cost: 0.732723 / Training Accuracy: 0.208984\n",
      "Epoch: 2 / Batch: 48128/60000 / Cost: 0.732695 / Training Accuracy: 0.197266\n",
      "Epoch: 2 / Batch: 48640/60000 / Cost: 0.733241 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 49152/60000 / Cost: 0.733217 / Training Accuracy: 0.185547\n",
      "Epoch: 2 / Batch: 49664/60000 / Cost: 0.733365 / Training Accuracy: 0.160156\n",
      "Epoch: 2 / Batch: 50176/60000 / Cost: 0.733332 / Training Accuracy: 0.162109\n",
      "Epoch: 2 / Batch: 50688/60000 / Cost: 0.732957 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 51200/60000 / Cost: 0.732858 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 51712/60000 / Cost: 0.733126 / Training Accuracy: 0.160156\n",
      "Epoch: 2 / Batch: 52224/60000 / Cost: 0.732654 / Training Accuracy: 0.207031\n",
      "Epoch: 2 / Batch: 52736/60000 / Cost: 0.732603 / Training Accuracy: 0.208984\n",
      "Epoch: 2 / Batch: 53248/60000 / Cost: 0.733189 / Training Accuracy: 0.162109\n",
      "Epoch: 2 / Batch: 53760/60000 / Cost: 0.733018 / Training Accuracy: 0.175781\n",
      "Epoch: 2 / Batch: 54272/60000 / Cost: 0.732945 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 54784/60000 / Cost: 0.732595 / Training Accuracy: 0.199219\n",
      "Epoch: 2 / Batch: 55296/60000 / Cost: 0.732912 / Training Accuracy: 0.177734\n",
      "Epoch: 2 / Batch: 55808/60000 / Cost: 0.733069 / Training Accuracy: 0.169922\n",
      "Epoch: 2 / Batch: 56320/60000 / Cost: 0.732748 / Training Accuracy: 0.189453\n",
      "Epoch: 2 / Batch: 56832/60000 / Cost: 0.732126 / Training Accuracy: 0.208984\n",
      "Epoch: 2 / Batch: 57344/60000 / Cost: 0.732389 / Training Accuracy: 0.208984\n",
      "Epoch: 2 / Batch: 57856/60000 / Cost: 0.732568 / Training Accuracy: 0.195313\n",
      "Epoch: 2 / Batch: 58368/60000 / Cost: 0.732532 / Training Accuracy: 0.191406\n",
      "Epoch: 2 / Batch: 58880/60000 / Cost: 0.73296 / Training Accuracy: 0.183594\n",
      "Epoch: 2 / Batch: 59392/60000 / Cost: 0.733411 / Training Accuracy: 0.152344\n",
      "Epoch: 2 / Batch: 59904/60000 / Cost: 0.732925 / Training Accuracy: 0.177083\n",
      "Epoch: 3 / Batch: 0/60000 / Cost: 0.732381 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 512/60000 / Cost: 0.732461 / Training Accuracy: 0.1875\n",
      "Epoch: 3 / Batch: 1024/60000 / Cost: 0.732594 / Training Accuracy: 0.181641\n",
      "Epoch: 3 / Batch: 1536/60000 / Cost: 0.732641 / Training Accuracy: 0.181641\n",
      "Epoch: 3 / Batch: 2048/60000 / Cost: 0.732717 / Training Accuracy: 0.1875\n",
      "Epoch: 3 / Batch: 2560/60000 / Cost: 0.732308 / Training Accuracy: 0.179688\n",
      "Epoch: 3 / Batch: 3072/60000 / Cost: 0.732243 / Training Accuracy: 0.201172\n",
      "Epoch: 3 / Batch: 3584/60000 / Cost: 0.732357 / Training Accuracy: 0.189453\n",
      "Epoch: 3 / Batch: 4096/60000 / Cost: 0.732174 / Training Accuracy: 0.181641\n",
      "Epoch: 3 / Batch: 4608/60000 / Cost: 0.732576 / Training Accuracy: 0.175781\n",
      "Epoch: 3 / Batch: 5120/60000 / Cost: 0.7324 / Training Accuracy: 0.185547\n",
      "Epoch: 3 / Batch: 5632/60000 / Cost: 0.73202 / Training Accuracy: 0.212891\n",
      "Epoch: 3 / Batch: 6144/60000 / Cost: 0.732265 / Training Accuracy: 0.183594\n",
      "Epoch: 3 / Batch: 6656/60000 / Cost: 0.732273 / Training Accuracy: 0.185547\n",
      "Epoch: 3 / Batch: 7168/60000 / Cost: 0.732737 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 7680/60000 / Cost: 0.732018 / Training Accuracy: 0.183594\n",
      "Epoch: 3 / Batch: 8192/60000 / Cost: 0.732277 / Training Accuracy: 0.183594\n",
      "Epoch: 3 / Batch: 8704/60000 / Cost: 0.732117 / Training Accuracy: 0.179688\n",
      "Epoch: 3 / Batch: 9216/60000 / Cost: 0.731923 / Training Accuracy: 0.195313\n",
      "Epoch: 3 / Batch: 9728/60000 / Cost: 0.732191 / Training Accuracy: 0.1875\n",
      "Epoch: 3 / Batch: 10240/60000 / Cost: 0.731925 / Training Accuracy: 0.189453\n",
      "Epoch: 3 / Batch: 10752/60000 / Cost: 0.732407 / Training Accuracy: 0.169922\n",
      "Epoch: 3 / Batch: 11264/60000 / Cost: 0.732412 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 11776/60000 / Cost: 0.732907 / Training Accuracy: 0.146484\n",
      "Epoch: 3 / Batch: 12288/60000 / Cost: 0.732002 / Training Accuracy: 0.193359\n",
      "Epoch: 3 / Batch: 12800/60000 / Cost: 0.732133 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 13312/60000 / Cost: 0.731794 / Training Accuracy: 0.197266\n",
      "Epoch: 3 / Batch: 13824/60000 / Cost: 0.731936 / Training Accuracy: 0.185547\n",
      "Epoch: 3 / Batch: 14336/60000 / Cost: 0.732019 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 14848/60000 / Cost: 0.732538 / Training Accuracy: 0.175781\n",
      "Epoch: 3 / Batch: 15360/60000 / Cost: 0.7317 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 15872/60000 / Cost: 0.731949 / Training Accuracy: 0.201172\n",
      "Epoch: 3 / Batch: 16384/60000 / Cost: 0.73148 / Training Accuracy: 0.197266\n",
      "Epoch: 3 / Batch: 16896/60000 / Cost: 0.731923 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 17408/60000 / Cost: 0.731593 / Training Accuracy: 0.193359\n",
      "Epoch: 3 / Batch: 17920/60000 / Cost: 0.73174 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 18432/60000 / Cost: 0.732013 / Training Accuracy: 0.193359\n",
      "Epoch: 3 / Batch: 18944/60000 / Cost: 0.731715 / Training Accuracy: 0.1875\n",
      "Epoch: 3 / Batch: 19456/60000 / Cost: 0.731858 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 19968/60000 / Cost: 0.731928 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 20480/60000 / Cost: 0.731813 / Training Accuracy: 0.189453\n",
      "Epoch: 3 / Batch: 20992/60000 / Cost: 0.73214 / Training Accuracy: 0.162109\n",
      "Epoch: 3 / Batch: 21504/60000 / Cost: 0.73186 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 22016/60000 / Cost: 0.731358 / Training Accuracy: 0.199219\n",
      "Epoch: 3 / Batch: 22528/60000 / Cost: 0.732016 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 23040/60000 / Cost: 0.731389 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 23552/60000 / Cost: 0.731768 / Training Accuracy: 0.189453\n",
      "Epoch: 3 / Batch: 24064/60000 / Cost: 0.730699 / Training Accuracy: 0.216797\n",
      "Epoch: 3 / Batch: 24576/60000 / Cost: 0.731601 / Training Accuracy: 0.175781\n",
      "Epoch: 3 / Batch: 25088/60000 / Cost: 0.73209 / Training Accuracy: 0.154297\n",
      "Epoch: 3 / Batch: 25600/60000 / Cost: 0.731886 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 26112/60000 / Cost: 0.731629 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 26624/60000 / Cost: 0.730261 / Training Accuracy: 0.210938\n",
      "Epoch: 3 / Batch: 27136/60000 / Cost: 0.731101 / Training Accuracy: 0.195313\n",
      "Epoch: 3 / Batch: 27648/60000 / Cost: 0.731659 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 28160/60000 / Cost: 0.731948 / Training Accuracy: 0.166016\n",
      "Epoch: 3 / Batch: 28672/60000 / Cost: 0.731403 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 29184/60000 / Cost: 0.731897 / Training Accuracy: 0.166016\n",
      "Epoch: 3 / Batch: 29696/60000 / Cost: 0.730771 / Training Accuracy: 0.181641\n",
      "Epoch: 3 / Batch: 30208/60000 / Cost: 0.731667 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 30720/60000 / Cost: 0.730081 / Training Accuracy: 0.21875\n",
      "Epoch: 3 / Batch: 31232/60000 / Cost: 0.732116 / Training Accuracy: 0.150391\n",
      "Epoch: 3 / Batch: 31744/60000 / Cost: 0.731189 / Training Accuracy: 0.1875\n",
      "Epoch: 3 / Batch: 32256/60000 / Cost: 0.730531 / Training Accuracy: 0.193359\n",
      "Epoch: 3 / Batch: 32768/60000 / Cost: 0.732204 / Training Accuracy: 0.152344\n",
      "Epoch: 3 / Batch: 33280/60000 / Cost: 0.731265 / Training Accuracy: 0.160156\n",
      "Epoch: 3 / Batch: 33792/60000 / Cost: 0.730435 / Training Accuracy: 0.197266\n",
      "Epoch: 3 / Batch: 34304/60000 / Cost: 0.731026 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 34816/60000 / Cost: 0.729911 / Training Accuracy: 0.214844\n",
      "Epoch: 3 / Batch: 35328/60000 / Cost: 0.731615 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 35840/60000 / Cost: 0.732018 / Training Accuracy: 0.15625\n",
      "Epoch: 3 / Batch: 36352/60000 / Cost: 0.731118 / Training Accuracy: 0.183594\n",
      "Epoch: 3 / Batch: 36864/60000 / Cost: 0.730855 / Training Accuracy: 0.175781\n",
      "Epoch: 3 / Batch: 37376/60000 / Cost: 0.729742 / Training Accuracy: 0.199219\n",
      "Epoch: 3 / Batch: 37888/60000 / Cost: 0.73194 / Training Accuracy: 0.162109\n",
      "Epoch: 3 / Batch: 38400/60000 / Cost: 0.731591 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 38912/60000 / Cost: 0.729792 / Training Accuracy: 0.210938\n",
      "Epoch: 3 / Batch: 39424/60000 / Cost: 0.731195 / Training Accuracy: 0.169922\n",
      "Epoch: 3 / Batch: 39936/60000 / Cost: 0.731045 / Training Accuracy: 0.177734\n",
      "Epoch: 3 / Batch: 40448/60000 / Cost: 0.729874 / Training Accuracy: 0.207031\n",
      "Epoch: 3 / Batch: 40960/60000 / Cost: 0.728968 / Training Accuracy: 0.236328\n",
      "Epoch: 3 / Batch: 41472/60000 / Cost: 0.731693 / Training Accuracy: 0.167969\n",
      "Epoch: 3 / Batch: 41984/60000 / Cost: 0.73099 / Training Accuracy: 0.197266\n",
      "Epoch: 3 / Batch: 42496/60000 / Cost: 0.730674 / Training Accuracy: 0.179688\n",
      "Epoch: 3 / Batch: 43008/60000 / Cost: 0.731439 / Training Accuracy: 0.177734\n",
      "Epoch: 3 / Batch: 43520/60000 / Cost: 0.730795 / Training Accuracy: 0.193359\n",
      "Epoch: 3 / Batch: 44032/60000 / Cost: 0.730545 / Training Accuracy: 0.177734\n",
      "Epoch: 3 / Batch: 44544/60000 / Cost: 0.729501 / Training Accuracy: 0.224609\n",
      "Epoch: 3 / Batch: 45056/60000 / Cost: 0.729446 / Training Accuracy: 0.203125\n",
      "Epoch: 3 / Batch: 45568/60000 / Cost: 0.731412 / Training Accuracy: 0.162109\n",
      "Epoch: 3 / Batch: 46080/60000 / Cost: 0.731509 / Training Accuracy: 0.15625\n",
      "Epoch: 3 / Batch: 46592/60000 / Cost: 0.730712 / Training Accuracy: 0.197266\n",
      "Epoch: 3 / Batch: 47104/60000 / Cost: 0.73034 / Training Accuracy: 0.183594\n",
      "Epoch: 3 / Batch: 47616/60000 / Cost: 0.729944 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 48128/60000 / Cost: 0.730642 / Training Accuracy: 0.166016\n",
      "Epoch: 3 / Batch: 48640/60000 / Cost: 0.730124 / Training Accuracy: 0.191406\n",
      "Epoch: 3 / Batch: 49152/60000 / Cost: 0.729587 / Training Accuracy: 0.208984\n",
      "Epoch: 3 / Batch: 49664/60000 / Cost: 0.730716 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 50176/60000 / Cost: 0.730632 / Training Accuracy: 0.173828\n",
      "Epoch: 3 / Batch: 50688/60000 / Cost: 0.730309 / Training Accuracy: 0.185547\n",
      "Epoch: 3 / Batch: 51200/60000 / Cost: 0.730177 / Training Accuracy: 0.189453\n",
      "Epoch: 3 / Batch: 51712/60000 / Cost: 0.730456 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 52224/60000 / Cost: 0.730658 / Training Accuracy: 0.164063\n",
      "Epoch: 3 / Batch: 52736/60000 / Cost: 0.729257 / Training Accuracy: 0.216797\n",
      "Epoch: 3 / Batch: 53248/60000 / Cost: 0.729861 / Training Accuracy: 0.189453\n",
      "Epoch: 3 / Batch: 53760/60000 / Cost: 0.729297 / Training Accuracy: 0.195313\n",
      "Epoch: 3 / Batch: 54272/60000 / Cost: 0.730062 / Training Accuracy: 0.183594\n",
      "Epoch: 3 / Batch: 54784/60000 / Cost: 0.730162 / Training Accuracy: 0.179688\n",
      "Epoch: 3 / Batch: 55296/60000 / Cost: 0.729757 / Training Accuracy: 0.169922\n",
      "Epoch: 3 / Batch: 55808/60000 / Cost: 0.730671 / Training Accuracy: 0.171875\n",
      "Epoch: 3 / Batch: 56320/60000 / Cost: 0.729526 / Training Accuracy: 0.205078\n",
      "Epoch: 3 / Batch: 56832/60000 / Cost: 0.729306 / Training Accuracy: 0.207031\n",
      "Epoch: 3 / Batch: 57344/60000 / Cost: 0.728664 / Training Accuracy: 0.216797\n",
      "Epoch: 3 / Batch: 57856/60000 / Cost: 0.730354 / Training Accuracy: 0.175781\n",
      "Epoch: 3 / Batch: 58368/60000 / Cost: 0.728556 / Training Accuracy: 0.234375\n",
      "Epoch: 3 / Batch: 58880/60000 / Cost: 0.728971 / Training Accuracy: 0.201172\n",
      "Epoch: 3 / Batch: 59392/60000 / Cost: 0.731254 / Training Accuracy: 0.150391\n",
      "Epoch: 3 / Batch: 59904/60000 / Cost: 0.729472 / Training Accuracy: 0.177083\n",
      "Epoch: 4 / Batch: 0/60000 / Cost: 0.729356 / Training Accuracy: 0.191406\n",
      "Epoch: 4 / Batch: 512/60000 / Cost: 0.728778 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 1024/60000 / Cost: 0.729056 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 1536/60000 / Cost: 0.729353 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 2048/60000 / Cost: 0.728702 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 2560/60000 / Cost: 0.728949 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 3072/60000 / Cost: 0.72884 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 3584/60000 / Cost: 0.729735 / Training Accuracy: 0.179688\n",
      "Epoch: 4 / Batch: 4096/60000 / Cost: 0.729088 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 4608/60000 / Cost: 0.728321 / Training Accuracy: 0.208984\n",
      "Epoch: 4 / Batch: 5120/60000 / Cost: 0.729185 / Training Accuracy: 0.179688\n",
      "Epoch: 4 / Batch: 5632/60000 / Cost: 0.72968 / Training Accuracy: 0.193359\n",
      "Epoch: 4 / Batch: 6144/60000 / Cost: 0.728788 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 6656/60000 / Cost: 0.730181 / Training Accuracy: 0.173828\n",
      "Epoch: 4 / Batch: 7168/60000 / Cost: 0.72867 / Training Accuracy: 0.191406\n",
      "Epoch: 4 / Batch: 7680/60000 / Cost: 0.72893 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 8192/60000 / Cost: 0.730065 / Training Accuracy: 0.15625\n",
      "Epoch: 4 / Batch: 8704/60000 / Cost: 0.729796 / Training Accuracy: 0.167969\n",
      "Epoch: 4 / Batch: 9216/60000 / Cost: 0.729446 / Training Accuracy: 0.183594\n",
      "Epoch: 4 / Batch: 9728/60000 / Cost: 0.729362 / Training Accuracy: 0.1875\n",
      "Epoch: 4 / Batch: 10240/60000 / Cost: 0.729704 / Training Accuracy: 0.177734\n",
      "Epoch: 4 / Batch: 10752/60000 / Cost: 0.729521 / Training Accuracy: 0.195313\n",
      "Epoch: 4 / Batch: 11264/60000 / Cost: 0.727824 / Training Accuracy: 0.222656\n",
      "Epoch: 4 / Batch: 11776/60000 / Cost: 0.728875 / Training Accuracy: 0.169922\n",
      "Epoch: 4 / Batch: 12288/60000 / Cost: 0.729366 / Training Accuracy: 0.171875\n",
      "Epoch: 4 / Batch: 12800/60000 / Cost: 0.728562 / Training Accuracy: 0.212891\n",
      "Epoch: 4 / Batch: 13312/60000 / Cost: 0.729144 / Training Accuracy: 0.189453\n",
      "Epoch: 4 / Batch: 13824/60000 / Cost: 0.728647 / Training Accuracy: 0.191406\n",
      "Epoch: 4 / Batch: 14336/60000 / Cost: 0.728996 / Training Accuracy: 0.169922\n",
      "Epoch: 4 / Batch: 14848/60000 / Cost: 0.730109 / Training Accuracy: 0.175781\n",
      "Epoch: 4 / Batch: 15360/60000 / Cost: 0.728939 / Training Accuracy: 0.183594\n",
      "Epoch: 4 / Batch: 15872/60000 / Cost: 0.728625 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 16384/60000 / Cost: 0.728485 / Training Accuracy: 0.220703\n",
      "Epoch: 4 / Batch: 16896/60000 / Cost: 0.729492 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 17408/60000 / Cost: 0.728832 / Training Accuracy: 0.207031\n",
      "Epoch: 4 / Batch: 17920/60000 / Cost: 0.729774 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 18432/60000 / Cost: 0.728672 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 18944/60000 / Cost: 0.728492 / Training Accuracy: 0.210938\n",
      "Epoch: 4 / Batch: 19456/60000 / Cost: 0.729792 / Training Accuracy: 0.177734\n",
      "Epoch: 4 / Batch: 19968/60000 / Cost: 0.727561 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 20480/60000 / Cost: 0.729742 / Training Accuracy: 0.169922\n",
      "Epoch: 4 / Batch: 20992/60000 / Cost: 0.728738 / Training Accuracy: 0.185547\n",
      "Epoch: 4 / Batch: 21504/60000 / Cost: 0.728864 / Training Accuracy: 0.179688\n",
      "Epoch: 4 / Batch: 22016/60000 / Cost: 0.728535 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 22528/60000 / Cost: 0.728974 / Training Accuracy: 0.189453\n",
      "Epoch: 4 / Batch: 23040/60000 / Cost: 0.72944 / Training Accuracy: 0.193359\n",
      "Epoch: 4 / Batch: 23552/60000 / Cost: 0.727157 / Training Accuracy: 0.212891\n",
      "Epoch: 4 / Batch: 24064/60000 / Cost: 0.727927 / Training Accuracy: 0.195313\n",
      "Epoch: 4 / Batch: 24576/60000 / Cost: 0.72695 / Training Accuracy: 0.222656\n",
      "Epoch: 4 / Batch: 25088/60000 / Cost: 0.729553 / Training Accuracy: 0.171875\n",
      "Epoch: 4 / Batch: 25600/60000 / Cost: 0.726791 / Training Accuracy: 0.230469\n",
      "Epoch: 4 / Batch: 26112/60000 / Cost: 0.728017 / Training Accuracy: 0.216797\n",
      "Epoch: 4 / Batch: 26624/60000 / Cost: 0.728437 / Training Accuracy: 0.207031\n",
      "Epoch: 4 / Batch: 27136/60000 / Cost: 0.728584 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 27648/60000 / Cost: 0.729559 / Training Accuracy: 0.15625\n",
      "Epoch: 4 / Batch: 28160/60000 / Cost: 0.726943 / Training Accuracy: 0.220703\n",
      "Epoch: 4 / Batch: 28672/60000 / Cost: 0.72855 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 29184/60000 / Cost: 0.727946 / Training Accuracy: 0.210938\n",
      "Epoch: 4 / Batch: 29696/60000 / Cost: 0.729326 / Training Accuracy: 0.193359\n",
      "Epoch: 4 / Batch: 30208/60000 / Cost: 0.729027 / Training Accuracy: 0.183594\n",
      "Epoch: 4 / Batch: 30720/60000 / Cost: 0.728203 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 31232/60000 / Cost: 0.729073 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 31744/60000 / Cost: 0.728055 / Training Accuracy: 0.21875\n",
      "Epoch: 4 / Batch: 32256/60000 / Cost: 0.727666 / Training Accuracy: 0.208984\n",
      "Epoch: 4 / Batch: 32768/60000 / Cost: 0.72883 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 33280/60000 / Cost: 0.728572 / Training Accuracy: 0.208984\n",
      "Epoch: 4 / Batch: 33792/60000 / Cost: 0.727784 / Training Accuracy: 0.191406\n",
      "Epoch: 4 / Batch: 34304/60000 / Cost: 0.726548 / Training Accuracy: 0.236328\n",
      "Epoch: 4 / Batch: 34816/60000 / Cost: 0.728485 / Training Accuracy: 0.185547\n",
      "Epoch: 4 / Batch: 35328/60000 / Cost: 0.728079 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 35840/60000 / Cost: 0.728257 / Training Accuracy: 0.207031\n",
      "Epoch: 4 / Batch: 36352/60000 / Cost: 0.728373 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 36864/60000 / Cost: 0.729446 / Training Accuracy: 0.171875\n",
      "Epoch: 4 / Batch: 37376/60000 / Cost: 0.727368 / Training Accuracy: 0.207031\n",
      "Epoch: 4 / Batch: 37888/60000 / Cost: 0.726629 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 38400/60000 / Cost: 0.72949 / Training Accuracy: 0.201172\n",
      "Epoch: 4 / Batch: 38912/60000 / Cost: 0.728123 / Training Accuracy: 0.179688\n",
      "Epoch: 4 / Batch: 39424/60000 / Cost: 0.729228 / Training Accuracy: 0.1875\n",
      "Epoch: 4 / Batch: 39936/60000 / Cost: 0.728537 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 40448/60000 / Cost: 0.729377 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 40960/60000 / Cost: 0.727891 / Training Accuracy: 0.195313\n",
      "Epoch: 4 / Batch: 41472/60000 / Cost: 0.728811 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 41984/60000 / Cost: 0.729128 / Training Accuracy: 0.195313\n",
      "Epoch: 4 / Batch: 42496/60000 / Cost: 0.728756 / Training Accuracy: 0.162109\n",
      "Epoch: 4 / Batch: 43008/60000 / Cost: 0.72632 / Training Accuracy: 0.21875\n",
      "Epoch: 4 / Batch: 43520/60000 / Cost: 0.728188 / Training Accuracy: 0.179688\n",
      "Epoch: 4 / Batch: 44032/60000 / Cost: 0.727893 / Training Accuracy: 0.205078\n",
      "Epoch: 4 / Batch: 44544/60000 / Cost: 0.727175 / Training Accuracy: 0.212891\n",
      "Epoch: 4 / Batch: 45056/60000 / Cost: 0.728548 / Training Accuracy: 0.177734\n",
      "Epoch: 4 / Batch: 45568/60000 / Cost: 0.728265 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 46080/60000 / Cost: 0.727241 / Training Accuracy: 0.207031\n",
      "Epoch: 4 / Batch: 46592/60000 / Cost: 0.727822 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 47104/60000 / Cost: 0.728805 / Training Accuracy: 0.181641\n",
      "Epoch: 4 / Batch: 47616/60000 / Cost: 0.729832 / Training Accuracy: 0.169922\n",
      "Epoch: 4 / Batch: 48128/60000 / Cost: 0.728064 / Training Accuracy: 0.199219\n",
      "Epoch: 4 / Batch: 48640/60000 / Cost: 0.729102 / Training Accuracy: 0.1875\n",
      "Epoch: 4 / Batch: 49152/60000 / Cost: 0.728029 / Training Accuracy: 0.197266\n",
      "Epoch: 4 / Batch: 49664/60000 / Cost: 0.727565 / Training Accuracy: 0.207031\n",
      "Epoch: 4 / Batch: 50176/60000 / Cost: 0.728049 / Training Accuracy: 0.193359\n",
      "Epoch: 4 / Batch: 50688/60000 / Cost: 0.72689 / Training Accuracy: 0.222656\n",
      "Epoch: 4 / Batch: 51200/60000 / Cost: 0.727543 / Training Accuracy: 0.208984\n",
      "Epoch: 4 / Batch: 51712/60000 / Cost: 0.727501 / Training Accuracy: 0.208984\n",
      "Epoch: 4 / Batch: 52224/60000 / Cost: 0.72708 / Training Accuracy: 0.21875\n",
      "Epoch: 4 / Batch: 52736/60000 / Cost: 0.727095 / Training Accuracy: 0.212891\n",
      "Epoch: 4 / Batch: 53248/60000 / Cost: 0.727378 / Training Accuracy: 0.216797\n",
      "Epoch: 4 / Batch: 53760/60000 / Cost: 0.728849 / Training Accuracy: 0.210938\n",
      "Epoch: 4 / Batch: 54272/60000 / Cost: 0.727494 / Training Accuracy: 0.212891\n",
      "Epoch: 4 / Batch: 54784/60000 / Cost: 0.727428 / Training Accuracy: 0.210938\n",
      "Epoch: 4 / Batch: 55296/60000 / Cost: 0.727737 / Training Accuracy: 0.220703\n",
      "Epoch: 4 / Batch: 55808/60000 / Cost: 0.726696 / Training Accuracy: 0.222656\n",
      "Epoch: 4 / Batch: 56320/60000 / Cost: 0.728078 / Training Accuracy: 0.216797\n",
      "Epoch: 4 / Batch: 56832/60000 / Cost: 0.728026 / Training Accuracy: 0.220703\n",
      "Epoch: 4 / Batch: 57344/60000 / Cost: 0.727943 / Training Accuracy: 0.203125\n",
      "Epoch: 4 / Batch: 57856/60000 / Cost: 0.726608 / Training Accuracy: 0.212891\n",
      "Epoch: 4 / Batch: 58368/60000 / Cost: 0.726454 / Training Accuracy: 0.234375\n",
      "Epoch: 4 / Batch: 58880/60000 / Cost: 0.728012 / Training Accuracy: 0.1875\n",
      "Epoch: 4 / Batch: 59392/60000 / Cost: 0.726103 / Training Accuracy: 0.228516\n",
      "Epoch: 4 / Batch: 59904/60000 / Cost: 0.727957 / Training Accuracy: 0.208333\n",
      "Epoch: 5 / Batch: 0/60000 / Cost: 0.727826 / Training Accuracy: 0.191406\n",
      "Epoch: 5 / Batch: 512/60000 / Cost: 0.727405 / Training Accuracy: 0.197266\n",
      "Epoch: 5 / Batch: 1024/60000 / Cost: 0.7269 / Training Accuracy: 0.228516\n",
      "Epoch: 5 / Batch: 1536/60000 / Cost: 0.726528 / Training Accuracy: 0.224609\n",
      "Epoch: 5 / Batch: 2048/60000 / Cost: 0.726921 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 2560/60000 / Cost: 0.727023 / Training Accuracy: 0.214844\n",
      "Epoch: 5 / Batch: 3072/60000 / Cost: 0.7283 / Training Accuracy: 0.207031\n",
      "Epoch: 5 / Batch: 3584/60000 / Cost: 0.7268 / Training Accuracy: 0.210938\n",
      "Epoch: 5 / Batch: 4096/60000 / Cost: 0.726481 / Training Accuracy: 0.226563\n",
      "Epoch: 5 / Batch: 4608/60000 / Cost: 0.727479 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 5120/60000 / Cost: 0.726802 / Training Accuracy: 0.228516\n",
      "Epoch: 5 / Batch: 5632/60000 / Cost: 0.727437 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 6144/60000 / Cost: 0.727887 / Training Accuracy: 0.207031\n",
      "Epoch: 5 / Batch: 6656/60000 / Cost: 0.727387 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 7168/60000 / Cost: 0.727053 / Training Accuracy: 0.228516\n",
      "Epoch: 5 / Batch: 7680/60000 / Cost: 0.727526 / Training Accuracy: 0.214844\n",
      "Epoch: 5 / Batch: 8192/60000 / Cost: 0.726203 / Training Accuracy: 0.232422\n",
      "Epoch: 5 / Batch: 8704/60000 / Cost: 0.726551 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 9216/60000 / Cost: 0.726186 / Training Accuracy: 0.236328\n",
      "Epoch: 5 / Batch: 9728/60000 / Cost: 0.725748 / Training Accuracy: 0.244141\n",
      "Epoch: 5 / Batch: 10240/60000 / Cost: 0.727666 / Training Accuracy: 0.230469\n",
      "Epoch: 5 / Batch: 10752/60000 / Cost: 0.72562 / Training Accuracy: 0.251953\n",
      "Epoch: 5 / Batch: 11264/60000 / Cost: 0.72828 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 11776/60000 / Cost: 0.728289 / Training Accuracy: 0.191406\n",
      "Epoch: 5 / Batch: 12288/60000 / Cost: 0.726101 / Training Accuracy: 0.216797\n",
      "Epoch: 5 / Batch: 12800/60000 / Cost: 0.727388 / Training Accuracy: 0.199219\n",
      "Epoch: 5 / Batch: 13312/60000 / Cost: 0.727951 / Training Accuracy: 0.189453\n",
      "Epoch: 5 / Batch: 13824/60000 / Cost: 0.728526 / Training Accuracy: 0.195313\n",
      "Epoch: 5 / Batch: 14336/60000 / Cost: 0.727496 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 14848/60000 / Cost: 0.72626 / Training Accuracy: 0.232422\n",
      "Epoch: 5 / Batch: 15360/60000 / Cost: 0.728089 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 15872/60000 / Cost: 0.727012 / Training Accuracy: 0.222656\n",
      "Epoch: 5 / Batch: 16384/60000 / Cost: 0.72549 / Training Accuracy: 0.261719\n",
      "Epoch: 5 / Batch: 16896/60000 / Cost: 0.726841 / Training Accuracy: 0.226563\n",
      "Epoch: 5 / Batch: 17408/60000 / Cost: 0.729226 / Training Accuracy: 0.166016\n",
      "Epoch: 5 / Batch: 17920/60000 / Cost: 0.727559 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 18432/60000 / Cost: 0.727962 / Training Accuracy: 0.210938\n",
      "Epoch: 5 / Batch: 18944/60000 / Cost: 0.727812 / Training Accuracy: 0.234375\n",
      "Epoch: 5 / Batch: 19456/60000 / Cost: 0.727521 / Training Accuracy: 0.222656\n",
      "Epoch: 5 / Batch: 19968/60000 / Cost: 0.725489 / Training Accuracy: 0.275391\n",
      "Epoch: 5 / Batch: 20480/60000 / Cost: 0.727439 / Training Accuracy: 0.238281\n",
      "Epoch: 5 / Batch: 20992/60000 / Cost: 0.726659 / Training Accuracy: 0.220703\n",
      "Epoch: 5 / Batch: 21504/60000 / Cost: 0.727081 / Training Accuracy: 0.199219\n",
      "Epoch: 5 / Batch: 22016/60000 / Cost: 0.727325 / Training Accuracy: 0.21875\n",
      "Epoch: 5 / Batch: 22528/60000 / Cost: 0.727308 / Training Accuracy: 0.220703\n",
      "Epoch: 5 / Batch: 23040/60000 / Cost: 0.726051 / Training Accuracy: 0.214844\n",
      "Epoch: 5 / Batch: 23552/60000 / Cost: 0.727546 / Training Accuracy: 0.21875\n",
      "Epoch: 5 / Batch: 24064/60000 / Cost: 0.727556 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 24576/60000 / Cost: 0.726914 / Training Accuracy: 0.21875\n",
      "Epoch: 5 / Batch: 25088/60000 / Cost: 0.72755 / Training Accuracy: 0.216797\n",
      "Epoch: 5 / Batch: 25600/60000 / Cost: 0.726871 / Training Accuracy: 0.234375\n",
      "Epoch: 5 / Batch: 26112/60000 / Cost: 0.727856 / Training Accuracy: 0.207031\n",
      "Epoch: 5 / Batch: 26624/60000 / Cost: 0.725013 / Training Accuracy: 0.259766\n",
      "Epoch: 5 / Batch: 27136/60000 / Cost: 0.728377 / Training Accuracy: 0.173828\n",
      "Epoch: 5 / Batch: 27648/60000 / Cost: 0.727297 / Training Accuracy: 0.207031\n",
      "Epoch: 5 / Batch: 28160/60000 / Cost: 0.727093 / Training Accuracy: 0.228516\n",
      "Epoch: 5 / Batch: 28672/60000 / Cost: 0.727513 / Training Accuracy: 0.21875\n",
      "Epoch: 5 / Batch: 29184/60000 / Cost: 0.725966 / Training Accuracy: 0.257813\n",
      "Epoch: 5 / Batch: 29696/60000 / Cost: 0.727813 / Training Accuracy: 0.240234\n",
      "Epoch: 5 / Batch: 30208/60000 / Cost: 0.726049 / Training Accuracy: 0.232422\n",
      "Epoch: 5 / Batch: 30720/60000 / Cost: 0.727296 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 31232/60000 / Cost: 0.726117 / Training Accuracy: 0.238281\n",
      "Epoch: 5 / Batch: 31744/60000 / Cost: 0.728399 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 32256/60000 / Cost: 0.7259 / Training Accuracy: 0.236328\n",
      "Epoch: 5 / Batch: 32768/60000 / Cost: 0.726904 / Training Accuracy: 0.222656\n",
      "Epoch: 5 / Batch: 33280/60000 / Cost: 0.726551 / Training Accuracy: 0.205078\n",
      "Epoch: 5 / Batch: 33792/60000 / Cost: 0.726827 / Training Accuracy: 0.216797\n",
      "Epoch: 5 / Batch: 34304/60000 / Cost: 0.72611 / Training Accuracy: 0.240234\n",
      "Epoch: 5 / Batch: 34816/60000 / Cost: 0.725595 / Training Accuracy: 0.244141\n",
      "Epoch: 5 / Batch: 35328/60000 / Cost: 0.7256 / Training Accuracy: 0.246094\n",
      "Epoch: 5 / Batch: 35840/60000 / Cost: 0.727695 / Training Accuracy: 0.210938\n",
      "Epoch: 5 / Batch: 36352/60000 / Cost: 0.726387 / Training Accuracy: 0.216797\n",
      "Epoch: 5 / Batch: 36864/60000 / Cost: 0.726304 / Training Accuracy: 0.246094\n",
      "Epoch: 5 / Batch: 37376/60000 / Cost: 0.726178 / Training Accuracy: 0.234375\n",
      "Epoch: 5 / Batch: 37888/60000 / Cost: 0.724927 / Training Accuracy: 0.246094\n",
      "Epoch: 5 / Batch: 38400/60000 / Cost: 0.726774 / Training Accuracy: 0.226563\n",
      "Epoch: 5 / Batch: 38912/60000 / Cost: 0.72621 / Training Accuracy: 0.265625\n",
      "Epoch: 5 / Batch: 39424/60000 / Cost: 0.72655 / Training Accuracy: 0.236328\n",
      "Epoch: 5 / Batch: 39936/60000 / Cost: 0.727081 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 40448/60000 / Cost: 0.727154 / Training Accuracy: 0.21875\n",
      "Epoch: 5 / Batch: 40960/60000 / Cost: 0.725763 / Training Accuracy: 0.265625\n",
      "Epoch: 5 / Batch: 41472/60000 / Cost: 0.727717 / Training Accuracy: 0.214844\n",
      "Epoch: 5 / Batch: 41984/60000 / Cost: 0.727246 / Training Accuracy: 0.214844\n",
      "Epoch: 5 / Batch: 42496/60000 / Cost: 0.725763 / Training Accuracy: 0.226563\n",
      "Epoch: 5 / Batch: 43008/60000 / Cost: 0.724586 / Training Accuracy: 0.253906\n",
      "Epoch: 5 / Batch: 43520/60000 / Cost: 0.724257 / Training Accuracy: 0.273438\n",
      "Epoch: 5 / Batch: 44032/60000 / Cost: 0.727527 / Training Accuracy: 0.203125\n",
      "Epoch: 5 / Batch: 44544/60000 / Cost: 0.72676 / Training Accuracy: 0.224609\n",
      "Epoch: 5 / Batch: 45056/60000 / Cost: 0.727132 / Training Accuracy: 0.236328\n",
      "Epoch: 5 / Batch: 45568/60000 / Cost: 0.726055 / Training Accuracy: 0.253906\n",
      "Epoch: 5 / Batch: 46080/60000 / Cost: 0.72544 / Training Accuracy: 0.25\n",
      "Epoch: 5 / Batch: 46592/60000 / Cost: 0.727023 / Training Accuracy: 0.224609\n",
      "Epoch: 5 / Batch: 47104/60000 / Cost: 0.728161 / Training Accuracy: 0.207031\n",
      "Epoch: 5 / Batch: 47616/60000 / Cost: 0.727014 / Training Accuracy: 0.21875\n",
      "Epoch: 5 / Batch: 48128/60000 / Cost: 0.725514 / Training Accuracy: 0.251953\n",
      "Epoch: 5 / Batch: 48640/60000 / Cost: 0.72599 / Training Accuracy: 0.253906\n",
      "Epoch: 5 / Batch: 49152/60000 / Cost: 0.726016 / Training Accuracy: 0.263672\n",
      "Epoch: 5 / Batch: 49664/60000 / Cost: 0.725205 / Training Accuracy: 0.275391\n",
      "Epoch: 5 / Batch: 50176/60000 / Cost: 0.726654 / Training Accuracy: 0.236328\n",
      "Epoch: 5 / Batch: 50688/60000 / Cost: 0.726245 / Training Accuracy: 0.244141\n",
      "Epoch: 5 / Batch: 51200/60000 / Cost: 0.724724 / Training Accuracy: 0.271484\n",
      "Epoch: 5 / Batch: 51712/60000 / Cost: 0.726366 / Training Accuracy: 0.224609\n",
      "Epoch: 5 / Batch: 52224/60000 / Cost: 0.726003 / Training Accuracy: 0.267578\n",
      "Epoch: 5 / Batch: 52736/60000 / Cost: 0.726166 / Training Accuracy: 0.246094\n",
      "Epoch: 5 / Batch: 53248/60000 / Cost: 0.723729 / Training Accuracy: 0.287109\n",
      "Epoch: 5 / Batch: 53760/60000 / Cost: 0.72598 / Training Accuracy: 0.244141\n",
      "Epoch: 5 / Batch: 54272/60000 / Cost: 0.72673 / Training Accuracy: 0.257813\n",
      "Epoch: 5 / Batch: 54784/60000 / Cost: 0.725839 / Training Accuracy: 0.226563\n",
      "Epoch: 5 / Batch: 55296/60000 / Cost: 0.727229 / Training Accuracy: 0.212891\n",
      "Epoch: 5 / Batch: 55808/60000 / Cost: 0.725505 / Training Accuracy: 0.248047\n",
      "Epoch: 5 / Batch: 56320/60000 / Cost: 0.724968 / Training Accuracy: 0.283203\n",
      "Epoch: 5 / Batch: 56832/60000 / Cost: 0.725128 / Training Accuracy: 0.259766\n",
      "Epoch: 5 / Batch: 57344/60000 / Cost: 0.725789 / Training Accuracy: 0.251953\n",
      "Epoch: 5 / Batch: 57856/60000 / Cost: 0.725833 / Training Accuracy: 0.234375\n",
      "Epoch: 5 / Batch: 58368/60000 / Cost: 0.728022 / Training Accuracy: 0.242188\n",
      "Epoch: 5 / Batch: 58880/60000 / Cost: 0.72561 / Training Accuracy: 0.257813\n",
      "Epoch: 5 / Batch: 59392/60000 / Cost: 0.724379 / Training Accuracy: 0.308594\n",
      "Epoch: 5 / Batch: 59904/60000 / Cost: 0.72229 / Training Accuracy: 0.333333\n",
      "Epoch: 6 / Batch: 0/60000 / Cost: 0.726054 / Training Accuracy: 0.265625\n",
      "Epoch: 6 / Batch: 512/60000 / Cost: 0.724969 / Training Accuracy: 0.253906\n",
      "Epoch: 6 / Batch: 1024/60000 / Cost: 0.725367 / Training Accuracy: 0.255859\n",
      "Epoch: 6 / Batch: 1536/60000 / Cost: 0.725931 / Training Accuracy: 0.21875\n",
      "Epoch: 6 / Batch: 2048/60000 / Cost: 0.726586 / Training Accuracy: 0.257813\n",
      "Epoch: 6 / Batch: 2560/60000 / Cost: 0.726884 / Training Accuracy: 0.236328\n",
      "Epoch: 6 / Batch: 3072/60000 / Cost: 0.725302 / Training Accuracy: 0.253906\n",
      "Epoch: 6 / Batch: 3584/60000 / Cost: 0.724994 / Training Accuracy: 0.277344\n",
      "Epoch: 6 / Batch: 4096/60000 / Cost: 0.724307 / Training Accuracy: 0.275391\n",
      "Epoch: 6 / Batch: 4608/60000 / Cost: 0.726873 / Training Accuracy: 0.232422\n",
      "Epoch: 6 / Batch: 5120/60000 / Cost: 0.726614 / Training Accuracy: 0.246094\n",
      "Epoch: 6 / Batch: 5632/60000 / Cost: 0.724507 / Training Accuracy: 0.259766\n",
      "Epoch: 6 / Batch: 6144/60000 / Cost: 0.72615 / Training Accuracy: 0.238281\n",
      "Epoch: 6 / Batch: 6656/60000 / Cost: 0.725685 / Training Accuracy: 0.242188\n",
      "Epoch: 6 / Batch: 7168/60000 / Cost: 0.726484 / Training Accuracy: 0.222656\n",
      "Epoch: 6 / Batch: 7680/60000 / Cost: 0.724482 / Training Accuracy: 0.283203\n",
      "Epoch: 6 / Batch: 8192/60000 / Cost: 0.727593 / Training Accuracy: 0.210938\n",
      "Epoch: 6 / Batch: 8704/60000 / Cost: 0.725475 / Training Accuracy: 0.261719\n",
      "Epoch: 6 / Batch: 9216/60000 / Cost: 0.723675 / Training Accuracy: 0.289063\n",
      "Epoch: 6 / Batch: 9728/60000 / Cost: 0.726757 / Training Accuracy: 0.236328\n",
      "Epoch: 6 / Batch: 10240/60000 / Cost: 0.728177 / Training Accuracy: 0.197266\n",
      "Epoch: 6 / Batch: 10752/60000 / Cost: 0.725019 / Training Accuracy: 0.277344\n",
      "Epoch: 6 / Batch: 11264/60000 / Cost: 0.725454 / Training Accuracy: 0.277344\n",
      "Epoch: 6 / Batch: 11776/60000 / Cost: 0.725948 / Training Accuracy: 0.246094\n",
      "Epoch: 6 / Batch: 12288/60000 / Cost: 0.726537 / Training Accuracy: 0.207031\n",
      "Epoch: 6 / Batch: 12800/60000 / Cost: 0.725698 / Training Accuracy: 0.240234\n",
      "Epoch: 6 / Batch: 13312/60000 / Cost: 0.728356 / Training Accuracy: 0.201172\n",
      "Epoch: 6 / Batch: 13824/60000 / Cost: 0.726523 / Training Accuracy: 0.246094\n",
      "Epoch: 6 / Batch: 14336/60000 / Cost: 0.724808 / Training Accuracy: 0.269531\n",
      "Epoch: 6 / Batch: 14848/60000 / Cost: 0.726653 / Training Accuracy: 0.234375\n",
      "Epoch: 6 / Batch: 15360/60000 / Cost: 0.725327 / Training Accuracy: 0.259766\n",
      "Epoch: 6 / Batch: 15872/60000 / Cost: 0.726086 / Training Accuracy: 0.25\n",
      "Epoch: 6 / Batch: 16384/60000 / Cost: 0.726538 / Training Accuracy: 0.248047\n",
      "Epoch: 6 / Batch: 16896/60000 / Cost: 0.725995 / Training Accuracy: 0.271484\n",
      "Epoch: 6 / Batch: 17408/60000 / Cost: 0.724969 / Training Accuracy: 0.251953\n",
      "Epoch: 6 / Batch: 17920/60000 / Cost: 0.726608 / Training Accuracy: 0.253906\n",
      "Epoch: 6 / Batch: 18432/60000 / Cost: 0.726134 / Training Accuracy: 0.271484\n",
      "Epoch: 6 / Batch: 18944/60000 / Cost: 0.724358 / Training Accuracy: 0.287109\n",
      "Epoch: 6 / Batch: 19456/60000 / Cost: 0.724911 / Training Accuracy: 0.253906\n",
      "Epoch: 6 / Batch: 19968/60000 / Cost: 0.727281 / Training Accuracy: 0.25\n",
      "Epoch: 6 / Batch: 20480/60000 / Cost: 0.726109 / Training Accuracy: 0.246094\n",
      "Epoch: 6 / Batch: 20992/60000 / Cost: 0.727255 / Training Accuracy: 0.242188\n",
      "Epoch: 6 / Batch: 21504/60000 / Cost: 0.724654 / Training Accuracy: 0.277344\n",
      "Epoch: 6 / Batch: 22016/60000 / Cost: 0.725824 / Training Accuracy: 0.228516\n",
      "Epoch: 6 / Batch: 22528/60000 / Cost: 0.724807 / Training Accuracy: 0.277344\n",
      "Epoch: 6 / Batch: 23040/60000 / Cost: 0.725225 / Training Accuracy: 0.261719\n",
      "Epoch: 6 / Batch: 23552/60000 / Cost: 0.726904 / Training Accuracy: 0.236328\n",
      "Epoch: 6 / Batch: 24064/60000 / Cost: 0.726565 / Training Accuracy: 0.25\n",
      "Epoch: 6 / Batch: 24576/60000 / Cost: 0.725307 / Training Accuracy: 0.253906\n",
      "Epoch: 6 / Batch: 25088/60000 / Cost: 0.725239 / Training Accuracy: 0.273438\n",
      "Epoch: 6 / Batch: 25600/60000 / Cost: 0.724748 / Training Accuracy: 0.277344\n",
      "Epoch: 6 / Batch: 26112/60000 / Cost: 0.724562 / Training Accuracy: 0.269531\n",
      "Epoch: 6 / Batch: 26624/60000 / Cost: 0.726315 / Training Accuracy: 0.242188\n",
      "Epoch: 6 / Batch: 27136/60000 / Cost: 0.7252 / Training Accuracy: 0.259766\n",
      "Epoch: 6 / Batch: 27648/60000 / Cost: 0.72756 / Training Accuracy: 0.226563\n",
      "Epoch: 6 / Batch: 28160/60000 / Cost: 0.725656 / Training Accuracy: 0.238281\n",
      "Epoch: 6 / Batch: 28672/60000 / Cost: 0.725847 / Training Accuracy: 0.244141\n",
      "Epoch: 6 / Batch: 29184/60000 / Cost: 0.724254 / Training Accuracy: 0.267578\n",
      "Epoch: 6 / Batch: 29696/60000 / Cost: 0.725026 / Training Accuracy: 0.257813\n",
      "Epoch: 6 / Batch: 30208/60000 / Cost: 0.724645 / Training Accuracy: 0.255859\n",
      "Epoch: 6 / Batch: 30720/60000 / Cost: 0.724895 / Training Accuracy: 0.259766\n",
      "Epoch: 6 / Batch: 31232/60000 / Cost: 0.723589 / Training Accuracy: 0.291016\n",
      "Epoch: 6 / Batch: 31744/60000 / Cost: 0.724422 / Training Accuracy: 0.265625\n",
      "Epoch: 6 / Batch: 32256/60000 / Cost: 0.725939 / Training Accuracy: 0.236328\n",
      "Epoch: 6 / Batch: 32768/60000 / Cost: 0.726263 / Training Accuracy: 0.261719\n",
      "Epoch: 6 / Batch: 33280/60000 / Cost: 0.725396 / Training Accuracy: 0.269531\n",
      "Epoch: 6 / Batch: 33792/60000 / Cost: 0.725719 / Training Accuracy: 0.25\n",
      "Epoch: 6 / Batch: 34304/60000 / Cost: 0.725 / Training Accuracy: 0.283203\n",
      "Epoch: 6 / Batch: 34816/60000 / Cost: 0.726174 / Training Accuracy: 0.246094\n",
      "Epoch: 6 / Batch: 35328/60000 / Cost: 0.726624 / Training Accuracy: 0.251953\n",
      "Epoch: 6 / Batch: 35840/60000 / Cost: 0.726583 / Training Accuracy: 0.232422\n",
      "Epoch: 6 / Batch: 36352/60000 / Cost: 0.725267 / Training Accuracy: 0.244141\n",
      "Epoch: 6 / Batch: 36864/60000 / Cost: 0.725291 / Training Accuracy: 0.287109\n",
      "Epoch: 6 / Batch: 37376/60000 / Cost: 0.722976 / Training Accuracy: 0.308594\n",
      "Epoch: 6 / Batch: 37888/60000 / Cost: 0.722845 / Training Accuracy: 0.279297\n",
      "Epoch: 6 / Batch: 38400/60000 / Cost: 0.725005 / Training Accuracy: 0.251953\n",
      "Epoch: 6 / Batch: 38912/60000 / Cost: 0.726533 / Training Accuracy: 0.242188\n",
      "Epoch: 6 / Batch: 39424/60000 / Cost: 0.725074 / Training Accuracy: 0.263672\n",
      "Epoch: 6 / Batch: 39936/60000 / Cost: 0.724648 / Training Accuracy: 0.285156\n",
      "Epoch: 6 / Batch: 40448/60000 / Cost: 0.724515 / Training Accuracy: 0.275391\n",
      "Epoch: 6 / Batch: 40960/60000 / Cost: 0.725629 / Training Accuracy: 0.248047\n",
      "Epoch: 6 / Batch: 41472/60000 / Cost: 0.724267 / Training Accuracy: 0.289063\n",
      "Epoch: 6 / Batch: 41984/60000 / Cost: 0.726212 / Training Accuracy: 0.251953\n",
      "Epoch: 6 / Batch: 42496/60000 / Cost: 0.725367 / Training Accuracy: 0.263672\n",
      "Epoch: 6 / Batch: 43008/60000 / Cost: 0.724299 / Training Accuracy: 0.265625\n",
      "Epoch: 6 / Batch: 43520/60000 / Cost: 0.726429 / Training Accuracy: 0.275391\n",
      "Epoch: 6 / Batch: 44032/60000 / Cost: 0.726099 / Training Accuracy: 0.253906\n",
      "Epoch: 6 / Batch: 44544/60000 / Cost: 0.725687 / Training Accuracy: 0.259766\n",
      "Epoch: 6 / Batch: 45056/60000 / Cost: 0.725992 / Training Accuracy: 0.240234\n",
      "Epoch: 6 / Batch: 45568/60000 / Cost: 0.725688 / Training Accuracy: 0.246094\n",
      "Epoch: 6 / Batch: 46080/60000 / Cost: 0.725262 / Training Accuracy: 0.283203\n",
      "Epoch: 6 / Batch: 46592/60000 / Cost: 0.725645 / Training Accuracy: 0.271484\n",
      "Epoch: 6 / Batch: 47104/60000 / Cost: 0.724391 / Training Accuracy: 0.251953\n",
      "Epoch: 6 / Batch: 47616/60000 / Cost: 0.723896 / Training Accuracy: 0.324219\n",
      "Epoch: 6 / Batch: 48128/60000 / Cost: 0.723882 / Training Accuracy: 0.289063\n",
      "Epoch: 6 / Batch: 48640/60000 / Cost: 0.727088 / Training Accuracy: 0.238281\n",
      "Epoch: 6 / Batch: 49152/60000 / Cost: 0.724962 / Training Accuracy: 0.279297\n",
      "Epoch: 6 / Batch: 49664/60000 / Cost: 0.724937 / Training Accuracy: 0.261719\n",
      "Epoch: 6 / Batch: 50176/60000 / Cost: 0.724679 / Training Accuracy: 0.261719\n",
      "Epoch: 6 / Batch: 50688/60000 / Cost: 0.725774 / Training Accuracy: 0.25\n",
      "Epoch: 6 / Batch: 51200/60000 / Cost: 0.724316 / Training Accuracy: 0.289063\n",
      "Epoch: 6 / Batch: 51712/60000 / Cost: 0.725942 / Training Accuracy: 0.267578\n",
      "Epoch: 6 / Batch: 52224/60000 / Cost: 0.723562 / Training Accuracy: 0.279297\n",
      "Epoch: 6 / Batch: 52736/60000 / Cost: 0.724252 / Training Accuracy: 0.294922\n",
      "Epoch: 6 / Batch: 53248/60000 / Cost: 0.725012 / Training Accuracy: 0.287109\n",
      "Epoch: 6 / Batch: 53760/60000 / Cost: 0.725325 / Training Accuracy: 0.292969\n",
      "Epoch: 6 / Batch: 54272/60000 / Cost: 0.725113 / Training Accuracy: 0.28125\n",
      "Epoch: 6 / Batch: 54784/60000 / Cost: 0.72443 / Training Accuracy: 0.291016\n",
      "Epoch: 6 / Batch: 55296/60000 / Cost: 0.725581 / Training Accuracy: 0.28125\n",
      "Epoch: 6 / Batch: 55808/60000 / Cost: 0.725118 / Training Accuracy: 0.261719\n",
      "Epoch: 6 / Batch: 56320/60000 / Cost: 0.725335 / Training Accuracy: 0.279297\n",
      "Epoch: 6 / Batch: 56832/60000 / Cost: 0.726784 / Training Accuracy: 0.248047\n",
      "Epoch: 6 / Batch: 57344/60000 / Cost: 0.724826 / Training Accuracy: 0.291016\n",
      "Epoch: 6 / Batch: 57856/60000 / Cost: 0.723991 / Training Accuracy: 0.306641\n",
      "Epoch: 6 / Batch: 58368/60000 / Cost: 0.724795 / Training Accuracy: 0.298828\n",
      "Epoch: 6 / Batch: 58880/60000 / Cost: 0.723135 / Training Accuracy: 0.316406\n",
      "Epoch: 6 / Batch: 59392/60000 / Cost: 0.725047 / Training Accuracy: 0.306641\n",
      "Epoch: 6 / Batch: 59904/60000 / Cost: 0.723537 / Training Accuracy: 0.302083\n",
      "Epoch: 7 / Batch: 0/60000 / Cost: 0.725012 / Training Accuracy: 0.285156\n",
      "Epoch: 7 / Batch: 512/60000 / Cost: 0.723344 / Training Accuracy: 0.34375\n",
      "Epoch: 7 / Batch: 1024/60000 / Cost: 0.724078 / Training Accuracy: 0.320313\n",
      "Epoch: 7 / Batch: 1536/60000 / Cost: 0.725658 / Training Accuracy: 0.255859\n",
      "Epoch: 7 / Batch: 2048/60000 / Cost: 0.725544 / Training Accuracy: 0.285156\n",
      "Epoch: 7 / Batch: 2560/60000 / Cost: 0.725108 / Training Accuracy: 0.3125\n",
      "Epoch: 7 / Batch: 3072/60000 / Cost: 0.724976 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 3584/60000 / Cost: 0.725279 / Training Accuracy: 0.296875\n",
      "Epoch: 7 / Batch: 4096/60000 / Cost: 0.727504 / Training Accuracy: 0.273438\n",
      "Epoch: 7 / Batch: 4608/60000 / Cost: 0.72258 / Training Accuracy: 0.333984\n",
      "Epoch: 7 / Batch: 5120/60000 / Cost: 0.724964 / Training Accuracy: 0.289063\n",
      "Epoch: 7 / Batch: 5632/60000 / Cost: 0.724564 / Training Accuracy: 0.304688\n",
      "Epoch: 7 / Batch: 6144/60000 / Cost: 0.724093 / Training Accuracy: 0.347656\n",
      "Epoch: 7 / Batch: 6656/60000 / Cost: 0.724511 / Training Accuracy: 0.279297\n",
      "Epoch: 7 / Batch: 7168/60000 / Cost: 0.725221 / Training Accuracy: 0.306641\n",
      "Epoch: 7 / Batch: 7680/60000 / Cost: 0.725744 / Training Accuracy: 0.269531\n",
      "Epoch: 7 / Batch: 8192/60000 / Cost: 0.725823 / Training Accuracy: 0.3125\n",
      "Epoch: 7 / Batch: 8704/60000 / Cost: 0.724509 / Training Accuracy: 0.316406\n",
      "Epoch: 7 / Batch: 9216/60000 / Cost: 0.725164 / Training Accuracy: 0.308594\n",
      "Epoch: 7 / Batch: 9728/60000 / Cost: 0.724219 / Training Accuracy: 0.294922\n",
      "Epoch: 7 / Batch: 10240/60000 / Cost: 0.725183 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 10752/60000 / Cost: 0.725189 / Training Accuracy: 0.289063\n",
      "Epoch: 7 / Batch: 11264/60000 / Cost: 0.723833 / Training Accuracy: 0.3125\n",
      "Epoch: 7 / Batch: 11776/60000 / Cost: 0.724233 / Training Accuracy: 0.285156\n",
      "Epoch: 7 / Batch: 12288/60000 / Cost: 0.725845 / Training Accuracy: 0.269531\n",
      "Epoch: 7 / Batch: 12800/60000 / Cost: 0.725181 / Training Accuracy: 0.28125\n",
      "Epoch: 7 / Batch: 13312/60000 / Cost: 0.724281 / Training Accuracy: 0.306641\n",
      "Epoch: 7 / Batch: 13824/60000 / Cost: 0.726139 / Training Accuracy: 0.253906\n",
      "Epoch: 7 / Batch: 14336/60000 / Cost: 0.724682 / Training Accuracy: 0.306641\n",
      "Epoch: 7 / Batch: 14848/60000 / Cost: 0.724291 / Training Accuracy: 0.318359\n",
      "Epoch: 7 / Batch: 15360/60000 / Cost: 0.725794 / Training Accuracy: 0.267578\n",
      "Epoch: 7 / Batch: 15872/60000 / Cost: 0.725684 / Training Accuracy: 0.292969\n",
      "Epoch: 7 / Batch: 16384/60000 / Cost: 0.72316 / Training Accuracy: 0.335938\n",
      "Epoch: 7 / Batch: 16896/60000 / Cost: 0.726039 / Training Accuracy: 0.275391\n",
      "Epoch: 7 / Batch: 17408/60000 / Cost: 0.724253 / Training Accuracy: 0.287109\n",
      "Epoch: 7 / Batch: 17920/60000 / Cost: 0.723219 / Training Accuracy: 0.332031\n",
      "Epoch: 7 / Batch: 18432/60000 / Cost: 0.723243 / Training Accuracy: 0.353516\n",
      "Epoch: 7 / Batch: 18944/60000 / Cost: 0.725855 / Training Accuracy: 0.267578\n",
      "Epoch: 7 / Batch: 19456/60000 / Cost: 0.725666 / Training Accuracy: 0.279297\n",
      "Epoch: 7 / Batch: 19968/60000 / Cost: 0.725047 / Training Accuracy: 0.294922\n",
      "Epoch: 7 / Batch: 20480/60000 / Cost: 0.72093 / Training Accuracy: 0.363281\n",
      "Epoch: 7 / Batch: 20992/60000 / Cost: 0.723864 / Training Accuracy: 0.318359\n",
      "Epoch: 7 / Batch: 21504/60000 / Cost: 0.725949 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 22016/60000 / Cost: 0.725546 / Training Accuracy: 0.271484\n",
      "Epoch: 7 / Batch: 22528/60000 / Cost: 0.723794 / Training Accuracy: 0.330078\n",
      "Epoch: 7 / Batch: 23040/60000 / Cost: 0.725129 / Training Accuracy: 0.298828\n",
      "Epoch: 7 / Batch: 23552/60000 / Cost: 0.727391 / Training Accuracy: 0.259766\n",
      "Epoch: 7 / Batch: 24064/60000 / Cost: 0.723823 / Training Accuracy: 0.326172\n",
      "Epoch: 7 / Batch: 24576/60000 / Cost: 0.724571 / Training Accuracy: 0.322266\n",
      "Epoch: 7 / Batch: 25088/60000 / Cost: 0.724067 / Training Accuracy: 0.3125\n",
      "Epoch: 7 / Batch: 25600/60000 / Cost: 0.724125 / Training Accuracy: 0.298828\n",
      "Epoch: 7 / Batch: 26112/60000 / Cost: 0.724372 / Training Accuracy: 0.306641\n",
      "Epoch: 7 / Batch: 26624/60000 / Cost: 0.724987 / Training Accuracy: 0.308594\n",
      "Epoch: 7 / Batch: 27136/60000 / Cost: 0.723023 / Training Accuracy: 0.333984\n",
      "Epoch: 7 / Batch: 27648/60000 / Cost: 0.726398 / Training Accuracy: 0.298828\n",
      "Epoch: 7 / Batch: 28160/60000 / Cost: 0.726609 / Training Accuracy: 0.289063\n",
      "Epoch: 7 / Batch: 28672/60000 / Cost: 0.724236 / Training Accuracy: 0.320313\n",
      "Epoch: 7 / Batch: 29184/60000 / Cost: 0.723418 / Training Accuracy: 0.34375\n",
      "Epoch: 7 / Batch: 29696/60000 / Cost: 0.725096 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 30208/60000 / Cost: 0.724845 / Training Accuracy: 0.289063\n",
      "Epoch: 7 / Batch: 30720/60000 / Cost: 0.724577 / Training Accuracy: 0.300781\n",
      "Epoch: 7 / Batch: 31232/60000 / Cost: 0.724519 / Training Accuracy: 0.326172\n",
      "Epoch: 7 / Batch: 31744/60000 / Cost: 0.724378 / Training Accuracy: 0.306641\n",
      "Epoch: 7 / Batch: 32256/60000 / Cost: 0.723808 / Training Accuracy: 0.337891\n",
      "Epoch: 7 / Batch: 32768/60000 / Cost: 0.723538 / Training Accuracy: 0.316406\n",
      "Epoch: 7 / Batch: 33280/60000 / Cost: 0.723251 / Training Accuracy: 0.330078\n",
      "Epoch: 7 / Batch: 33792/60000 / Cost: 0.725291 / Training Accuracy: 0.308594\n",
      "Epoch: 7 / Batch: 34304/60000 / Cost: 0.722912 / Training Accuracy: 0.363281\n",
      "Epoch: 7 / Batch: 34816/60000 / Cost: 0.724336 / Training Accuracy: 0.324219\n",
      "Epoch: 7 / Batch: 35328/60000 / Cost: 0.723645 / Training Accuracy: 0.324219\n",
      "Epoch: 7 / Batch: 35840/60000 / Cost: 0.725344 / Training Accuracy: 0.291016\n",
      "Epoch: 7 / Batch: 36352/60000 / Cost: 0.725128 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 36864/60000 / Cost: 0.724115 / Training Accuracy: 0.308594\n",
      "Epoch: 7 / Batch: 37376/60000 / Cost: 0.72418 / Training Accuracy: 0.304688\n",
      "Epoch: 7 / Batch: 37888/60000 / Cost: 0.724466 / Training Accuracy: 0.308594\n",
      "Epoch: 7 / Batch: 38400/60000 / Cost: 0.72518 / Training Accuracy: 0.320313\n",
      "Epoch: 7 / Batch: 38912/60000 / Cost: 0.722952 / Training Accuracy: 0.308594\n",
      "Epoch: 7 / Batch: 39424/60000 / Cost: 0.722541 / Training Accuracy: 0.353516\n",
      "Epoch: 7 / Batch: 39936/60000 / Cost: 0.722311 / Training Accuracy: 0.365234\n",
      "Epoch: 7 / Batch: 40448/60000 / Cost: 0.724539 / Training Accuracy: 0.300781\n",
      "Epoch: 7 / Batch: 40960/60000 / Cost: 0.723728 / Training Accuracy: 0.339844\n",
      "Epoch: 7 / Batch: 41472/60000 / Cost: 0.724207 / Training Accuracy: 0.3125\n",
      "Epoch: 7 / Batch: 41984/60000 / Cost: 0.724695 / Training Accuracy: 0.292969\n",
      "Epoch: 7 / Batch: 42496/60000 / Cost: 0.722821 / Training Accuracy: 0.322266\n",
      "Epoch: 7 / Batch: 43008/60000 / Cost: 0.723282 / Training Accuracy: 0.304688\n",
      "Epoch: 7 / Batch: 43520/60000 / Cost: 0.723527 / Training Accuracy: 0.302734\n",
      "Epoch: 7 / Batch: 44032/60000 / Cost: 0.723999 / Training Accuracy: 0.291016\n",
      "Epoch: 7 / Batch: 44544/60000 / Cost: 0.724475 / Training Accuracy: 0.316406\n",
      "Epoch: 7 / Batch: 45056/60000 / Cost: 0.724038 / Training Accuracy: 0.320313\n",
      "Epoch: 7 / Batch: 45568/60000 / Cost: 0.724458 / Training Accuracy: 0.287109\n",
      "Epoch: 7 / Batch: 46080/60000 / Cost: 0.724625 / Training Accuracy: 0.302734\n",
      "Epoch: 7 / Batch: 46592/60000 / Cost: 0.724054 / Training Accuracy: 0.318359\n",
      "Epoch: 7 / Batch: 47104/60000 / Cost: 0.724426 / Training Accuracy: 0.289063\n",
      "Epoch: 7 / Batch: 47616/60000 / Cost: 0.723763 / Training Accuracy: 0.292969\n",
      "Epoch: 7 / Batch: 48128/60000 / Cost: 0.722349 / Training Accuracy: 0.328125\n",
      "Epoch: 7 / Batch: 48640/60000 / Cost: 0.723191 / Training Accuracy: 0.318359\n",
      "Epoch: 7 / Batch: 49152/60000 / Cost: 0.722319 / Training Accuracy: 0.320313\n",
      "Epoch: 7 / Batch: 49664/60000 / Cost: 0.726304 / Training Accuracy: 0.25\n",
      "Epoch: 7 / Batch: 50176/60000 / Cost: 0.723265 / Training Accuracy: 0.287109\n",
      "Epoch: 7 / Batch: 50688/60000 / Cost: 0.722785 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 51200/60000 / Cost: 0.723854 / Training Accuracy: 0.28125\n",
      "Epoch: 7 / Batch: 51712/60000 / Cost: 0.722169 / Training Accuracy: 0.335938\n",
      "Epoch: 7 / Batch: 52224/60000 / Cost: 0.725077 / Training Accuracy: 0.269531\n",
      "Epoch: 7 / Batch: 52736/60000 / Cost: 0.722981 / Training Accuracy: 0.310547\n",
      "Epoch: 7 / Batch: 53248/60000 / Cost: 0.725561 / Training Accuracy: 0.273438\n",
      "Epoch: 7 / Batch: 53760/60000 / Cost: 0.722976 / Training Accuracy: 0.330078\n",
      "Epoch: 7 / Batch: 54272/60000 / Cost: 0.724573 / Training Accuracy: 0.275391\n",
      "Epoch: 7 / Batch: 54784/60000 / Cost: 0.724907 / Training Accuracy: 0.277344\n",
      "Epoch: 7 / Batch: 55296/60000 / Cost: 0.723727 / Training Accuracy: 0.300781\n",
      "Epoch: 7 / Batch: 55808/60000 / Cost: 0.723233 / Training Accuracy: 0.320313\n",
      "Epoch: 7 / Batch: 56320/60000 / Cost: 0.724622 / Training Accuracy: 0.296875\n",
      "Epoch: 7 / Batch: 56832/60000 / Cost: 0.722655 / Training Accuracy: 0.316406\n",
      "Epoch: 7 / Batch: 57344/60000 / Cost: 0.724042 / Training Accuracy: 0.285156\n",
      "Epoch: 7 / Batch: 57856/60000 / Cost: 0.725056 / Training Accuracy: 0.269531\n",
      "Epoch: 7 / Batch: 58368/60000 / Cost: 0.723714 / Training Accuracy: 0.318359\n",
      "Epoch: 7 / Batch: 58880/60000 / Cost: 0.724012 / Training Accuracy: 0.3125\n",
      "Epoch: 7 / Batch: 59392/60000 / Cost: 0.723767 / Training Accuracy: 0.294922\n",
      "Epoch: 7 / Batch: 59904/60000 / Cost: 0.728002 / Training Accuracy: 0.270833\n",
      "Epoch: 8 / Batch: 0/60000 / Cost: 0.722649 / Training Accuracy: 0.324219\n",
      "Epoch: 8 / Batch: 512/60000 / Cost: 0.724061 / Training Accuracy: 0.302734\n",
      "Epoch: 8 / Batch: 1024/60000 / Cost: 0.722231 / Training Accuracy: 0.320313\n",
      "Epoch: 8 / Batch: 1536/60000 / Cost: 0.724962 / Training Accuracy: 0.255859\n",
      "Epoch: 8 / Batch: 2048/60000 / Cost: 0.724403 / Training Accuracy: 0.28125\n",
      "Epoch: 8 / Batch: 2560/60000 / Cost: 0.724009 / Training Accuracy: 0.322266\n",
      "Epoch: 8 / Batch: 3072/60000 / Cost: 0.725685 / Training Accuracy: 0.28125\n",
      "Epoch: 8 / Batch: 3584/60000 / Cost: 0.723088 / Training Accuracy: 0.3125\n",
      "Epoch: 8 / Batch: 4096/60000 / Cost: 0.723804 / Training Accuracy: 0.3125\n",
      "Epoch: 8 / Batch: 4608/60000 / Cost: 0.723649 / Training Accuracy: 0.320313\n",
      "Epoch: 8 / Batch: 5120/60000 / Cost: 0.724192 / Training Accuracy: 0.292969\n",
      "Epoch: 8 / Batch: 5632/60000 / Cost: 0.724987 / Training Accuracy: 0.28125\n",
      "Epoch: 8 / Batch: 6144/60000 / Cost: 0.72386 / Training Accuracy: 0.298828\n",
      "Epoch: 8 / Batch: 6656/60000 / Cost: 0.724929 / Training Accuracy: 0.285156\n",
      "Epoch: 8 / Batch: 7168/60000 / Cost: 0.722933 / Training Accuracy: 0.337891\n",
      "Epoch: 8 / Batch: 7680/60000 / Cost: 0.723601 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 8192/60000 / Cost: 0.721444 / Training Accuracy: 0.357422\n",
      "Epoch: 8 / Batch: 8704/60000 / Cost: 0.720798 / Training Accuracy: 0.363281\n",
      "Epoch: 8 / Batch: 9216/60000 / Cost: 0.723845 / Training Accuracy: 0.326172\n",
      "Epoch: 8 / Batch: 9728/60000 / Cost: 0.723829 / Training Accuracy: 0.306641\n",
      "Epoch: 8 / Batch: 10240/60000 / Cost: 0.723041 / Training Accuracy: 0.324219\n",
      "Epoch: 8 / Batch: 10752/60000 / Cost: 0.723908 / Training Accuracy: 0.326172\n",
      "Epoch: 8 / Batch: 11264/60000 / Cost: 0.726022 / Training Accuracy: 0.267578\n",
      "Epoch: 8 / Batch: 11776/60000 / Cost: 0.722365 / Training Accuracy: 0.322266\n",
      "Epoch: 8 / Batch: 12288/60000 / Cost: 0.723667 / Training Accuracy: 0.304688\n",
      "Epoch: 8 / Batch: 12800/60000 / Cost: 0.723047 / Training Accuracy: 0.337891\n",
      "Epoch: 8 / Batch: 13312/60000 / Cost: 0.724537 / Training Accuracy: 0.3125\n",
      "Epoch: 8 / Batch: 13824/60000 / Cost: 0.723478 / Training Accuracy: 0.320313\n",
      "Epoch: 8 / Batch: 14336/60000 / Cost: 0.725226 / Training Accuracy: 0.296875\n",
      "Epoch: 8 / Batch: 14848/60000 / Cost: 0.723928 / Training Accuracy: 0.300781\n",
      "Epoch: 8 / Batch: 15360/60000 / Cost: 0.724102 / Training Accuracy: 0.314453\n",
      "Epoch: 8 / Batch: 15872/60000 / Cost: 0.722054 / Training Accuracy: 0.349609\n",
      "Epoch: 8 / Batch: 16384/60000 / Cost: 0.723753 / Training Accuracy: 0.328125\n",
      "Epoch: 8 / Batch: 16896/60000 / Cost: 0.724057 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 17408/60000 / Cost: 0.722867 / Training Accuracy: 0.326172\n",
      "Epoch: 8 / Batch: 17920/60000 / Cost: 0.722076 / Training Accuracy: 0.34375\n",
      "Epoch: 8 / Batch: 18432/60000 / Cost: 0.724288 / Training Accuracy: 0.330078\n",
      "Epoch: 8 / Batch: 18944/60000 / Cost: 0.724983 / Training Accuracy: 0.296875\n",
      "Epoch: 8 / Batch: 19456/60000 / Cost: 0.723145 / Training Accuracy: 0.330078\n",
      "Epoch: 8 / Batch: 19968/60000 / Cost: 0.723029 / Training Accuracy: 0.335938\n",
      "Epoch: 8 / Batch: 20480/60000 / Cost: 0.724521 / Training Accuracy: 0.335938\n",
      "Epoch: 8 / Batch: 20992/60000 / Cost: 0.725237 / Training Accuracy: 0.285156\n",
      "Epoch: 8 / Batch: 21504/60000 / Cost: 0.724731 / Training Accuracy: 0.296875\n",
      "Epoch: 8 / Batch: 22016/60000 / Cost: 0.724371 / Training Accuracy: 0.316406\n",
      "Epoch: 8 / Batch: 22528/60000 / Cost: 0.72439 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 23040/60000 / Cost: 0.723676 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 23552/60000 / Cost: 0.724027 / Training Accuracy: 0.310547\n",
      "Epoch: 8 / Batch: 24064/60000 / Cost: 0.725254 / Training Accuracy: 0.292969\n",
      "Epoch: 8 / Batch: 24576/60000 / Cost: 0.72313 / Training Accuracy: 0.304688\n",
      "Epoch: 8 / Batch: 25088/60000 / Cost: 0.722175 / Training Accuracy: 0.335938\n",
      "Epoch: 8 / Batch: 25600/60000 / Cost: 0.723912 / Training Accuracy: 0.292969\n",
      "Epoch: 8 / Batch: 26112/60000 / Cost: 0.723859 / Training Accuracy: 0.324219\n",
      "Epoch: 8 / Batch: 26624/60000 / Cost: 0.723451 / Training Accuracy: 0.320313\n",
      "Epoch: 8 / Batch: 27136/60000 / Cost: 0.72488 / Training Accuracy: 0.324219\n",
      "Epoch: 8 / Batch: 27648/60000 / Cost: 0.720137 / Training Accuracy: 0.363281\n",
      "Epoch: 8 / Batch: 28160/60000 / Cost: 0.721024 / Training Accuracy: 0.333984\n",
      "Epoch: 8 / Batch: 28672/60000 / Cost: 0.724572 / Training Accuracy: 0.298828\n",
      "Epoch: 8 / Batch: 29184/60000 / Cost: 0.722866 / Training Accuracy: 0.330078\n",
      "Epoch: 8 / Batch: 29696/60000 / Cost: 0.722647 / Training Accuracy: 0.349609\n",
      "Epoch: 8 / Batch: 30208/60000 / Cost: 0.722494 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 30720/60000 / Cost: 0.722133 / Training Accuracy: 0.371094\n",
      "Epoch: 8 / Batch: 31232/60000 / Cost: 0.723855 / Training Accuracy: 0.294922\n",
      "Epoch: 8 / Batch: 31744/60000 / Cost: 0.723284 / Training Accuracy: 0.328125\n",
      "Epoch: 8 / Batch: 32256/60000 / Cost: 0.722039 / Training Accuracy: 0.326172\n",
      "Epoch: 8 / Batch: 32768/60000 / Cost: 0.724146 / Training Accuracy: 0.292969\n",
      "Epoch: 8 / Batch: 33280/60000 / Cost: 0.723731 / Training Accuracy: 0.328125\n",
      "Epoch: 8 / Batch: 33792/60000 / Cost: 0.724129 / Training Accuracy: 0.333984\n",
      "Epoch: 8 / Batch: 34304/60000 / Cost: 0.723307 / Training Accuracy: 0.345703\n",
      "Epoch: 8 / Batch: 34816/60000 / Cost: 0.723931 / Training Accuracy: 0.328125\n",
      "Epoch: 8 / Batch: 35328/60000 / Cost: 0.723342 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 35840/60000 / Cost: 0.72088 / Training Accuracy: 0.375\n",
      "Epoch: 8 / Batch: 36352/60000 / Cost: 0.724096 / Training Accuracy: 0.337891\n",
      "Epoch: 8 / Batch: 36864/60000 / Cost: 0.722331 / Training Accuracy: 0.34375\n",
      "Epoch: 8 / Batch: 37376/60000 / Cost: 0.722389 / Training Accuracy: 0.357422\n",
      "Epoch: 8 / Batch: 37888/60000 / Cost: 0.722847 / Training Accuracy: 0.349609\n",
      "Epoch: 8 / Batch: 38400/60000 / Cost: 0.722976 / Training Accuracy: 0.339844\n",
      "Epoch: 8 / Batch: 38912/60000 / Cost: 0.723197 / Training Accuracy: 0.335938\n",
      "Epoch: 8 / Batch: 39424/60000 / Cost: 0.723187 / Training Accuracy: 0.345703\n",
      "Epoch: 8 / Batch: 39936/60000 / Cost: 0.723642 / Training Accuracy: 0.310547\n",
      "Epoch: 8 / Batch: 40448/60000 / Cost: 0.722541 / Training Accuracy: 0.333984\n",
      "Epoch: 8 / Batch: 40960/60000 / Cost: 0.724282 / Training Accuracy: 0.296875\n",
      "Epoch: 8 / Batch: 41472/60000 / Cost: 0.722198 / Training Accuracy: 0.333984\n",
      "Epoch: 8 / Batch: 41984/60000 / Cost: 0.723484 / Training Accuracy: 0.332031\n",
      "Epoch: 8 / Batch: 42496/60000 / Cost: 0.723016 / Training Accuracy: 0.333984\n",
      "Epoch: 8 / Batch: 43008/60000 / Cost: 0.721696 / Training Accuracy: 0.339844\n",
      "Epoch: 8 / Batch: 43520/60000 / Cost: 0.724441 / Training Accuracy: 0.304688\n",
      "Epoch: 8 / Batch: 44032/60000 / Cost: 0.721346 / Training Accuracy: 0.330078\n",
      "Epoch: 8 / Batch: 44544/60000 / Cost: 0.723287 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 45056/60000 / Cost: 0.722556 / Training Accuracy: 0.318359\n",
      "Epoch: 8 / Batch: 45568/60000 / Cost: 0.72402 / Training Accuracy: 0.292969\n",
      "Epoch: 8 / Batch: 46080/60000 / Cost: 0.723578 / Training Accuracy: 0.289063\n",
      "Epoch: 8 / Batch: 46592/60000 / Cost: 0.721049 / Training Accuracy: 0.339844\n",
      "Epoch: 8 / Batch: 47104/60000 / Cost: 0.722122 / Training Accuracy: 0.34375\n",
      "Epoch: 8 / Batch: 47616/60000 / Cost: 0.722945 / Training Accuracy: 0.337891\n",
      "Epoch: 8 / Batch: 48128/60000 / Cost: 0.722708 / Training Accuracy: 0.3125\n",
      "Epoch: 8 / Batch: 48640/60000 / Cost: 0.722996 / Training Accuracy: 0.316406\n",
      "Epoch: 8 / Batch: 49152/60000 / Cost: 0.725338 / Training Accuracy: 0.287109\n",
      "Epoch: 8 / Batch: 49664/60000 / Cost: 0.72408 / Training Accuracy: 0.339844\n",
      "Epoch: 8 / Batch: 50176/60000 / Cost: 0.721812 / Training Accuracy: 0.34375\n",
      "Epoch: 8 / Batch: 50688/60000 / Cost: 0.722897 / Training Accuracy: 0.304688\n",
      "Epoch: 8 / Batch: 51200/60000 / Cost: 0.723302 / Training Accuracy: 0.335938\n",
      "Epoch: 8 / Batch: 51712/60000 / Cost: 0.723568 / Training Accuracy: 0.306641\n",
      "Epoch: 8 / Batch: 52224/60000 / Cost: 0.723135 / Training Accuracy: 0.347656\n",
      "Epoch: 8 / Batch: 52736/60000 / Cost: 0.722657 / Training Accuracy: 0.337891\n",
      "Epoch: 8 / Batch: 53248/60000 / Cost: 0.721942 / Training Accuracy: 0.324219\n",
      "Epoch: 8 / Batch: 53760/60000 / Cost: 0.722935 / Training Accuracy: 0.335938\n",
      "Epoch: 8 / Batch: 54272/60000 / Cost: 0.722512 / Training Accuracy: 0.306641\n",
      "Epoch: 8 / Batch: 54784/60000 / Cost: 0.723616 / Training Accuracy: 0.330078\n",
      "Epoch: 8 / Batch: 55296/60000 / Cost: 0.723025 / Training Accuracy: 0.330078\n",
      "Epoch: 8 / Batch: 55808/60000 / Cost: 0.723064 / Training Accuracy: 0.353516\n",
      "Epoch: 8 / Batch: 56320/60000 / Cost: 0.722789 / Training Accuracy: 0.34375\n",
      "Epoch: 8 / Batch: 56832/60000 / Cost: 0.721908 / Training Accuracy: 0.332031\n",
      "Epoch: 8 / Batch: 57344/60000 / Cost: 0.724002 / Training Accuracy: 0.326172\n",
      "Epoch: 8 / Batch: 57856/60000 / Cost: 0.722805 / Training Accuracy: 0.341797\n",
      "Epoch: 8 / Batch: 58368/60000 / Cost: 0.721979 / Training Accuracy: 0.345703\n",
      "Epoch: 8 / Batch: 58880/60000 / Cost: 0.723799 / Training Accuracy: 0.320313\n",
      "Epoch: 8 / Batch: 59392/60000 / Cost: 0.724296 / Training Accuracy: 0.296875\n",
      "Epoch: 8 / Batch: 59904/60000 / Cost: 0.721046 / Training Accuracy: 0.385417\n",
      "Epoch: 9 / Batch: 0/60000 / Cost: 0.722589 / Training Accuracy: 0.349609\n",
      "Epoch: 9 / Batch: 512/60000 / Cost: 0.723404 / Training Accuracy: 0.310547\n",
      "Epoch: 9 / Batch: 1024/60000 / Cost: 0.722504 / Training Accuracy: 0.353516\n",
      "Epoch: 9 / Batch: 1536/60000 / Cost: 0.723459 / Training Accuracy: 0.324219\n",
      "Epoch: 9 / Batch: 2048/60000 / Cost: 0.721946 / Training Accuracy: 0.337891\n",
      "Epoch: 9 / Batch: 2560/60000 / Cost: 0.723912 / Training Accuracy: 0.304688\n",
      "Epoch: 9 / Batch: 3072/60000 / Cost: 0.723314 / Training Accuracy: 0.306641\n",
      "Epoch: 9 / Batch: 3584/60000 / Cost: 0.721193 / Training Accuracy: 0.365234\n",
      "Epoch: 9 / Batch: 4096/60000 / Cost: 0.723511 / Training Accuracy: 0.304688\n",
      "Epoch: 9 / Batch: 4608/60000 / Cost: 0.722058 / Training Accuracy: 0.353516\n",
      "Epoch: 9 / Batch: 5120/60000 / Cost: 0.723615 / Training Accuracy: 0.335938\n",
      "Epoch: 9 / Batch: 5632/60000 / Cost: 0.722776 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 6144/60000 / Cost: 0.722521 / Training Accuracy: 0.308594\n",
      "Epoch: 9 / Batch: 6656/60000 / Cost: 0.72213 / Training Accuracy: 0.337891\n",
      "Epoch: 9 / Batch: 7168/60000 / Cost: 0.72058 / Training Accuracy: 0.373047\n",
      "Epoch: 9 / Batch: 7680/60000 / Cost: 0.723956 / Training Accuracy: 0.322266\n",
      "Epoch: 9 / Batch: 8192/60000 / Cost: 0.724604 / Training Accuracy: 0.292969\n",
      "Epoch: 9 / Batch: 8704/60000 / Cost: 0.721557 / Training Accuracy: 0.351563\n",
      "Epoch: 9 / Batch: 9216/60000 / Cost: 0.720963 / Training Accuracy: 0.386719\n",
      "Epoch: 9 / Batch: 9728/60000 / Cost: 0.72324 / Training Accuracy: 0.328125\n",
      "Epoch: 9 / Batch: 10240/60000 / Cost: 0.724509 / Training Accuracy: 0.306641\n",
      "Epoch: 9 / Batch: 10752/60000 / Cost: 0.723049 / Training Accuracy: 0.326172\n",
      "Epoch: 9 / Batch: 11264/60000 / Cost: 0.721734 / Training Accuracy: 0.355469\n",
      "Epoch: 9 / Batch: 11776/60000 / Cost: 0.720978 / Training Accuracy: 0.369141\n",
      "Epoch: 9 / Batch: 12288/60000 / Cost: 0.721926 / Training Accuracy: 0.333984\n",
      "Epoch: 9 / Batch: 12800/60000 / Cost: 0.72107 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 13312/60000 / Cost: 0.723975 / Training Accuracy: 0.320313\n",
      "Epoch: 9 / Batch: 13824/60000 / Cost: 0.721514 / Training Accuracy: 0.357422\n",
      "Epoch: 9 / Batch: 14336/60000 / Cost: 0.722934 / Training Accuracy: 0.355469\n",
      "Epoch: 9 / Batch: 14848/60000 / Cost: 0.72246 / Training Accuracy: 0.349609\n",
      "Epoch: 9 / Batch: 15360/60000 / Cost: 0.721755 / Training Accuracy: 0.355469\n",
      "Epoch: 9 / Batch: 15872/60000 / Cost: 0.722054 / Training Accuracy: 0.339844\n",
      "Epoch: 9 / Batch: 16384/60000 / Cost: 0.722565 / Training Accuracy: 0.341797\n",
      "Epoch: 9 / Batch: 16896/60000 / Cost: 0.721242 / Training Accuracy: 0.365234\n",
      "Epoch: 9 / Batch: 17408/60000 / Cost: 0.721793 / Training Accuracy: 0.339844\n",
      "Epoch: 9 / Batch: 17920/60000 / Cost: 0.724161 / Training Accuracy: 0.298828\n",
      "Epoch: 9 / Batch: 18432/60000 / Cost: 0.725285 / Training Accuracy: 0.285156\n",
      "Epoch: 9 / Batch: 18944/60000 / Cost: 0.721802 / Training Accuracy: 0.337891\n",
      "Epoch: 9 / Batch: 19456/60000 / Cost: 0.721984 / Training Accuracy: 0.339844\n",
      "Epoch: 9 / Batch: 19968/60000 / Cost: 0.723019 / Training Accuracy: 0.322266\n",
      "Epoch: 9 / Batch: 20480/60000 / Cost: 0.72258 / Training Accuracy: 0.337891\n",
      "Epoch: 9 / Batch: 20992/60000 / Cost: 0.722002 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 21504/60000 / Cost: 0.723478 / Training Accuracy: 0.318359\n",
      "Epoch: 9 / Batch: 22016/60000 / Cost: 0.722324 / Training Accuracy: 0.339844\n",
      "Epoch: 9 / Batch: 22528/60000 / Cost: 0.722515 / Training Accuracy: 0.351563\n",
      "Epoch: 9 / Batch: 23040/60000 / Cost: 0.723061 / Training Accuracy: 0.328125\n",
      "Epoch: 9 / Batch: 23552/60000 / Cost: 0.723685 / Training Accuracy: 0.310547\n",
      "Epoch: 9 / Batch: 24064/60000 / Cost: 0.721862 / Training Accuracy: 0.375\n",
      "Epoch: 9 / Batch: 24576/60000 / Cost: 0.722558 / Training Accuracy: 0.357422\n",
      "Epoch: 9 / Batch: 25088/60000 / Cost: 0.72321 / Training Accuracy: 0.3125\n",
      "Epoch: 9 / Batch: 25600/60000 / Cost: 0.723456 / Training Accuracy: 0.316406\n",
      "Epoch: 9 / Batch: 26112/60000 / Cost: 0.722139 / Training Accuracy: 0.361328\n",
      "Epoch: 9 / Batch: 26624/60000 / Cost: 0.720844 / Training Accuracy: 0.375\n",
      "Epoch: 9 / Batch: 27136/60000 / Cost: 0.721699 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 27648/60000 / Cost: 0.720742 / Training Accuracy: 0.376953\n",
      "Epoch: 9 / Batch: 28160/60000 / Cost: 0.721953 / Training Accuracy: 0.347656\n",
      "Epoch: 9 / Batch: 28672/60000 / Cost: 0.720687 / Training Accuracy: 0.355469\n",
      "Epoch: 9 / Batch: 29184/60000 / Cost: 0.721842 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 29696/60000 / Cost: 0.720817 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 30208/60000 / Cost: 0.722394 / Training Accuracy: 0.361328\n",
      "Epoch: 9 / Batch: 30720/60000 / Cost: 0.721754 / Training Accuracy: 0.357422\n",
      "Epoch: 9 / Batch: 31232/60000 / Cost: 0.722808 / Training Accuracy: 0.326172\n",
      "Epoch: 9 / Batch: 31744/60000 / Cost: 0.722965 / Training Accuracy: 0.322266\n",
      "Epoch: 9 / Batch: 32256/60000 / Cost: 0.720936 / Training Accuracy: 0.365234\n",
      "Epoch: 9 / Batch: 32768/60000 / Cost: 0.721166 / Training Accuracy: 0.353516\n",
      "Epoch: 9 / Batch: 33280/60000 / Cost: 0.721656 / Training Accuracy: 0.361328\n",
      "Epoch: 9 / Batch: 33792/60000 / Cost: 0.722468 / Training Accuracy: 0.3125\n",
      "Epoch: 9 / Batch: 34304/60000 / Cost: 0.721987 / Training Accuracy: 0.335938\n",
      "Epoch: 9 / Batch: 34816/60000 / Cost: 0.722099 / Training Accuracy: 0.359375\n",
      "Epoch: 9 / Batch: 35328/60000 / Cost: 0.722759 / Training Accuracy: 0.330078\n",
      "Epoch: 9 / Batch: 35840/60000 / Cost: 0.723368 / Training Accuracy: 0.318359\n",
      "Epoch: 9 / Batch: 36352/60000 / Cost: 0.721465 / Training Accuracy: 0.328125\n",
      "Epoch: 9 / Batch: 36864/60000 / Cost: 0.721105 / Training Accuracy: 0.347656\n",
      "Epoch: 9 / Batch: 37376/60000 / Cost: 0.721174 / Training Accuracy: 0.347656\n",
      "Epoch: 9 / Batch: 37888/60000 / Cost: 0.723056 / Training Accuracy: 0.306641\n",
      "Epoch: 9 / Batch: 38400/60000 / Cost: 0.723827 / Training Accuracy: 0.328125\n",
      "Epoch: 9 / Batch: 38912/60000 / Cost: 0.722634 / Training Accuracy: 0.339844\n",
      "Epoch: 9 / Batch: 39424/60000 / Cost: 0.720672 / Training Accuracy: 0.359375\n",
      "Epoch: 9 / Batch: 39936/60000 / Cost: 0.721338 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 40448/60000 / Cost: 0.723286 / Training Accuracy: 0.3125\n",
      "Epoch: 9 / Batch: 40960/60000 / Cost: 0.724235 / Training Accuracy: 0.306641\n",
      "Epoch: 9 / Batch: 41472/60000 / Cost: 0.723021 / Training Accuracy: 0.326172\n",
      "Epoch: 9 / Batch: 41984/60000 / Cost: 0.722133 / Training Accuracy: 0.328125\n",
      "Epoch: 9 / Batch: 42496/60000 / Cost: 0.723334 / Training Accuracy: 0.314453\n",
      "Epoch: 9 / Batch: 43008/60000 / Cost: 0.72354 / Training Accuracy: 0.324219\n",
      "Epoch: 9 / Batch: 43520/60000 / Cost: 0.720682 / Training Accuracy: 0.394531\n",
      "Epoch: 9 / Batch: 44032/60000 / Cost: 0.720973 / Training Accuracy: 0.373047\n",
      "Epoch: 9 / Batch: 44544/60000 / Cost: 0.721876 / Training Accuracy: 0.34375\n",
      "Epoch: 9 / Batch: 45056/60000 / Cost: 0.721976 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 45568/60000 / Cost: 0.719889 / Training Accuracy: 0.380859\n",
      "Epoch: 9 / Batch: 46080/60000 / Cost: 0.721138 / Training Accuracy: 0.349609\n",
      "Epoch: 9 / Batch: 46592/60000 / Cost: 0.723304 / Training Accuracy: 0.333984\n",
      "Epoch: 9 / Batch: 47104/60000 / Cost: 0.724257 / Training Accuracy: 0.300781\n",
      "Epoch: 9 / Batch: 47616/60000 / Cost: 0.722964 / Training Accuracy: 0.304688\n",
      "Epoch: 9 / Batch: 48128/60000 / Cost: 0.722329 / Training Accuracy: 0.330078\n",
      "Epoch: 9 / Batch: 48640/60000 / Cost: 0.721541 / Training Accuracy: 0.351563\n",
      "Epoch: 9 / Batch: 49152/60000 / Cost: 0.721759 / Training Accuracy: 0.363281\n",
      "Epoch: 9 / Batch: 49664/60000 / Cost: 0.721398 / Training Accuracy: 0.345703\n",
      "Epoch: 9 / Batch: 50176/60000 / Cost: 0.722324 / Training Accuracy: 0.333984\n",
      "Epoch: 9 / Batch: 50688/60000 / Cost: 0.721617 / Training Accuracy: 0.326172\n",
      "Epoch: 9 / Batch: 51200/60000 / Cost: 0.722203 / Training Accuracy: 0.310547\n",
      "Epoch: 9 / Batch: 51712/60000 / Cost: 0.723265 / Training Accuracy: 0.3125\n",
      "Epoch: 9 / Batch: 52224/60000 / Cost: 0.721755 / Training Accuracy: 0.326172\n",
      "Epoch: 9 / Batch: 52736/60000 / Cost: 0.721925 / Training Accuracy: 0.339844\n",
      "Epoch: 9 / Batch: 53248/60000 / Cost: 0.723563 / Training Accuracy: 0.296875\n",
      "Epoch: 9 / Batch: 53760/60000 / Cost: 0.721429 / Training Accuracy: 0.34375\n",
      "Epoch: 9 / Batch: 54272/60000 / Cost: 0.723473 / Training Accuracy: 0.34375\n",
      "Epoch: 9 / Batch: 54784/60000 / Cost: 0.722701 / Training Accuracy: 0.326172\n",
      "Epoch: 9 / Batch: 55296/60000 / Cost: 0.721512 / Training Accuracy: 0.365234\n",
      "Epoch: 9 / Batch: 55808/60000 / Cost: 0.721043 / Training Accuracy: 0.353516\n",
      "Epoch: 9 / Batch: 56320/60000 / Cost: 0.722783 / Training Accuracy: 0.333984\n",
      "Epoch: 9 / Batch: 56832/60000 / Cost: 0.721417 / Training Accuracy: 0.337891\n",
      "Epoch: 9 / Batch: 57344/60000 / Cost: 0.7209 / Training Accuracy: 0.365234\n",
      "Epoch: 9 / Batch: 57856/60000 / Cost: 0.721308 / Training Accuracy: 0.347656\n",
      "Epoch: 9 / Batch: 58368/60000 / Cost: 0.721586 / Training Accuracy: 0.373047\n",
      "Epoch: 9 / Batch: 58880/60000 / Cost: 0.723356 / Training Accuracy: 0.333984\n",
      "Epoch: 9 / Batch: 59392/60000 / Cost: 0.7226 / Training Accuracy: 0.330078\n",
      "Epoch: 9 / Batch: 59904/60000 / Cost: 0.721389 / Training Accuracy: 0.364583\n",
      "Epoch: 10 / Batch: 0/60000 / Cost: 0.72248 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 512/60000 / Cost: 0.722134 / Training Accuracy: 0.355469\n",
      "Epoch: 10 / Batch: 1024/60000 / Cost: 0.721239 / Training Accuracy: 0.328125\n",
      "Epoch: 10 / Batch: 1536/60000 / Cost: 0.721598 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 2048/60000 / Cost: 0.722606 / Training Accuracy: 0.330078\n",
      "Epoch: 10 / Batch: 2560/60000 / Cost: 0.721685 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 3072/60000 / Cost: 0.722208 / Training Accuracy: 0.302734\n",
      "Epoch: 10 / Batch: 3584/60000 / Cost: 0.721413 / Training Accuracy: 0.375\n",
      "Epoch: 10 / Batch: 4096/60000 / Cost: 0.722188 / Training Accuracy: 0.330078\n",
      "Epoch: 10 / Batch: 4608/60000 / Cost: 0.721692 / Training Accuracy: 0.3125\n",
      "Epoch: 10 / Batch: 5120/60000 / Cost: 0.721669 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 5632/60000 / Cost: 0.721916 / Training Accuracy: 0.326172\n",
      "Epoch: 10 / Batch: 6144/60000 / Cost: 0.722249 / Training Accuracy: 0.347656\n",
      "Epoch: 10 / Batch: 6656/60000 / Cost: 0.721277 / Training Accuracy: 0.337891\n",
      "Epoch: 10 / Batch: 7168/60000 / Cost: 0.721471 / Training Accuracy: 0.367188\n",
      "Epoch: 10 / Batch: 7680/60000 / Cost: 0.721157 / Training Accuracy: 0.353516\n",
      "Epoch: 10 / Batch: 8192/60000 / Cost: 0.719918 / Training Accuracy: 0.351563\n",
      "Epoch: 10 / Batch: 8704/60000 / Cost: 0.720063 / Training Accuracy: 0.367188\n",
      "Epoch: 10 / Batch: 9216/60000 / Cost: 0.721661 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 9728/60000 / Cost: 0.720737 / Training Accuracy: 0.353516\n",
      "Epoch: 10 / Batch: 10240/60000 / Cost: 0.721361 / Training Accuracy: 0.345703\n",
      "Epoch: 10 / Batch: 10752/60000 / Cost: 0.721801 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 11264/60000 / Cost: 0.723445 / Training Accuracy: 0.310547\n",
      "Epoch: 10 / Batch: 11776/60000 / Cost: 0.722566 / Training Accuracy: 0.326172\n",
      "Epoch: 10 / Batch: 12288/60000 / Cost: 0.721693 / Training Accuracy: 0.375\n",
      "Epoch: 10 / Batch: 12800/60000 / Cost: 0.722999 / Training Accuracy: 0.320313\n",
      "Epoch: 10 / Batch: 13312/60000 / Cost: 0.720389 / Training Accuracy: 0.382813\n",
      "Epoch: 10 / Batch: 13824/60000 / Cost: 0.719099 / Training Accuracy: 0.412109\n",
      "Epoch: 10 / Batch: 14336/60000 / Cost: 0.721733 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 14848/60000 / Cost: 0.721379 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 15360/60000 / Cost: 0.721536 / Training Accuracy: 0.345703\n",
      "Epoch: 10 / Batch: 15872/60000 / Cost: 0.721374 / Training Accuracy: 0.335938\n",
      "Epoch: 10 / Batch: 16384/60000 / Cost: 0.721935 / Training Accuracy: 0.318359\n",
      "Epoch: 10 / Batch: 16896/60000 / Cost: 0.720367 / Training Accuracy: 0.376953\n",
      "Epoch: 10 / Batch: 17408/60000 / Cost: 0.718869 / Training Accuracy: 0.384766\n",
      "Epoch: 10 / Batch: 17920/60000 / Cost: 0.721873 / Training Accuracy: 0.339844\n",
      "Epoch: 10 / Batch: 18432/60000 / Cost: 0.722222 / Training Accuracy: 0.353516\n",
      "Epoch: 10 / Batch: 18944/60000 / Cost: 0.72346 / Training Accuracy: 0.306641\n",
      "Epoch: 10 / Batch: 19456/60000 / Cost: 0.721415 / Training Accuracy: 0.333984\n",
      "Epoch: 10 / Batch: 19968/60000 / Cost: 0.721687 / Training Accuracy: 0.332031\n",
      "Epoch: 10 / Batch: 20480/60000 / Cost: 0.720889 / Training Accuracy: 0.347656\n",
      "Epoch: 10 / Batch: 20992/60000 / Cost: 0.72079 / Training Accuracy: 0.359375\n",
      "Epoch: 10 / Batch: 21504/60000 / Cost: 0.71995 / Training Accuracy: 0.371094\n",
      "Epoch: 10 / Batch: 22016/60000 / Cost: 0.722833 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 22528/60000 / Cost: 0.721771 / Training Accuracy: 0.318359\n",
      "Epoch: 10 / Batch: 23040/60000 / Cost: 0.721307 / Training Accuracy: 0.337891\n",
      "Epoch: 10 / Batch: 23552/60000 / Cost: 0.720595 / Training Accuracy: 0.378906\n",
      "Epoch: 10 / Batch: 24064/60000 / Cost: 0.722785 / Training Accuracy: 0.3125\n",
      "Epoch: 10 / Batch: 24576/60000 / Cost: 0.722738 / Training Accuracy: 0.324219\n",
      "Epoch: 10 / Batch: 25088/60000 / Cost: 0.722849 / Training Accuracy: 0.320313\n",
      "Epoch: 10 / Batch: 25600/60000 / Cost: 0.72007 / Training Accuracy: 0.388672\n",
      "Epoch: 10 / Batch: 26112/60000 / Cost: 0.720174 / Training Accuracy: 0.380859\n",
      "Epoch: 10 / Batch: 26624/60000 / Cost: 0.722495 / Training Accuracy: 0.330078\n",
      "Epoch: 10 / Batch: 27136/60000 / Cost: 0.721566 / Training Accuracy: 0.355469\n",
      "Epoch: 10 / Batch: 27648/60000 / Cost: 0.722506 / Training Accuracy: 0.318359\n",
      "Epoch: 10 / Batch: 28160/60000 / Cost: 0.722683 / Training Accuracy: 0.355469\n",
      "Epoch: 10 / Batch: 28672/60000 / Cost: 0.721274 / Training Accuracy: 0.376953\n",
      "Epoch: 10 / Batch: 29184/60000 / Cost: 0.722888 / Training Accuracy: 0.322266\n",
      "Epoch: 10 / Batch: 29696/60000 / Cost: 0.720395 / Training Accuracy: 0.371094\n",
      "Epoch: 10 / Batch: 30208/60000 / Cost: 0.721476 / Training Accuracy: 0.365234\n",
      "Epoch: 10 / Batch: 30720/60000 / Cost: 0.721459 / Training Accuracy: 0.357422\n",
      "Epoch: 10 / Batch: 31232/60000 / Cost: 0.720926 / Training Accuracy: 0.339844\n",
      "Epoch: 10 / Batch: 31744/60000 / Cost: 0.721781 / Training Accuracy: 0.34375\n",
      "Epoch: 10 / Batch: 32256/60000 / Cost: 0.721362 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 32768/60000 / Cost: 0.721835 / Training Accuracy: 0.351563\n",
      "Epoch: 10 / Batch: 33280/60000 / Cost: 0.719117 / Training Accuracy: 0.378906\n",
      "Epoch: 10 / Batch: 33792/60000 / Cost: 0.721105 / Training Accuracy: 0.349609\n",
      "Epoch: 10 / Batch: 34304/60000 / Cost: 0.720945 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 34816/60000 / Cost: 0.71928 / Training Accuracy: 0.367188\n",
      "Epoch: 10 / Batch: 35328/60000 / Cost: 0.72231 / Training Accuracy: 0.308594\n",
      "Epoch: 10 / Batch: 35840/60000 / Cost: 0.720579 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 36352/60000 / Cost: 0.721846 / Training Accuracy: 0.347656\n",
      "Epoch: 10 / Batch: 36864/60000 / Cost: 0.722102 / Training Accuracy: 0.361328\n",
      "Epoch: 10 / Batch: 37376/60000 / Cost: 0.722521 / Training Accuracy: 0.316406\n",
      "Epoch: 10 / Batch: 37888/60000 / Cost: 0.718926 / Training Accuracy: 0.375\n",
      "Epoch: 10 / Batch: 38400/60000 / Cost: 0.720389 / Training Accuracy: 0.382813\n",
      "Epoch: 10 / Batch: 38912/60000 / Cost: 0.719959 / Training Accuracy: 0.375\n",
      "Epoch: 10 / Batch: 39424/60000 / Cost: 0.720556 / Training Accuracy: 0.359375\n",
      "Epoch: 10 / Batch: 39936/60000 / Cost: 0.721063 / Training Accuracy: 0.359375\n",
      "Epoch: 10 / Batch: 40448/60000 / Cost: 0.72111 / Training Accuracy: 0.353516\n",
      "Epoch: 10 / Batch: 40960/60000 / Cost: 0.721199 / Training Accuracy: 0.335938\n",
      "Epoch: 10 / Batch: 41472/60000 / Cost: 0.722112 / Training Accuracy: 0.353516\n",
      "Epoch: 10 / Batch: 41984/60000 / Cost: 0.720058 / Training Accuracy: 0.365234\n",
      "Epoch: 10 / Batch: 42496/60000 / Cost: 0.723152 / Training Accuracy: 0.308594\n",
      "Epoch: 10 / Batch: 43008/60000 / Cost: 0.720278 / Training Accuracy: 0.34375\n",
      "Epoch: 10 / Batch: 43520/60000 / Cost: 0.720858 / Training Accuracy: 0.351563\n",
      "Epoch: 10 / Batch: 44032/60000 / Cost: 0.722196 / Training Accuracy: 0.326172\n",
      "Epoch: 10 / Batch: 44544/60000 / Cost: 0.720995 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 45056/60000 / Cost: 0.720746 / Training Accuracy: 0.361328\n",
      "Epoch: 10 / Batch: 45568/60000 / Cost: 0.722699 / Training Accuracy: 0.328125\n",
      "Epoch: 10 / Batch: 46080/60000 / Cost: 0.721697 / Training Accuracy: 0.322266\n",
      "Epoch: 10 / Batch: 46592/60000 / Cost: 0.719598 / Training Accuracy: 0.355469\n",
      "Epoch: 10 / Batch: 47104/60000 / Cost: 0.721019 / Training Accuracy: 0.357422\n",
      "Epoch: 10 / Batch: 47616/60000 / Cost: 0.721308 / Training Accuracy: 0.337891\n",
      "Epoch: 10 / Batch: 48128/60000 / Cost: 0.72026 / Training Accuracy: 0.373047\n",
      "Epoch: 10 / Batch: 48640/60000 / Cost: 0.721797 / Training Accuracy: 0.34375\n",
      "Epoch: 10 / Batch: 49152/60000 / Cost: 0.720707 / Training Accuracy: 0.371094\n",
      "Epoch: 10 / Batch: 49664/60000 / Cost: 0.722431 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 50176/60000 / Cost: 0.720859 / Training Accuracy: 0.330078\n",
      "Epoch: 10 / Batch: 50688/60000 / Cost: 0.722682 / Training Accuracy: 0.330078\n",
      "Epoch: 10 / Batch: 51200/60000 / Cost: 0.721375 / Training Accuracy: 0.371094\n",
      "Epoch: 10 / Batch: 51712/60000 / Cost: 0.720106 / Training Accuracy: 0.380859\n",
      "Epoch: 10 / Batch: 52224/60000 / Cost: 0.720543 / Training Accuracy: 0.369141\n",
      "Epoch: 10 / Batch: 52736/60000 / Cost: 0.721944 / Training Accuracy: 0.328125\n",
      "Epoch: 10 / Batch: 53248/60000 / Cost: 0.722344 / Training Accuracy: 0.320313\n",
      "Epoch: 10 / Batch: 53760/60000 / Cost: 0.720864 / Training Accuracy: 0.375\n",
      "Epoch: 10 / Batch: 54272/60000 / Cost: 0.71919 / Training Accuracy: 0.378906\n",
      "Epoch: 10 / Batch: 54784/60000 / Cost: 0.723146 / Training Accuracy: 0.300781\n",
      "Epoch: 10 / Batch: 55296/60000 / Cost: 0.721117 / Training Accuracy: 0.347656\n",
      "Epoch: 10 / Batch: 55808/60000 / Cost: 0.720815 / Training Accuracy: 0.345703\n",
      "Epoch: 10 / Batch: 56320/60000 / Cost: 0.718672 / Training Accuracy: 0.378906\n",
      "Epoch: 10 / Batch: 56832/60000 / Cost: 0.719377 / Training Accuracy: 0.384766\n",
      "Epoch: 10 / Batch: 57344/60000 / Cost: 0.721108 / Training Accuracy: 0.341797\n",
      "Epoch: 10 / Batch: 57856/60000 / Cost: 0.719851 / Training Accuracy: 0.390625\n",
      "Epoch: 10 / Batch: 58368/60000 / Cost: 0.721408 / Training Accuracy: 0.361328\n",
      "Epoch: 10 / Batch: 58880/60000 / Cost: 0.72166 / Training Accuracy: 0.337891\n",
      "Epoch: 10 / Batch: 59392/60000 / Cost: 0.719586 / Training Accuracy: 0.380859\n",
      "Epoch: 10 / Batch: 59904/60000 / Cost: 0.721682 / Training Accuracy: 0.34375\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for i in range(num_epoch):\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    data_x = data[:, :img_flat_size]\n",
    "    data_y = data[:, img_flat_size]\n",
    "\n",
    "    data_y_onehot = np.zeros([data_y.shape[0], num_label])\n",
    "    for j in range(data_y.shape[0]):\n",
    "        data_y_onehot[j, int(data_y[j])] = 1\n",
    "    \n",
    "    data_y_onehot_val = np.zeros([validation_y.shape[0], num_label])\n",
    "    for j in range(validation_y.shape[0]):\n",
    "        data_y_onehot_val[j, int(validation_y[j])] = 1\n",
    "        \n",
    "    batch_count = 1\n",
    "    for j in range(0, len_data, batch_size):\n",
    "        if j + batch_size < len_data:\n",
    "            data_x_in = data_x[j : j + batch_size, :]\n",
    "            data_y_in = data_y_onehot[j : j + batch_size, :]\n",
    "        else:\n",
    "            data_x_in = data_x[j : len_data, :]\n",
    "            data_y_in = data_y_onehot[j : len_data, :]\n",
    "        \n",
    "        \n",
    "        data_x_in_resize = np.reshape(data_x_in, (data_x_in.shape[0], img_size, img_size))\n",
    "                                      \n",
    "        img_fraction = np.zeros([data_x_in.shape[0], img_fraction_size, img_fraction_size, len_stack])\n",
    "                                      \n",
    "        index_fraction = 0\n",
    "        for m in range(len_vertical):\n",
    "            start_v = stride * m\n",
    "            for n in range(len_horizontal):\n",
    "                start_h = stride * n\n",
    "\n",
    "                img_fraction[:,:,:,index_fraction] = data_x_in_resize[:, \n",
    "                                                                      start_v : start_v + img_fraction_size, \n",
    "                                                                      start_h : start_h + img_fraction_size]\n",
    "                index_fraction += 1\n",
    "        \n",
    "        optimizer.run(feed_dict = {x_image: img_fraction, y_target: data_y_in})\n",
    "        cost = sess.run(Cost, feed_dict = {x_image: img_fraction, y_target: data_y_in})\n",
    "        acc = sess.run(accuracy, feed_dict = {x_image: img_fraction, y_target: data_y_in})\n",
    "                                      \n",
    "        print(\"Epoch: \" + str(i+1) + ' / ' + \"Batch: \" + str(j) + '/' + str(len_data) + ' / ' + \"Cost: \" + str(cost) + ' / ' + \\\n",
    "              \"Training Accuracy: \" + str(acc))\n",
    "#         val_acc = sess.run(accuracy, feed_dict = {x_image: validation_x, y_target: data_y_onehot_val})\n",
    "        \n",
    "#         print(\"Epoch: \" + str(i+1) + ' / ' + \"Batch: \" + str(j) + '/' + str(len_data) + ' / ' + \"Cost: \" + str(cost) + ' / ' + \\\n",
    "#               \"Training Accuracy: \" + str(acc) + ' / ' + \"Validation Accuracy: \" + str(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "test_y_onehot = np.zeros([test_y.shape[0], num_label])\n",
    "for i in range(test_y.shape[0]):\n",
    "    test_y_onehot[i, int(test_y[i])] = 1\n",
    "\n",
    "test_result = sess.run(output, feed_dict = {x_image: test_x, rnn_batch_size: test_x.shape[0], rnn_step_size: step_size})\n",
    "\n",
    "count_correct = 0\n",
    "for i in range(test_result.shape[0]):\n",
    "    prediction_y = np.argmax(test_result[i,:])\n",
    "    \n",
    "    if prediction_y == test_y[i]:\n",
    "        count_correct += 1\n",
    "\n",
    "test_acc = count_correct / test_result.shape[0]\n",
    "\n",
    "print(\"Test Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
