{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "img_size = 28\n",
    "img_flat_size = img_size * img_size\n",
    "lstm_size = 512\n",
    "\n",
    "num_label = 10\n",
    "num_epoch = 10\n",
    "\n",
    "learning_rate = 5e-4\n",
    "epsilon = 1e-8\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "step_size = img_size\n",
    "flatten_size = img_size\n",
    "\n",
    "validation_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd4977f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting example image\n",
    "img = mnist.train.images[0]\n",
    "img_resize = img.reshape((img_size, img_size))\n",
    "plt.imshow(img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "# Input \n",
    "x_image  = tf.placeholder(tf.float32, shape = [None, img_flat_size])\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, num_label])\n",
    "\n",
    "input_flat = tf.reshape(x_image,[-1, step_size , flatten_size])\n",
    "\n",
    "# LSTM cell\n",
    "cell = tf.contrib.rnn.LSTMCell(num_units = lstm_size, state_is_tuple = True)\n",
    "rnn_out, rnn_state = tf.nn.dynamic_rnn(inputs = input_flat, cell = cell, dtype = tf.float32)\n",
    "    \n",
    "# Vectorization\n",
    "rnn_out = rnn_out[:, -1, :]\n",
    "rnn_out = tf.reshape(rnn_out ,shape = [-1, lstm_size])\n",
    "\n",
    "# Densely connect layer variables \n",
    "w_fc1 = weight_variable([lstm_size, 256])\n",
    "b_fc1 = bias_variable([256])\n",
    "\n",
    "w_fc2 = weight_variable([256, num_label])\n",
    "b_fc2 = bias_variable([num_label])\n",
    "\n",
    "# Fully Connected Layer\n",
    "h_fc1 = tf.nn.relu(tf.matmul(rnn_out, w_fc1)+b_fc1)\n",
    "output = tf.matmul(h_fc1, w_fc2)+b_fc2\n",
    "\n",
    "# Training \n",
    "Loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y_target, logits = output)\n",
    "Cost = tf.reduce_mean(Loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon = epsilon).minimize(Cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_target,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (60000, 784)\n",
      "Testing set: (9000, 784)\n",
      "Validation set: (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for train, test, validation\n",
    "\n",
    "test_len = mnist.test.images.shape[0]\n",
    "validation_len = int(test_len * validation_ratio)\n",
    "\n",
    "train_x = mnist.train.images\n",
    "test_x = mnist.test.images[validation_len : test_len, :]\n",
    "validation_x = mnist.test.images[ : validation_len, :]\n",
    "\n",
    "train_y = mnist.train.labels\n",
    "test_y = mnist.test.labels[validation_len : test_len]\n",
    "validation_y = mnist.test.labels[ : validation_len]\n",
    "\n",
    "print(\"Training set: \" + str(train_x.shape))\n",
    "print(\"Testing set: \" + str(test_x.shape))\n",
    "print(\"Validation set: \" + str(validation_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / Batch: 0/60000 / Cost: 0.72034 / Training Accuracy: 0.0839844 / Validation Accuracy: 0.095\n",
      "Epoch: 0 / Batch: 512/60000 / Cost: 0.700627 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.086\n",
      "Epoch: 0 / Batch: 1024/60000 / Cost: 0.667191 / Training Accuracy: 0.0957031 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 1536/60000 / Cost: 0.611176 / Training Accuracy: 0.105469 / Validation Accuracy: 0.084\n",
      "Epoch: 0 / Batch: 2048/60000 / Cost: 0.514322 / Training Accuracy: 0.09375 / Validation Accuracy: 0.083\n",
      "Epoch: 0 / Batch: 2560/60000 / Cost: 0.419504 / Training Accuracy: 0.0761719 / Validation Accuracy: 0.09\n",
      "Epoch: 0 / Batch: 3072/60000 / Cost: 0.364924 / Training Accuracy: 0.121094 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 3584/60000 / Cost: 0.341469 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 4096/60000 / Cost: 0.336297 / Training Accuracy: 0.0839844 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 4608/60000 / Cost: 0.335395 / Training Accuracy: 0.105469 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 5120/60000 / Cost: 0.33861 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 5632/60000 / Cost: 0.341287 / Training Accuracy: 0.0839844 / Validation Accuracy: 0.089\n",
      "Epoch: 0 / Batch: 6144/60000 / Cost: 0.338314 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 6656/60000 / Cost: 0.3355 / Training Accuracy: 0.09375 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 7168/60000 / Cost: 0.329335 / Training Accuracy: 0.115234 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 7680/60000 / Cost: 0.332531 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 8192/60000 / Cost: 0.332289 / Training Accuracy: 0.109375 / Validation Accuracy: 0.1\n",
      "Epoch: 0 / Batch: 8704/60000 / Cost: 0.329449 / Training Accuracy: 0.103516 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 9216/60000 / Cost: 0.330765 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 9728/60000 / Cost: 0.3283 / Training Accuracy: 0.123047 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 10240/60000 / Cost: 0.32813 / Training Accuracy: 0.121094 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 10752/60000 / Cost: 0.326848 / Training Accuracy: 0.144531 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 11264/60000 / Cost: 0.327173 / Training Accuracy: 0.09375 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 11776/60000 / Cost: 0.3248 / Training Accuracy: 0.113281 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 12288/60000 / Cost: 0.327608 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.129\n",
      "Epoch: 0 / Batch: 12800/60000 / Cost: 0.32787 / Training Accuracy: 0.111328 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 13312/60000 / Cost: 0.327669 / Training Accuracy: 0.105469 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 13824/60000 / Cost: 0.327857 / Training Accuracy: 0.101563 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 14336/60000 / Cost: 0.329465 / Training Accuracy: 0.0820313 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 14848/60000 / Cost: 0.326123 / Training Accuracy: 0.103516 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 15360/60000 / Cost: 0.325655 / Training Accuracy: 0.107422 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 15872/60000 / Cost: 0.325132 / Training Accuracy: 0.117188 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 16384/60000 / Cost: 0.325672 / Training Accuracy: 0.109375 / Validation Accuracy: 0.087\n",
      "Epoch: 0 / Batch: 16896/60000 / Cost: 0.327142 / Training Accuracy: 0.0839844 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 17408/60000 / Cost: 0.32685 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 17920/60000 / Cost: 0.325883 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 18432/60000 / Cost: 0.326131 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 18944/60000 / Cost: 0.32597 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 19456/60000 / Cost: 0.324656 / Training Accuracy: 0.126953 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 19968/60000 / Cost: 0.326106 / Training Accuracy: 0.113281 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 20480/60000 / Cost: 0.32588 / Training Accuracy: 0.103516 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 20992/60000 / Cost: 0.324593 / Training Accuracy: 0.113281 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 21504/60000 / Cost: 0.325403 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 22016/60000 / Cost: 0.324838 / Training Accuracy: 0.103516 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 22528/60000 / Cost: 0.326314 / Training Accuracy: 0.117188 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 23040/60000 / Cost: 0.325849 / Training Accuracy: 0.126953 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 23552/60000 / Cost: 0.326337 / Training Accuracy: 0.0957031 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 24064/60000 / Cost: 0.324775 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 24576/60000 / Cost: 0.32562 / Training Accuracy: 0.0839844 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 25088/60000 / Cost: 0.32596 / Training Accuracy: 0.105469 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 25600/60000 / Cost: 0.325279 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 26112/60000 / Cost: 0.325561 / Training Accuracy: 0.0957031 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 26624/60000 / Cost: 0.326 / Training Accuracy: 0.09375 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 27136/60000 / Cost: 0.325939 / Training Accuracy: 0.078125 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 27648/60000 / Cost: 0.325172 / Training Accuracy: 0.0957031 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 28160/60000 / Cost: 0.324939 / Training Accuracy: 0.09375 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 28672/60000 / Cost: 0.324789 / Training Accuracy: 0.128906 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 29184/60000 / Cost: 0.325013 / Training Accuracy: 0.113281 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 29696/60000 / Cost: 0.325223 / Training Accuracy: 0.09375 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 30208/60000 / Cost: 0.324959 / Training Accuracy: 0.101563 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 30720/60000 / Cost: 0.325438 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 31232/60000 / Cost: 0.325606 / Training Accuracy: 0.105469 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 31744/60000 / Cost: 0.325466 / Training Accuracy: 0.128906 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 32256/60000 / Cost: 0.325514 / Training Accuracy: 0.09375 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 32768/60000 / Cost: 0.325378 / Training Accuracy: 0.109375 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 33280/60000 / Cost: 0.325362 / Training Accuracy: 0.115234 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 33792/60000 / Cost: 0.324917 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 34304/60000 / Cost: 0.324968 / Training Accuracy: 0.115234 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 34816/60000 / Cost: 0.325908 / Training Accuracy: 0.101563 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 35328/60000 / Cost: 0.325802 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 35840/60000 / Cost: 0.32446 / Training Accuracy: 0.126953 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 36352/60000 / Cost: 0.32545 / Training Accuracy: 0.101563 / Validation Accuracy: 0.085\n",
      "Epoch: 0 / Batch: 36864/60000 / Cost: 0.325477 / Training Accuracy: 0.115234 / Validation Accuracy: 0.094\n",
      "Epoch: 0 / Batch: 37376/60000 / Cost: 0.325132 / Training Accuracy: 0.111328 / Validation Accuracy: 0.094\n",
      "Epoch: 0 / Batch: 37888/60000 / Cost: 0.32457 / Training Accuracy: 0.107422 / Validation Accuracy: 0.094\n",
      "Epoch: 0 / Batch: 38400/60000 / Cost: 0.325095 / Training Accuracy: 0.115234 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 38912/60000 / Cost: 0.325342 / Training Accuracy: 0.109375 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 39424/60000 / Cost: 0.325558 / Training Accuracy: 0.107422 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 39936/60000 / Cost: 0.325348 / Training Accuracy: 0.107422 / Validation Accuracy: 0.116\n",
      "Epoch: 0 / Batch: 40448/60000 / Cost: 0.325062 / Training Accuracy: 0.121094 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 40960/60000 / Cost: 0.325752 / Training Accuracy: 0.121094 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 41472/60000 / Cost: 0.325467 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 41984/60000 / Cost: 0.325339 / Training Accuracy: 0.107422 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 42496/60000 / Cost: 0.32508 / Training Accuracy: 0.115234 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 43008/60000 / Cost: 0.325696 / Training Accuracy: 0.101563 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 43520/60000 / Cost: 0.32543 / Training Accuracy: 0.0957031 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 44032/60000 / Cost: 0.324994 / Training Accuracy: 0.121094 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 44544/60000 / Cost: 0.325574 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 45056/60000 / Cost: 0.325058 / Training Accuracy: 0.115234 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 45568/60000 / Cost: 0.32588 / Training Accuracy: 0.0878906 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 46080/60000 / Cost: 0.324632 / Training Accuracy: 0.115234 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 46592/60000 / Cost: 0.325638 / Training Accuracy: 0.103516 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 47104/60000 / Cost: 0.325861 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 47616/60000 / Cost: 0.325592 / Training Accuracy: 0.0839844 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 48128/60000 / Cost: 0.324609 / Training Accuracy: 0.115234 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 48640/60000 / Cost: 0.325024 / Training Accuracy: 0.117188 / Validation Accuracy: 0.089\n",
      "Epoch: 0 / Batch: 49152/60000 / Cost: 0.325015 / Training Accuracy: 0.117188 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 49664/60000 / Cost: 0.324924 / Training Accuracy: 0.103516 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 50176/60000 / Cost: 0.324916 / Training Accuracy: 0.128906 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 50688/60000 / Cost: 0.325098 / Training Accuracy: 0.105469 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 51200/60000 / Cost: 0.32506 / Training Accuracy: 0.117188 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 51712/60000 / Cost: 0.324921 / Training Accuracy: 0.0683594 / Validation Accuracy: 0.11\n",
      "Epoch: 0 / Batch: 52224/60000 / Cost: 0.324785 / Training Accuracy: 0.121094 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 52736/60000 / Cost: 0.324458 / Training Accuracy: 0.126953 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 53248/60000 / Cost: 0.324967 / Training Accuracy: 0.125 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 53760/60000 / Cost: 0.326816 / Training Accuracy: 0.111328 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 54272/60000 / Cost: 0.325433 / Training Accuracy: 0.109375 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 54784/60000 / Cost: 0.32424 / Training Accuracy: 0.123047 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 55296/60000 / Cost: 0.324906 / Training Accuracy: 0.115234 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 55808/60000 / Cost: 0.325458 / Training Accuracy: 0.09375 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 56320/60000 / Cost: 0.324844 / Training Accuracy: 0.123047 / Validation Accuracy: 0.126\n",
      "Epoch: 0 / Batch: 56832/60000 / Cost: 0.324133 / Training Accuracy: 0.105469 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 57344/60000 / Cost: 0.324275 / Training Accuracy: 0.117188 / Validation Accuracy: 0.107\n",
      "Epoch: 0 / Batch: 57856/60000 / Cost: 0.323421 / Training Accuracy: 0.150391 / Validation Accuracy: 0.114\n",
      "Epoch: 0 / Batch: 58368/60000 / Cost: 0.326211 / Training Accuracy: 0.105469 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 58880/60000 / Cost: 0.325241 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 59392/60000 / Cost: 0.324725 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.099\n",
      "Epoch: 0 / Batch: 59904/60000 / Cost: 0.324495 / Training Accuracy: 0.15625 / Validation Accuracy: 0.099\n",
      "Epoch: 1 / Batch: 0/60000 / Cost: 0.326121 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.099\n",
      "Epoch: 1 / Batch: 512/60000 / Cost: 0.325119 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.099\n",
      "Epoch: 1 / Batch: 1024/60000 / Cost: 0.325044 / Training Accuracy: 0.113281 / Validation Accuracy: 0.099\n",
      "Epoch: 1 / Batch: 1536/60000 / Cost: 0.324911 / Training Accuracy: 0.105469 / Validation Accuracy: 0.099\n",
      "Epoch: 1 / Batch: 2048/60000 / Cost: 0.325077 / Training Accuracy: 0.171875 / Validation Accuracy: 0.152\n",
      "Epoch: 1 / Batch: 2560/60000 / Cost: 0.324726 / Training Accuracy: 0.130859 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 3072/60000 / Cost: 0.325106 / Training Accuracy: 0.117188 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 3584/60000 / Cost: 0.324511 / Training Accuracy: 0.115234 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 4096/60000 / Cost: 0.324646 / Training Accuracy: 0.111328 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 4608/60000 / Cost: 0.325231 / Training Accuracy: 0.105469 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 5120/60000 / Cost: 0.324532 / Training Accuracy: 0.107422 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 5632/60000 / Cost: 0.324116 / Training Accuracy: 0.0996094 / Validation Accuracy: 0.126\n",
      "Epoch: 1 / Batch: 6144/60000 / Cost: 0.324001 / Training Accuracy: 0.121094 / Validation Accuracy: 0.13\n",
      "Epoch: 1 / Batch: 6656/60000 / Cost: 0.324581 / Training Accuracy: 0.105469 / Validation Accuracy: 0.107\n",
      "Epoch: 1 / Batch: 7168/60000 / Cost: 0.325053 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.107\n",
      "Epoch: 1 / Batch: 7680/60000 / Cost: 0.32379 / Training Accuracy: 0.199219 / Validation Accuracy: 0.212\n",
      "Epoch: 1 / Batch: 8192/60000 / Cost: 0.32483 / Training Accuracy: 0.126953 / Validation Accuracy: 0.133\n",
      "Epoch: 1 / Batch: 8704/60000 / Cost: 0.32411 / Training Accuracy: 0.125 / Validation Accuracy: 0.131\n",
      "Epoch: 1 / Batch: 9216/60000 / Cost: 0.323317 / Training Accuracy: 0.199219 / Validation Accuracy: 0.196\n",
      "Epoch: 1 / Batch: 9728/60000 / Cost: 0.323812 / Training Accuracy: 0.181641 / Validation Accuracy: 0.202\n",
      "Epoch: 1 / Batch: 10240/60000 / Cost: 0.323395 / Training Accuracy: 0.216797 / Validation Accuracy: 0.208\n",
      "Epoch: 1 / Batch: 10752/60000 / Cost: 0.323319 / Training Accuracy: 0.210938 / Validation Accuracy: 0.199\n",
      "Epoch: 1 / Batch: 11264/60000 / Cost: 0.3252 / Training Accuracy: 0.181641 / Validation Accuracy: 0.192\n",
      "Epoch: 1 / Batch: 11776/60000 / Cost: 0.323808 / Training Accuracy: 0.177734 / Validation Accuracy: 0.199\n",
      "Epoch: 1 / Batch: 12288/60000 / Cost: 0.323222 / Training Accuracy: 0.212891 / Validation Accuracy: 0.207\n",
      "Epoch: 1 / Batch: 12800/60000 / Cost: 0.322907 / Training Accuracy: 0.193359 / Validation Accuracy: 0.207\n",
      "Epoch: 1 / Batch: 13312/60000 / Cost: 0.32347 / Training Accuracy: 0.183594 / Validation Accuracy: 0.194\n",
      "Epoch: 1 / Batch: 13824/60000 / Cost: 0.323149 / Training Accuracy: 0.144531 / Validation Accuracy: 0.161\n",
      "Epoch: 1 / Batch: 14336/60000 / Cost: 0.321854 / Training Accuracy: 0.160156 / Validation Accuracy: 0.147\n",
      "Epoch: 1 / Batch: 14848/60000 / Cost: 0.32261 / Training Accuracy: 0.162109 / Validation Accuracy: 0.157\n",
      "Epoch: 1 / Batch: 15360/60000 / Cost: 0.322676 / Training Accuracy: 0.189453 / Validation Accuracy: 0.189\n",
      "Epoch: 1 / Batch: 15872/60000 / Cost: 0.323118 / Training Accuracy: 0.15625 / Validation Accuracy: 0.184\n",
      "Epoch: 1 / Batch: 16384/60000 / Cost: 0.322451 / Training Accuracy: 0.148438 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 16896/60000 / Cost: 0.322757 / Training Accuracy: 0.130859 / Validation Accuracy: 0.14\n",
      "Epoch: 1 / Batch: 17408/60000 / Cost: 0.323182 / Training Accuracy: 0.138672 / Validation Accuracy: 0.159\n",
      "Epoch: 1 / Batch: 17920/60000 / Cost: 0.322326 / Training Accuracy: 0.220703 / Validation Accuracy: 0.224\n",
      "Epoch: 1 / Batch: 18432/60000 / Cost: 0.322607 / Training Accuracy: 0.191406 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 18944/60000 / Cost: 0.321907 / Training Accuracy: 0.207031 / Validation Accuracy: 0.206\n",
      "Epoch: 1 / Batch: 19456/60000 / Cost: 0.322009 / Training Accuracy: 0.244141 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 19968/60000 / Cost: 0.321444 / Training Accuracy: 0.242188 / Validation Accuracy: 0.264\n",
      "Epoch: 1 / Batch: 20480/60000 / Cost: 0.32147 / Training Accuracy: 0.144531 / Validation Accuracy: 0.144\n",
      "Epoch: 1 / Batch: 20992/60000 / Cost: 0.321323 / Training Accuracy: 0.210938 / Validation Accuracy: 0.221\n",
      "Epoch: 1 / Batch: 21504/60000 / Cost: 0.321071 / Training Accuracy: 0.228516 / Validation Accuracy: 0.209\n",
      "Epoch: 1 / Batch: 22016/60000 / Cost: 0.319837 / Training Accuracy: 0.248047 / Validation Accuracy: 0.201\n",
      "Epoch: 1 / Batch: 22528/60000 / Cost: 0.321686 / Training Accuracy: 0.177734 / Validation Accuracy: 0.199\n",
      "Epoch: 1 / Batch: 23040/60000 / Cost: 0.320975 / Training Accuracy: 0.191406 / Validation Accuracy: 0.2\n",
      "Epoch: 1 / Batch: 23552/60000 / Cost: 0.320134 / Training Accuracy: 0.244141 / Validation Accuracy: 0.219\n",
      "Epoch: 1 / Batch: 24064/60000 / Cost: 0.320805 / Training Accuracy: 0.242188 / Validation Accuracy: 0.209\n",
      "Epoch: 1 / Batch: 24576/60000 / Cost: 0.320606 / Training Accuracy: 0.185547 / Validation Accuracy: 0.179\n",
      "Epoch: 1 / Batch: 25088/60000 / Cost: 0.322326 / Training Accuracy: 0.138672 / Validation Accuracy: 0.148\n",
      "Epoch: 1 / Batch: 25600/60000 / Cost: 0.319975 / Training Accuracy: 0.158203 / Validation Accuracy: 0.149\n",
      "Epoch: 1 / Batch: 26112/60000 / Cost: 0.319941 / Training Accuracy: 0.185547 / Validation Accuracy: 0.193\n",
      "Epoch: 1 / Batch: 26624/60000 / Cost: 0.320645 / Training Accuracy: 0.189453 / Validation Accuracy: 0.221\n",
      "Epoch: 1 / Batch: 27136/60000 / Cost: 0.319308 / Training Accuracy: 0.175781 / Validation Accuracy: 0.185\n",
      "Epoch: 1 / Batch: 27648/60000 / Cost: 0.31956 / Training Accuracy: 0.134766 / Validation Accuracy: 0.163\n",
      "Epoch: 1 / Batch: 28160/60000 / Cost: 0.320059 / Training Accuracy: 0.152344 / Validation Accuracy: 0.187\n",
      "Epoch: 1 / Batch: 28672/60000 / Cost: 0.319033 / Training Accuracy: 0.228516 / Validation Accuracy: 0.219\n",
      "Epoch: 1 / Batch: 29184/60000 / Cost: 0.318473 / Training Accuracy: 0.234375 / Validation Accuracy: 0.238\n",
      "Epoch: 1 / Batch: 29696/60000 / Cost: 0.318021 / Training Accuracy: 0.220703 / Validation Accuracy: 0.224\n",
      "Epoch: 1 / Batch: 30208/60000 / Cost: 0.318764 / Training Accuracy: 0.193359 / Validation Accuracy: 0.19\n",
      "Epoch: 1 / Batch: 30720/60000 / Cost: 0.316992 / Training Accuracy: 0.220703 / Validation Accuracy: 0.2\n",
      "Epoch: 1 / Batch: 31232/60000 / Cost: 0.318546 / Training Accuracy: 0.193359 / Validation Accuracy: 0.212\n",
      "Epoch: 1 / Batch: 31744/60000 / Cost: 0.316987 / Training Accuracy: 0.234375 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 32256/60000 / Cost: 0.318176 / Training Accuracy: 0.185547 / Validation Accuracy: 0.214\n",
      "Epoch: 1 / Batch: 32768/60000 / Cost: 0.316116 / Training Accuracy: 0.216797 / Validation Accuracy: 0.211\n",
      "Epoch: 1 / Batch: 33280/60000 / Cost: 0.31452 / Training Accuracy: 0.240234 / Validation Accuracy: 0.202\n",
      "Epoch: 1 / Batch: 33792/60000 / Cost: 0.316762 / Training Accuracy: 0.1875 / Validation Accuracy: 0.213\n",
      "Epoch: 1 / Batch: 34304/60000 / Cost: 0.316073 / Training Accuracy: 0.203125 / Validation Accuracy: 0.222\n",
      "Epoch: 1 / Batch: 34816/60000 / Cost: 0.316126 / Training Accuracy: 0.207031 / Validation Accuracy: 0.224\n",
      "Epoch: 1 / Batch: 35328/60000 / Cost: 0.313947 / Training Accuracy: 0.205078 / Validation Accuracy: 0.229\n",
      "Epoch: 1 / Batch: 35840/60000 / Cost: 0.313028 / Training Accuracy: 0.236328 / Validation Accuracy: 0.233\n",
      "Epoch: 1 / Batch: 36352/60000 / Cost: 0.311964 / Training Accuracy: 0.205078 / Validation Accuracy: 0.196\n",
      "Epoch: 1 / Batch: 36864/60000 / Cost: 0.311089 / Training Accuracy: 0.210938 / Validation Accuracy: 0.205\n",
      "Epoch: 1 / Batch: 37376/60000 / Cost: 0.31136 / Training Accuracy: 0.203125 / Validation Accuracy: 0.206\n",
      "Epoch: 1 / Batch: 37888/60000 / Cost: 0.31342 / Training Accuracy: 0.164063 / Validation Accuracy: 0.194\n",
      "Epoch: 1 / Batch: 38400/60000 / Cost: 0.311417 / Training Accuracy: 0.166016 / Validation Accuracy: 0.201\n",
      "Epoch: 1 / Batch: 38912/60000 / Cost: 0.30817 / Training Accuracy: 0.179688 / Validation Accuracy: 0.171\n",
      "Epoch: 1 / Batch: 39424/60000 / Cost: 0.310391 / Training Accuracy: 0.197266 / Validation Accuracy: 0.218\n",
      "Epoch: 1 / Batch: 39936/60000 / Cost: 0.30826 / Training Accuracy: 0.212891 / Validation Accuracy: 0.219\n",
      "Epoch: 1 / Batch: 40448/60000 / Cost: 0.312838 / Training Accuracy: 0.208984 / Validation Accuracy: 0.18\n",
      "Epoch: 1 / Batch: 40960/60000 / Cost: 0.307508 / Training Accuracy: 0.205078 / Validation Accuracy: 0.224\n",
      "Epoch: 1 / Batch: 41472/60000 / Cost: 0.310102 / Training Accuracy: 0.214844 / Validation Accuracy: 0.227\n",
      "Epoch: 1 / Batch: 41984/60000 / Cost: 0.302023 / Training Accuracy: 0.255859 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 42496/60000 / Cost: 0.306772 / Training Accuracy: 0.257813 / Validation Accuracy: 0.225\n",
      "Epoch: 1 / Batch: 43008/60000 / Cost: 0.307451 / Training Accuracy: 0.230469 / Validation Accuracy: 0.289\n",
      "Epoch: 1 / Batch: 43520/60000 / Cost: 0.304404 / Training Accuracy: 0.275391 / Validation Accuracy: 0.282\n",
      "Epoch: 1 / Batch: 44032/60000 / Cost: 0.298723 / Training Accuracy: 0.253906 / Validation Accuracy: 0.221\n",
      "Epoch: 1 / Batch: 44544/60000 / Cost: 0.306058 / Training Accuracy: 0.220703 / Validation Accuracy: 0.227\n",
      "Epoch: 1 / Batch: 45056/60000 / Cost: 0.303614 / Training Accuracy: 0.226563 / Validation Accuracy: 0.225\n",
      "Epoch: 1 / Batch: 45568/60000 / Cost: 0.299096 / Training Accuracy: 0.240234 / Validation Accuracy: 0.227\n",
      "Epoch: 1 / Batch: 46080/60000 / Cost: 0.296171 / Training Accuracy: 0.28125 / Validation Accuracy: 0.236\n",
      "Epoch: 1 / Batch: 46592/60000 / Cost: 0.299875 / Training Accuracy: 0.248047 / Validation Accuracy: 0.236\n",
      "Epoch: 1 / Batch: 47104/60000 / Cost: 0.300358 / Training Accuracy: 0.25 / Validation Accuracy: 0.248\n",
      "Epoch: 1 / Batch: 47616/60000 / Cost: 0.295706 / Training Accuracy: 0.275391 / Validation Accuracy: 0.255\n",
      "Epoch: 1 / Batch: 48128/60000 / Cost: 0.296206 / Training Accuracy: 0.267578 / Validation Accuracy: 0.254\n",
      "Epoch: 1 / Batch: 48640/60000 / Cost: 0.293208 / Training Accuracy: 0.261719 / Validation Accuracy: 0.272\n",
      "Epoch: 1 / Batch: 49152/60000 / Cost: 0.292882 / Training Accuracy: 0.275391 / Validation Accuracy: 0.261\n",
      "Epoch: 1 / Batch: 49664/60000 / Cost: 0.294024 / Training Accuracy: 0.261719 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 50176/60000 / Cost: 0.295891 / Training Accuracy: 0.261719 / Validation Accuracy: 0.249\n",
      "Epoch: 1 / Batch: 50688/60000 / Cost: 0.291576 / Training Accuracy: 0.283203 / Validation Accuracy: 0.298\n",
      "Epoch: 1 / Batch: 51200/60000 / Cost: 0.294217 / Training Accuracy: 0.273438 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 51712/60000 / Cost: 0.285823 / Training Accuracy: 0.324219 / Validation Accuracy: 0.302\n",
      "Epoch: 1 / Batch: 52224/60000 / Cost: 0.287139 / Training Accuracy: 0.294922 / Validation Accuracy: 0.258\n",
      "Epoch: 1 / Batch: 52736/60000 / Cost: 0.283161 / Training Accuracy: 0.318359 / Validation Accuracy: 0.309\n",
      "Epoch: 1 / Batch: 53248/60000 / Cost: 0.286801 / Training Accuracy: 0.271484 / Validation Accuracy: 0.294\n",
      "Epoch: 1 / Batch: 53760/60000 / Cost: 0.280657 / Training Accuracy: 0.314453 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 54272/60000 / Cost: 0.302448 / Training Accuracy: 0.234375 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 54784/60000 / Cost: 0.299731 / Training Accuracy: 0.267578 / Validation Accuracy: 0.218\n",
      "Epoch: 1 / Batch: 55296/60000 / Cost: 0.293596 / Training Accuracy: 0.277344 / Validation Accuracy: 0.224\n",
      "Epoch: 1 / Batch: 55808/60000 / Cost: 0.283677 / Training Accuracy: 0.333984 / Validation Accuracy: 0.316\n",
      "Epoch: 1 / Batch: 56320/60000 / Cost: 0.278768 / Training Accuracy: 0.341797 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 56832/60000 / Cost: 0.286063 / Training Accuracy: 0.292969 / Validation Accuracy: 0.266\n",
      "Epoch: 1 / Batch: 57344/60000 / Cost: 0.287249 / Training Accuracy: 0.285156 / Validation Accuracy: 0.293\n",
      "Epoch: 1 / Batch: 57856/60000 / Cost: 0.277353 / Training Accuracy: 0.326172 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 58368/60000 / Cost: 0.285302 / Training Accuracy: 0.308594 / Validation Accuracy: 0.297\n",
      "Epoch: 1 / Batch: 58880/60000 / Cost: 0.28517 / Training Accuracy: 0.289063 / Validation Accuracy: 0.315\n",
      "Epoch: 1 / Batch: 59392/60000 / Cost: 0.286688 / Training Accuracy: 0.271484 / Validation Accuracy: 0.252\n",
      "Epoch: 1 / Batch: 59904/60000 / Cost: 0.278455 / Training Accuracy: 0.291667 / Validation Accuracy: 0.344\n",
      "Epoch: 2 / Batch: 0/60000 / Cost: 0.2834 / Training Accuracy: 0.283203 / Validation Accuracy: 0.329\n",
      "Epoch: 2 / Batch: 512/60000 / Cost: 0.279001 / Training Accuracy: 0.330078 / Validation Accuracy: 0.325\n",
      "Epoch: 2 / Batch: 1024/60000 / Cost: 0.286434 / Training Accuracy: 0.318359 / Validation Accuracy: 0.334\n",
      "Epoch: 2 / Batch: 1536/60000 / Cost: 0.280693 / Training Accuracy: 0.302734 / Validation Accuracy: 0.292\n",
      "Epoch: 2 / Batch: 2048/60000 / Cost: 0.26992 / Training Accuracy: 0.332031 / Validation Accuracy: 0.298\n",
      "Epoch: 2 / Batch: 2560/60000 / Cost: 0.282077 / Training Accuracy: 0.300781 / Validation Accuracy: 0.256\n",
      "Epoch: 2 / Batch: 3072/60000 / Cost: 0.272899 / Training Accuracy: 0.289063 / Validation Accuracy: 0.292\n",
      "Epoch: 2 / Batch: 3584/60000 / Cost: 0.283548 / Training Accuracy: 0.271484 / Validation Accuracy: 0.284\n",
      "Epoch: 2 / Batch: 4096/60000 / Cost: 0.280641 / Training Accuracy: 0.345703 / Validation Accuracy: 0.317\n",
      "Epoch: 2 / Batch: 4608/60000 / Cost: 0.269518 / Training Accuracy: 0.339844 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 5120/60000 / Cost: 0.281659 / Training Accuracy: 0.283203 / Validation Accuracy: 0.323\n",
      "Epoch: 2 / Batch: 5632/60000 / Cost: 0.269316 / Training Accuracy: 0.339844 / Validation Accuracy: 0.329\n",
      "Epoch: 2 / Batch: 6144/60000 / Cost: 0.272794 / Training Accuracy: 0.324219 / Validation Accuracy: 0.305\n",
      "Epoch: 2 / Batch: 6656/60000 / Cost: 0.273831 / Training Accuracy: 0.308594 / Validation Accuracy: 0.302\n",
      "Epoch: 2 / Batch: 7168/60000 / Cost: 0.263879 / Training Accuracy: 0.333984 / Validation Accuracy: 0.315\n",
      "Epoch: 2 / Batch: 7680/60000 / Cost: 0.268559 / Training Accuracy: 0.333984 / Validation Accuracy: 0.313\n",
      "Epoch: 2 / Batch: 8192/60000 / Cost: 0.26679 / Training Accuracy: 0.310547 / Validation Accuracy: 0.313\n",
      "Epoch: 2 / Batch: 8704/60000 / Cost: 0.273884 / Training Accuracy: 0.300781 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 9216/60000 / Cost: 0.265707 / Training Accuracy: 0.339844 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 9728/60000 / Cost: 0.258078 / Training Accuracy: 0.384766 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 10240/60000 / Cost: 0.26445 / Training Accuracy: 0.337891 / Validation Accuracy: 0.361\n",
      "Epoch: 2 / Batch: 10752/60000 / Cost: 0.260693 / Training Accuracy: 0.355469 / Validation Accuracy: 0.348\n",
      "Epoch: 2 / Batch: 11264/60000 / Cost: 0.260556 / Training Accuracy: 0.349609 / Validation Accuracy: 0.325\n",
      "Epoch: 2 / Batch: 11776/60000 / Cost: 0.258996 / Training Accuracy: 0.322266 / Validation Accuracy: 0.311\n",
      "Epoch: 2 / Batch: 12288/60000 / Cost: 0.252818 / Training Accuracy: 0.328125 / Validation Accuracy: 0.315\n",
      "Epoch: 2 / Batch: 12800/60000 / Cost: 0.254787 / Training Accuracy: 0.316406 / Validation Accuracy: 0.321\n",
      "Epoch: 2 / Batch: 13312/60000 / Cost: 0.25633 / Training Accuracy: 0.359375 / Validation Accuracy: 0.369\n",
      "Epoch: 2 / Batch: 13824/60000 / Cost: 0.246516 / Training Accuracy: 0.412109 / Validation Accuracy: 0.378\n",
      "Epoch: 2 / Batch: 14336/60000 / Cost: 0.250173 / Training Accuracy: 0.378906 / Validation Accuracy: 0.371\n",
      "Epoch: 2 / Batch: 14848/60000 / Cost: 0.246649 / Training Accuracy: 0.367188 / Validation Accuracy: 0.351\n",
      "Epoch: 2 / Batch: 15360/60000 / Cost: 0.253249 / Training Accuracy: 0.386719 / Validation Accuracy: 0.363\n",
      "Epoch: 2 / Batch: 15872/60000 / Cost: 0.237967 / Training Accuracy: 0.396484 / Validation Accuracy: 0.351\n",
      "Epoch: 2 / Batch: 16384/60000 / Cost: 0.24003 / Training Accuracy: 0.431641 / Validation Accuracy: 0.378\n",
      "Epoch: 2 / Batch: 16896/60000 / Cost: 0.252953 / Training Accuracy: 0.335938 / Validation Accuracy: 0.367\n",
      "Epoch: 2 / Batch: 17408/60000 / Cost: 0.245496 / Training Accuracy: 0.388672 / Validation Accuracy: 0.368\n",
      "Epoch: 2 / Batch: 17920/60000 / Cost: 0.244048 / Training Accuracy: 0.443359 / Validation Accuracy: 0.412\n",
      "Epoch: 2 / Batch: 18432/60000 / Cost: 0.253731 / Training Accuracy: 0.388672 / Validation Accuracy: 0.403\n",
      "Epoch: 2 / Batch: 18944/60000 / Cost: 0.240684 / Training Accuracy: 0.382813 / Validation Accuracy: 0.397\n",
      "Epoch: 2 / Batch: 19456/60000 / Cost: 0.248746 / Training Accuracy: 0.380859 / Validation Accuracy: 0.392\n",
      "Epoch: 2 / Batch: 19968/60000 / Cost: 0.24494 / Training Accuracy: 0.425781 / Validation Accuracy: 0.406\n",
      "Epoch: 2 / Batch: 20480/60000 / Cost: 0.245996 / Training Accuracy: 0.404297 / Validation Accuracy: 0.402\n",
      "Epoch: 2 / Batch: 20992/60000 / Cost: 0.242424 / Training Accuracy: 0.410156 / Validation Accuracy: 0.368\n",
      "Epoch: 2 / Batch: 21504/60000 / Cost: 0.238199 / Training Accuracy: 0.429688 / Validation Accuracy: 0.391\n",
      "Epoch: 2 / Batch: 22016/60000 / Cost: 0.245558 / Training Accuracy: 0.410156 / Validation Accuracy: 0.406\n",
      "Epoch: 2 / Batch: 22528/60000 / Cost: 0.251622 / Training Accuracy: 0.427734 / Validation Accuracy: 0.411\n",
      "Epoch: 2 / Batch: 23040/60000 / Cost: 0.24345 / Training Accuracy: 0.412109 / Validation Accuracy: 0.381\n",
      "Epoch: 2 / Batch: 23552/60000 / Cost: 0.228713 / Training Accuracy: 0.466797 / Validation Accuracy: 0.425\n",
      "Epoch: 2 / Batch: 24064/60000 / Cost: 0.238539 / Training Accuracy: 0.455078 / Validation Accuracy: 0.439\n",
      "Epoch: 2 / Batch: 24576/60000 / Cost: 0.241338 / Training Accuracy: 0.449219 / Validation Accuracy: 0.428\n",
      "Epoch: 2 / Batch: 25088/60000 / Cost: 0.233632 / Training Accuracy: 0.484375 / Validation Accuracy: 0.456\n",
      "Epoch: 2 / Batch: 25600/60000 / Cost: 0.246893 / Training Accuracy: 0.421875 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 26112/60000 / Cost: 0.230541 / Training Accuracy: 0.492188 / Validation Accuracy: 0.474\n",
      "Epoch: 2 / Batch: 26624/60000 / Cost: 0.236667 / Training Accuracy: 0.462891 / Validation Accuracy: 0.437\n",
      "Epoch: 2 / Batch: 27136/60000 / Cost: 0.238137 / Training Accuracy: 0.408203 / Validation Accuracy: 0.402\n",
      "Epoch: 2 / Batch: 27648/60000 / Cost: 0.231329 / Training Accuracy: 0.453125 / Validation Accuracy: 0.421\n",
      "Epoch: 2 / Batch: 28160/60000 / Cost: 0.22576 / Training Accuracy: 0.439453 / Validation Accuracy: 0.424\n",
      "Epoch: 2 / Batch: 28672/60000 / Cost: 0.220679 / Training Accuracy: 0.441406 / Validation Accuracy: 0.433\n",
      "Epoch: 2 / Batch: 29184/60000 / Cost: 0.23101 / Training Accuracy: 0.447266 / Validation Accuracy: 0.433\n",
      "Epoch: 2 / Batch: 29696/60000 / Cost: 0.228399 / Training Accuracy: 0.453125 / Validation Accuracy: 0.439\n",
      "Epoch: 2 / Batch: 30208/60000 / Cost: 0.219627 / Training Accuracy: 0.503906 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 30720/60000 / Cost: 0.217916 / Training Accuracy: 0.472656 / Validation Accuracy: 0.457\n",
      "Epoch: 2 / Batch: 31232/60000 / Cost: 0.231766 / Training Accuracy: 0.494141 / Validation Accuracy: 0.472\n",
      "Epoch: 2 / Batch: 31744/60000 / Cost: 0.226143 / Training Accuracy: 0.501953 / Validation Accuracy: 0.471\n",
      "Epoch: 2 / Batch: 32256/60000 / Cost: 0.228499 / Training Accuracy: 0.501953 / Validation Accuracy: 0.447\n",
      "Epoch: 2 / Batch: 32768/60000 / Cost: 0.215749 / Training Accuracy: 0.511719 / Validation Accuracy: 0.474\n",
      "Epoch: 2 / Batch: 33280/60000 / Cost: 0.235218 / Training Accuracy: 0.443359 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 33792/60000 / Cost: 0.217136 / Training Accuracy: 0.5 / Validation Accuracy: 0.454\n",
      "Epoch: 2 / Batch: 34304/60000 / Cost: 0.215386 / Training Accuracy: 0.476563 / Validation Accuracy: 0.421\n",
      "Epoch: 2 / Batch: 34816/60000 / Cost: 0.213421 / Training Accuracy: 0.5 / Validation Accuracy: 0.446\n",
      "Epoch: 2 / Batch: 35328/60000 / Cost: 0.218047 / Training Accuracy: 0.496094 / Validation Accuracy: 0.463\n",
      "Epoch: 2 / Batch: 35840/60000 / Cost: 0.216692 / Training Accuracy: 0.521484 / Validation Accuracy: 0.483\n",
      "Epoch: 2 / Batch: 36352/60000 / Cost: 0.226184 / Training Accuracy: 0.439453 / Validation Accuracy: 0.453\n",
      "Epoch: 2 / Batch: 36864/60000 / Cost: 0.208009 / Training Accuracy: 0.529297 / Validation Accuracy: 0.475\n",
      "Epoch: 2 / Batch: 37376/60000 / Cost: 0.219073 / Training Accuracy: 0.521484 / Validation Accuracy: 0.471\n",
      "Epoch: 2 / Batch: 37888/60000 / Cost: 0.2139 / Training Accuracy: 0.503906 / Validation Accuracy: 0.477\n",
      "Epoch: 2 / Batch: 38400/60000 / Cost: 0.218599 / Training Accuracy: 0.486328 / Validation Accuracy: 0.473\n",
      "Epoch: 2 / Batch: 38912/60000 / Cost: 0.221732 / Training Accuracy: 0.480469 / Validation Accuracy: 0.473\n",
      "Epoch: 2 / Batch: 39424/60000 / Cost: 0.207993 / Training Accuracy: 0.546875 / Validation Accuracy: 0.481\n",
      "Epoch: 2 / Batch: 39936/60000 / Cost: 0.224544 / Training Accuracy: 0.5 / Validation Accuracy: 0.488\n",
      "Epoch: 2 / Batch: 40448/60000 / Cost: 0.209684 / Training Accuracy: 0.523438 / Validation Accuracy: 0.497\n",
      "Epoch: 2 / Batch: 40960/60000 / Cost: 0.206504 / Training Accuracy: 0.578125 / Validation Accuracy: 0.498\n",
      "Epoch: 2 / Batch: 41472/60000 / Cost: 0.207168 / Training Accuracy: 0.527344 / Validation Accuracy: 0.509\n",
      "Epoch: 2 / Batch: 41984/60000 / Cost: 0.212541 / Training Accuracy: 0.498047 / Validation Accuracy: 0.508\n",
      "Epoch: 2 / Batch: 42496/60000 / Cost: 0.206788 / Training Accuracy: 0.513672 / Validation Accuracy: 0.478\n",
      "Epoch: 2 / Batch: 43008/60000 / Cost: 0.20837 / Training Accuracy: 0.542969 / Validation Accuracy: 0.463\n",
      "Epoch: 2 / Batch: 43520/60000 / Cost: 0.231144 / Training Accuracy: 0.460938 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 44032/60000 / Cost: 0.199432 / Training Accuracy: 0.535156 / Validation Accuracy: 0.53\n",
      "Epoch: 2 / Batch: 44544/60000 / Cost: 0.206956 / Training Accuracy: 0.501953 / Validation Accuracy: 0.465\n",
      "Epoch: 2 / Batch: 45056/60000 / Cost: 0.210648 / Training Accuracy: 0.552734 / Validation Accuracy: 0.483\n",
      "Epoch: 2 / Batch: 45568/60000 / Cost: 0.211709 / Training Accuracy: 0.558594 / Validation Accuracy: 0.533\n",
      "Epoch: 2 / Batch: 46080/60000 / Cost: 0.194347 / Training Accuracy: 0.595703 / Validation Accuracy: 0.537\n",
      "Epoch: 2 / Batch: 46592/60000 / Cost: 0.206172 / Training Accuracy: 0.541016 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 47104/60000 / Cost: 0.20741 / Training Accuracy: 0.507813 / Validation Accuracy: 0.493\n",
      "Epoch: 2 / Batch: 47616/60000 / Cost: 0.197223 / Training Accuracy: 0.525391 / Validation Accuracy: 0.493\n",
      "Epoch: 2 / Batch: 48128/60000 / Cost: 0.197912 / Training Accuracy: 0.554688 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 48640/60000 / Cost: 0.197526 / Training Accuracy: 0.527344 / Validation Accuracy: 0.515\n",
      "Epoch: 2 / Batch: 49152/60000 / Cost: 0.197027 / Training Accuracy: 0.613281 / Validation Accuracy: 0.545\n",
      "Epoch: 2 / Batch: 49664/60000 / Cost: 0.19097 / Training Accuracy: 0.601563 / Validation Accuracy: 0.522\n",
      "Epoch: 2 / Batch: 50176/60000 / Cost: 0.195455 / Training Accuracy: 0.568359 / Validation Accuracy: 0.536\n",
      "Epoch: 2 / Batch: 50688/60000 / Cost: 0.189906 / Training Accuracy: 0.560547 / Validation Accuracy: 0.541\n",
      "Epoch: 2 / Batch: 51200/60000 / Cost: 0.191066 / Training Accuracy: 0.582031 / Validation Accuracy: 0.531\n",
      "Epoch: 2 / Batch: 51712/60000 / Cost: 0.186983 / Training Accuracy: 0.603516 / Validation Accuracy: 0.568\n",
      "Epoch: 2 / Batch: 52224/60000 / Cost: 0.183167 / Training Accuracy: 0.628906 / Validation Accuracy: 0.602\n",
      "Epoch: 2 / Batch: 52736/60000 / Cost: 0.186058 / Training Accuracy: 0.634766 / Validation Accuracy: 0.605\n",
      "Epoch: 2 / Batch: 53248/60000 / Cost: 0.18486 / Training Accuracy: 0.613281 / Validation Accuracy: 0.586\n",
      "Epoch: 2 / Batch: 53760/60000 / Cost: 0.176066 / Training Accuracy: 0.634766 / Validation Accuracy: 0.599\n",
      "Epoch: 2 / Batch: 54272/60000 / Cost: 0.16554 / Training Accuracy: 0.685547 / Validation Accuracy: 0.593\n",
      "Epoch: 2 / Batch: 54784/60000 / Cost: 0.177485 / Training Accuracy: 0.644531 / Validation Accuracy: 0.588\n",
      "Epoch: 2 / Batch: 55296/60000 / Cost: 0.179964 / Training Accuracy: 0.632813 / Validation Accuracy: 0.574\n",
      "Epoch: 2 / Batch: 55808/60000 / Cost: 0.180047 / Training Accuracy: 0.630859 / Validation Accuracy: 0.579\n",
      "Epoch: 2 / Batch: 56320/60000 / Cost: 0.177458 / Training Accuracy: 0.652344 / Validation Accuracy: 0.588\n",
      "Epoch: 2 / Batch: 56832/60000 / Cost: 0.177204 / Training Accuracy: 0.636719 / Validation Accuracy: 0.571\n",
      "Epoch: 2 / Batch: 57344/60000 / Cost: 0.169549 / Training Accuracy: 0.621094 / Validation Accuracy: 0.599\n",
      "Epoch: 2 / Batch: 57856/60000 / Cost: 0.174142 / Training Accuracy: 0.673828 / Validation Accuracy: 0.612\n",
      "Epoch: 2 / Batch: 58368/60000 / Cost: 0.163912 / Training Accuracy: 0.669922 / Validation Accuracy: 0.627\n",
      "Epoch: 2 / Batch: 58880/60000 / Cost: 0.170798 / Training Accuracy: 0.666016 / Validation Accuracy: 0.617\n",
      "Epoch: 2 / Batch: 59392/60000 / Cost: 0.15778 / Training Accuracy: 0.689453 / Validation Accuracy: 0.644\n",
      "Epoch: 2 / Batch: 59904/60000 / Cost: 0.159432 / Training Accuracy: 0.645833 / Validation Accuracy: 0.589\n",
      "Epoch: 3 / Batch: 0/60000 / Cost: 0.170188 / Training Accuracy: 0.658203 / Validation Accuracy: 0.648\n",
      "Epoch: 3 / Batch: 512/60000 / Cost: 0.160762 / Training Accuracy: 0.701172 / Validation Accuracy: 0.649\n",
      "Epoch: 3 / Batch: 1024/60000 / Cost: 0.164794 / Training Accuracy: 0.689453 / Validation Accuracy: 0.632\n",
      "Epoch: 3 / Batch: 1536/60000 / Cost: 0.166778 / Training Accuracy: 0.673828 / Validation Accuracy: 0.634\n",
      "Epoch: 3 / Batch: 2048/60000 / Cost: 0.156638 / Training Accuracy: 0.677734 / Validation Accuracy: 0.613\n",
      "Epoch: 3 / Batch: 2560/60000 / Cost: 0.17159 / Training Accuracy: 0.636719 / Validation Accuracy: 0.612\n",
      "Epoch: 3 / Batch: 3072/60000 / Cost: 0.152372 / Training Accuracy: 0.681641 / Validation Accuracy: 0.644\n",
      "Epoch: 3 / Batch: 3584/60000 / Cost: 0.154107 / Training Accuracy: 0.677734 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 4096/60000 / Cost: 0.149836 / Training Accuracy: 0.697266 / Validation Accuracy: 0.639\n",
      "Epoch: 3 / Batch: 4608/60000 / Cost: 0.154052 / Training Accuracy: 0.675781 / Validation Accuracy: 0.664\n",
      "Epoch: 3 / Batch: 5120/60000 / Cost: 0.153737 / Training Accuracy: 0.712891 / Validation Accuracy: 0.655\n",
      "Epoch: 3 / Batch: 5632/60000 / Cost: 0.162657 / Training Accuracy: 0.669922 / Validation Accuracy: 0.638\n",
      "Epoch: 3 / Batch: 6144/60000 / Cost: 0.153533 / Training Accuracy: 0.632813 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 6656/60000 / Cost: 0.151778 / Training Accuracy: 0.710938 / Validation Accuracy: 0.646\n",
      "Epoch: 3 / Batch: 7168/60000 / Cost: 0.151695 / Training Accuracy: 0.728516 / Validation Accuracy: 0.668\n",
      "Epoch: 3 / Batch: 7680/60000 / Cost: 0.147496 / Training Accuracy: 0.695313 / Validation Accuracy: 0.647\n",
      "Epoch: 3 / Batch: 8192/60000 / Cost: 0.136275 / Training Accuracy: 0.734375 / Validation Accuracy: 0.671\n",
      "Epoch: 3 / Batch: 8704/60000 / Cost: 0.14349 / Training Accuracy: 0.726563 / Validation Accuracy: 0.671\n",
      "Epoch: 3 / Batch: 9216/60000 / Cost: 0.141499 / Training Accuracy: 0.732422 / Validation Accuracy: 0.67\n",
      "Epoch: 3 / Batch: 9728/60000 / Cost: 0.147089 / Training Accuracy: 0.697266 / Validation Accuracy: 0.649\n",
      "Epoch: 3 / Batch: 10240/60000 / Cost: 0.138424 / Training Accuracy: 0.742188 / Validation Accuracy: 0.683\n",
      "Epoch: 3 / Batch: 10752/60000 / Cost: 0.140899 / Training Accuracy: 0.71875 / Validation Accuracy: 0.697\n",
      "Epoch: 3 / Batch: 11264/60000 / Cost: 0.138323 / Training Accuracy: 0.75 / Validation Accuracy: 0.706\n",
      "Epoch: 3 / Batch: 11776/60000 / Cost: 0.140328 / Training Accuracy: 0.728516 / Validation Accuracy: 0.711\n",
      "Epoch: 3 / Batch: 12288/60000 / Cost: 0.121597 / Training Accuracy: 0.777344 / Validation Accuracy: 0.702\n",
      "Epoch: 3 / Batch: 12800/60000 / Cost: 0.142618 / Training Accuracy: 0.712891 / Validation Accuracy: 0.69\n",
      "Epoch: 3 / Batch: 13312/60000 / Cost: 0.132739 / Training Accuracy: 0.726563 / Validation Accuracy: 0.678\n",
      "Epoch: 3 / Batch: 13824/60000 / Cost: 0.128679 / Training Accuracy: 0.757813 / Validation Accuracy: 0.712\n",
      "Epoch: 3 / Batch: 14336/60000 / Cost: 0.123407 / Training Accuracy: 0.78125 / Validation Accuracy: 0.697\n",
      "Epoch: 3 / Batch: 14848/60000 / Cost: 0.129548 / Training Accuracy: 0.744141 / Validation Accuracy: 0.669\n",
      "Epoch: 3 / Batch: 15360/60000 / Cost: 0.119908 / Training Accuracy: 0.787109 / Validation Accuracy: 0.711\n",
      "Epoch: 3 / Batch: 15872/60000 / Cost: 0.12118 / Training Accuracy: 0.761719 / Validation Accuracy: 0.711\n",
      "Epoch: 3 / Batch: 16384/60000 / Cost: 0.1235 / Training Accuracy: 0.757813 / Validation Accuracy: 0.685\n",
      "Epoch: 3 / Batch: 16896/60000 / Cost: 0.139898 / Training Accuracy: 0.722656 / Validation Accuracy: 0.662\n",
      "Epoch: 3 / Batch: 17408/60000 / Cost: 0.126013 / Training Accuracy: 0.755859 / Validation Accuracy: 0.717\n",
      "Epoch: 3 / Batch: 17920/60000 / Cost: 0.135582 / Training Accuracy: 0.753906 / Validation Accuracy: 0.692\n",
      "Epoch: 3 / Batch: 18432/60000 / Cost: 0.12888 / Training Accuracy: 0.728516 / Validation Accuracy: 0.736\n",
      "Epoch: 3 / Batch: 18944/60000 / Cost: 0.127567 / Training Accuracy: 0.748047 / Validation Accuracy: 0.71\n",
      "Epoch: 3 / Batch: 19456/60000 / Cost: 0.117593 / Training Accuracy: 0.773438 / Validation Accuracy: 0.737\n",
      "Epoch: 3 / Batch: 19968/60000 / Cost: 0.12405 / Training Accuracy: 0.757813 / Validation Accuracy: 0.717\n",
      "Epoch: 3 / Batch: 20480/60000 / Cost: 0.129144 / Training Accuracy: 0.775391 / Validation Accuracy: 0.737\n",
      "Epoch: 3 / Batch: 20992/60000 / Cost: 0.114017 / Training Accuracy: 0.78125 / Validation Accuracy: 0.747\n",
      "Epoch: 3 / Batch: 21504/60000 / Cost: 0.120239 / Training Accuracy: 0.738281 / Validation Accuracy: 0.71\n",
      "Epoch: 3 / Batch: 22016/60000 / Cost: 0.119814 / Training Accuracy: 0.767578 / Validation Accuracy: 0.726\n",
      "Epoch: 3 / Batch: 22528/60000 / Cost: 0.108069 / Training Accuracy: 0.802734 / Validation Accuracy: 0.737\n",
      "Epoch: 3 / Batch: 23040/60000 / Cost: 0.116698 / Training Accuracy: 0.779297 / Validation Accuracy: 0.703\n",
      "Epoch: 3 / Batch: 23552/60000 / Cost: 0.114656 / Training Accuracy: 0.773438 / Validation Accuracy: 0.753\n",
      "Epoch: 3 / Batch: 24064/60000 / Cost: 0.117233 / Training Accuracy: 0.779297 / Validation Accuracy: 0.761\n",
      "Epoch: 3 / Batch: 24576/60000 / Cost: 0.114317 / Training Accuracy: 0.800781 / Validation Accuracy: 0.752\n",
      "Epoch: 3 / Batch: 25088/60000 / Cost: 0.111726 / Training Accuracy: 0.78125 / Validation Accuracy: 0.694\n",
      "Epoch: 3 / Batch: 25600/60000 / Cost: 0.128557 / Training Accuracy: 0.742188 / Validation Accuracy: 0.687\n",
      "Epoch: 3 / Batch: 26112/60000 / Cost: 0.106982 / Training Accuracy: 0.796875 / Validation Accuracy: 0.748\n",
      "Epoch: 3 / Batch: 26624/60000 / Cost: 0.122486 / Training Accuracy: 0.765625 / Validation Accuracy: 0.745\n",
      "Epoch: 3 / Batch: 27136/60000 / Cost: 0.117848 / Training Accuracy: 0.761719 / Validation Accuracy: 0.745\n",
      "Epoch: 3 / Batch: 27648/60000 / Cost: 0.119716 / Training Accuracy: 0.763672 / Validation Accuracy: 0.742\n",
      "Epoch: 3 / Batch: 28160/60000 / Cost: 0.102624 / Training Accuracy: 0.810547 / Validation Accuracy: 0.753\n",
      "Epoch: 3 / Batch: 28672/60000 / Cost: 0.111495 / Training Accuracy: 0.787109 / Validation Accuracy: 0.742\n",
      "Epoch: 3 / Batch: 29184/60000 / Cost: 0.118035 / Training Accuracy: 0.779297 / Validation Accuracy: 0.766\n",
      "Epoch: 3 / Batch: 29696/60000 / Cost: 0.112588 / Training Accuracy: 0.783203 / Validation Accuracy: 0.741\n",
      "Epoch: 3 / Batch: 30208/60000 / Cost: 0.120307 / Training Accuracy: 0.767578 / Validation Accuracy: 0.757\n",
      "Epoch: 3 / Batch: 30720/60000 / Cost: 0.11792 / Training Accuracy: 0.753906 / Validation Accuracy: 0.754\n",
      "Epoch: 3 / Batch: 31232/60000 / Cost: 0.106373 / Training Accuracy: 0.808594 / Validation Accuracy: 0.765\n",
      "Epoch: 3 / Batch: 31744/60000 / Cost: 0.112357 / Training Accuracy: 0.787109 / Validation Accuracy: 0.758\n",
      "Epoch: 3 / Batch: 32256/60000 / Cost: 0.111033 / Training Accuracy: 0.787109 / Validation Accuracy: 0.757\n",
      "Epoch: 3 / Batch: 32768/60000 / Cost: 0.110012 / Training Accuracy: 0.785156 / Validation Accuracy: 0.773\n",
      "Epoch: 3 / Batch: 33280/60000 / Cost: 0.108553 / Training Accuracy: 0.810547 / Validation Accuracy: 0.776\n",
      "Epoch: 3 / Batch: 33792/60000 / Cost: 0.107306 / Training Accuracy: 0.800781 / Validation Accuracy: 0.775\n",
      "Epoch: 3 / Batch: 34304/60000 / Cost: 0.0923967 / Training Accuracy: 0.847656 / Validation Accuracy: 0.775\n",
      "Epoch: 3 / Batch: 34816/60000 / Cost: 0.1026 / Training Accuracy: 0.808594 / Validation Accuracy: 0.779\n",
      "Epoch: 3 / Batch: 35328/60000 / Cost: 0.112558 / Training Accuracy: 0.783203 / Validation Accuracy: 0.763\n",
      "Epoch: 3 / Batch: 35840/60000 / Cost: 0.109504 / Training Accuracy: 0.794922 / Validation Accuracy: 0.782\n",
      "Epoch: 3 / Batch: 36352/60000 / Cost: 0.103535 / Training Accuracy: 0.806641 / Validation Accuracy: 0.799\n",
      "Epoch: 3 / Batch: 36864/60000 / Cost: 0.100316 / Training Accuracy: 0.810547 / Validation Accuracy: 0.794\n",
      "Epoch: 3 / Batch: 37376/60000 / Cost: 0.0977998 / Training Accuracy: 0.828125 / Validation Accuracy: 0.775\n",
      "Epoch: 3 / Batch: 37888/60000 / Cost: 0.0942845 / Training Accuracy: 0.822266 / Validation Accuracy: 0.785\n",
      "Epoch: 3 / Batch: 38400/60000 / Cost: 0.0892533 / Training Accuracy: 0.841797 / Validation Accuracy: 0.762\n",
      "Epoch: 3 / Batch: 38912/60000 / Cost: 0.0988442 / Training Accuracy: 0.835938 / Validation Accuracy: 0.787\n",
      "Epoch: 3 / Batch: 39424/60000 / Cost: 0.106754 / Training Accuracy: 0.783203 / Validation Accuracy: 0.808\n",
      "Epoch: 3 / Batch: 39936/60000 / Cost: 0.0999103 / Training Accuracy: 0.8125 / Validation Accuracy: 0.804\n",
      "Epoch: 3 / Batch: 40448/60000 / Cost: 0.102438 / Training Accuracy: 0.818359 / Validation Accuracy: 0.798\n",
      "Epoch: 3 / Batch: 40960/60000 / Cost: 0.0950686 / Training Accuracy: 0.837891 / Validation Accuracy: 0.822\n",
      "Epoch: 3 / Batch: 41472/60000 / Cost: 0.0967701 / Training Accuracy: 0.826172 / Validation Accuracy: 0.817\n",
      "Epoch: 3 / Batch: 41984/60000 / Cost: 0.0960648 / Training Accuracy: 0.818359 / Validation Accuracy: 0.799\n",
      "Epoch: 3 / Batch: 42496/60000 / Cost: 0.103292 / Training Accuracy: 0.798828 / Validation Accuracy: 0.801\n",
      "Epoch: 3 / Batch: 43008/60000 / Cost: 0.0894959 / Training Accuracy: 0.833984 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 43520/60000 / Cost: 0.100137 / Training Accuracy: 0.816406 / Validation Accuracy: 0.809\n",
      "Epoch: 3 / Batch: 44032/60000 / Cost: 0.0899791 / Training Accuracy: 0.857422 / Validation Accuracy: 0.806\n",
      "Epoch: 3 / Batch: 44544/60000 / Cost: 0.106723 / Training Accuracy: 0.800781 / Validation Accuracy: 0.775\n",
      "Epoch: 3 / Batch: 45056/60000 / Cost: 0.0928287 / Training Accuracy: 0.845703 / Validation Accuracy: 0.824\n",
      "Epoch: 3 / Batch: 45568/60000 / Cost: 0.0998747 / Training Accuracy: 0.808594 / Validation Accuracy: 0.779\n",
      "Epoch: 3 / Batch: 46080/60000 / Cost: 0.0918233 / Training Accuracy: 0.845703 / Validation Accuracy: 0.808\n",
      "Epoch: 3 / Batch: 46592/60000 / Cost: 0.0992567 / Training Accuracy: 0.808594 / Validation Accuracy: 0.797\n",
      "Epoch: 3 / Batch: 47104/60000 / Cost: 0.084623 / Training Accuracy: 0.865234 / Validation Accuracy: 0.832\n",
      "Epoch: 3 / Batch: 47616/60000 / Cost: 0.103662 / Training Accuracy: 0.792969 / Validation Accuracy: 0.799\n",
      "Epoch: 3 / Batch: 48128/60000 / Cost: 0.086925 / Training Accuracy: 0.853516 / Validation Accuracy: 0.819\n",
      "Epoch: 3 / Batch: 48640/60000 / Cost: 0.0896503 / Training Accuracy: 0.828125 / Validation Accuracy: 0.834\n",
      "Epoch: 3 / Batch: 49152/60000 / Cost: 0.0962738 / Training Accuracy: 0.806641 / Validation Accuracy: 0.819\n",
      "Epoch: 3 / Batch: 49664/60000 / Cost: 0.0891768 / Training Accuracy: 0.855469 / Validation Accuracy: 0.829\n",
      "Epoch: 3 / Batch: 50176/60000 / Cost: 0.0875711 / Training Accuracy: 0.861328 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 50688/60000 / Cost: 0.0838954 / Training Accuracy: 0.837891 / Validation Accuracy: 0.824\n",
      "Epoch: 3 / Batch: 51200/60000 / Cost: 0.086089 / Training Accuracy: 0.845703 / Validation Accuracy: 0.823\n",
      "Epoch: 3 / Batch: 51712/60000 / Cost: 0.0921708 / Training Accuracy: 0.84375 / Validation Accuracy: 0.834\n",
      "Epoch: 3 / Batch: 52224/60000 / Cost: 0.0890075 / Training Accuracy: 0.839844 / Validation Accuracy: 0.805\n",
      "Epoch: 3 / Batch: 52736/60000 / Cost: 0.0817801 / Training Accuracy: 0.857422 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 53248/60000 / Cost: 0.0915769 / Training Accuracy: 0.835938 / Validation Accuracy: 0.838\n",
      "Epoch: 3 / Batch: 53760/60000 / Cost: 0.0906755 / Training Accuracy: 0.833984 / Validation Accuracy: 0.815\n",
      "Epoch: 3 / Batch: 54272/60000 / Cost: 0.0929765 / Training Accuracy: 0.833984 / Validation Accuracy: 0.846\n",
      "Epoch: 3 / Batch: 54784/60000 / Cost: 0.0837684 / Training Accuracy: 0.845703 / Validation Accuracy: 0.846\n",
      "Epoch: 3 / Batch: 55296/60000 / Cost: 0.0919215 / Training Accuracy: 0.822266 / Validation Accuracy: 0.857\n",
      "Epoch: 3 / Batch: 55808/60000 / Cost: 0.0964627 / Training Accuracy: 0.796875 / Validation Accuracy: 0.855\n",
      "Epoch: 3 / Batch: 56320/60000 / Cost: 0.085899 / Training Accuracy: 0.857422 / Validation Accuracy: 0.847\n",
      "Epoch: 3 / Batch: 56832/60000 / Cost: 0.0820661 / Training Accuracy: 0.876953 / Validation Accuracy: 0.851\n",
      "Epoch: 3 / Batch: 57344/60000 / Cost: 0.0819881 / Training Accuracy: 0.857422 / Validation Accuracy: 0.852\n",
      "Epoch: 3 / Batch: 57856/60000 / Cost: 0.0767917 / Training Accuracy: 0.867188 / Validation Accuracy: 0.838\n",
      "Epoch: 3 / Batch: 58368/60000 / Cost: 0.0745802 / Training Accuracy: 0.876953 / Validation Accuracy: 0.853\n",
      "Epoch: 3 / Batch: 58880/60000 / Cost: 0.0927235 / Training Accuracy: 0.845703 / Validation Accuracy: 0.844\n",
      "Epoch: 3 / Batch: 59392/60000 / Cost: 0.0835439 / Training Accuracy: 0.833984 / Validation Accuracy: 0.845\n",
      "Epoch: 3 / Batch: 59904/60000 / Cost: 0.0766286 / Training Accuracy: 0.885417 / Validation Accuracy: 0.805\n",
      "Epoch: 4 / Batch: 0/60000 / Cost: 0.0886032 / Training Accuracy: 0.830078 / Validation Accuracy: 0.799\n",
      "Epoch: 4 / Batch: 512/60000 / Cost: 0.0768565 / Training Accuracy: 0.869141 / Validation Accuracy: 0.857\n",
      "Epoch: 4 / Batch: 1024/60000 / Cost: 0.0835286 / Training Accuracy: 0.839844 / Validation Accuracy: 0.835\n",
      "Epoch: 4 / Batch: 1536/60000 / Cost: 0.076215 / Training Accuracy: 0.869141 / Validation Accuracy: 0.853\n",
      "Epoch: 4 / Batch: 2048/60000 / Cost: 0.0770311 / Training Accuracy: 0.865234 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 2560/60000 / Cost: 0.0682322 / Training Accuracy: 0.875 / Validation Accuracy: 0.839\n",
      "Epoch: 4 / Batch: 3072/60000 / Cost: 0.0800342 / Training Accuracy: 0.861328 / Validation Accuracy: 0.851\n",
      "Epoch: 4 / Batch: 3584/60000 / Cost: 0.0697896 / Training Accuracy: 0.890625 / Validation Accuracy: 0.857\n",
      "Epoch: 4 / Batch: 4096/60000 / Cost: 0.0752643 / Training Accuracy: 0.871094 / Validation Accuracy: 0.847\n",
      "Epoch: 4 / Batch: 4608/60000 / Cost: 0.075109 / Training Accuracy: 0.878906 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 5120/60000 / Cost: 0.0746141 / Training Accuracy: 0.873047 / Validation Accuracy: 0.843\n",
      "Epoch: 4 / Batch: 5632/60000 / Cost: 0.0685958 / Training Accuracy: 0.880859 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 6144/60000 / Cost: 0.0725318 / Training Accuracy: 0.875 / Validation Accuracy: 0.847\n",
      "Epoch: 4 / Batch: 6656/60000 / Cost: 0.0740909 / Training Accuracy: 0.880859 / Validation Accuracy: 0.869\n",
      "Epoch: 4 / Batch: 7168/60000 / Cost: 0.076017 / Training Accuracy: 0.845703 / Validation Accuracy: 0.851\n",
      "Epoch: 4 / Batch: 7680/60000 / Cost: 0.0686063 / Training Accuracy: 0.880859 / Validation Accuracy: 0.854\n",
      "Epoch: 4 / Batch: 8192/60000 / Cost: 0.067919 / Training Accuracy: 0.886719 / Validation Accuracy: 0.868\n",
      "Epoch: 4 / Batch: 8704/60000 / Cost: 0.073402 / Training Accuracy: 0.873047 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 9216/60000 / Cost: 0.0631958 / Training Accuracy: 0.902344 / Validation Accuracy: 0.873\n",
      "Epoch: 4 / Batch: 9728/60000 / Cost: 0.0545016 / Training Accuracy: 0.921875 / Validation Accuracy: 0.887\n",
      "Epoch: 4 / Batch: 10240/60000 / Cost: 0.0673498 / Training Accuracy: 0.878906 / Validation Accuracy: 0.879\n",
      "Epoch: 4 / Batch: 10752/60000 / Cost: 0.0713963 / Training Accuracy: 0.880859 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 11264/60000 / Cost: 0.0683741 / Training Accuracy: 0.886719 / Validation Accuracy: 0.865\n",
      "Epoch: 4 / Batch: 11776/60000 / Cost: 0.0637542 / Training Accuracy: 0.900391 / Validation Accuracy: 0.873\n",
      "Epoch: 4 / Batch: 12288/60000 / Cost: 0.062263 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 12800/60000 / Cost: 0.0587314 / Training Accuracy: 0.916016 / Validation Accuracy: 0.885\n",
      "Epoch: 4 / Batch: 13312/60000 / Cost: 0.0642811 / Training Accuracy: 0.902344 / Validation Accuracy: 0.878\n",
      "Epoch: 4 / Batch: 13824/60000 / Cost: 0.0666132 / Training Accuracy: 0.884766 / Validation Accuracy: 0.869\n",
      "Epoch: 4 / Batch: 14336/60000 / Cost: 0.064465 / Training Accuracy: 0.882813 / Validation Accuracy: 0.873\n",
      "Epoch: 4 / Batch: 14848/60000 / Cost: 0.0590089 / Training Accuracy: 0.908203 / Validation Accuracy: 0.874\n",
      "Epoch: 4 / Batch: 15360/60000 / Cost: 0.058992 / Training Accuracy: 0.894531 / Validation Accuracy: 0.871\n",
      "Epoch: 4 / Batch: 15872/60000 / Cost: 0.0655056 / Training Accuracy: 0.898438 / Validation Accuracy: 0.866\n",
      "Epoch: 4 / Batch: 16384/60000 / Cost: 0.0755546 / Training Accuracy: 0.871094 / Validation Accuracy: 0.863\n",
      "Epoch: 4 / Batch: 16896/60000 / Cost: 0.0695219 / Training Accuracy: 0.876953 / Validation Accuracy: 0.877\n",
      "Epoch: 4 / Batch: 17408/60000 / Cost: 0.0572823 / Training Accuracy: 0.912109 / Validation Accuracy: 0.875\n",
      "Epoch: 4 / Batch: 17920/60000 / Cost: 0.0567991 / Training Accuracy: 0.902344 / Validation Accuracy: 0.857\n",
      "Epoch: 4 / Batch: 18432/60000 / Cost: 0.062153 / Training Accuracy: 0.882813 / Validation Accuracy: 0.867\n",
      "Epoch: 4 / Batch: 18944/60000 / Cost: 0.0648176 / Training Accuracy: 0.900391 / Validation Accuracy: 0.867\n",
      "Epoch: 4 / Batch: 19456/60000 / Cost: 0.065258 / Training Accuracy: 0.886719 / Validation Accuracy: 0.867\n",
      "Epoch: 4 / Batch: 19968/60000 / Cost: 0.0713886 / Training Accuracy: 0.865234 / Validation Accuracy: 0.878\n",
      "Epoch: 4 / Batch: 20480/60000 / Cost: 0.0639862 / Training Accuracy: 0.873047 / Validation Accuracy: 0.884\n",
      "Epoch: 4 / Batch: 20992/60000 / Cost: 0.0615306 / Training Accuracy: 0.90625 / Validation Accuracy: 0.879\n",
      "Epoch: 4 / Batch: 21504/60000 / Cost: 0.0510414 / Training Accuracy: 0.919922 / Validation Accuracy: 0.883\n",
      "Epoch: 4 / Batch: 22016/60000 / Cost: 0.0853315 / Training Accuracy: 0.841797 / Validation Accuracy: 0.839\n",
      "Epoch: 4 / Batch: 22528/60000 / Cost: 0.0578967 / Training Accuracy: 0.900391 / Validation Accuracy: 0.887\n",
      "Epoch: 4 / Batch: 23040/60000 / Cost: 0.0556286 / Training Accuracy: 0.910156 / Validation Accuracy: 0.853\n",
      "Epoch: 4 / Batch: 23552/60000 / Cost: 0.0562039 / Training Accuracy: 0.914063 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 24064/60000 / Cost: 0.0669339 / Training Accuracy: 0.892578 / Validation Accuracy: 0.872\n",
      "Epoch: 4 / Batch: 24576/60000 / Cost: 0.0615013 / Training Accuracy: 0.900391 / Validation Accuracy: 0.876\n",
      "Epoch: 4 / Batch: 25088/60000 / Cost: 0.0560297 / Training Accuracy: 0.894531 / Validation Accuracy: 0.894\n",
      "Epoch: 4 / Batch: 25600/60000 / Cost: 0.0578822 / Training Accuracy: 0.900391 / Validation Accuracy: 0.879\n",
      "Epoch: 4 / Batch: 26112/60000 / Cost: 0.0656534 / Training Accuracy: 0.888672 / Validation Accuracy: 0.864\n",
      "Epoch: 4 / Batch: 26624/60000 / Cost: 0.0644611 / Training Accuracy: 0.888672 / Validation Accuracy: 0.881\n",
      "Epoch: 4 / Batch: 27136/60000 / Cost: 0.0710223 / Training Accuracy: 0.886719 / Validation Accuracy: 0.886\n",
      "Epoch: 4 / Batch: 27648/60000 / Cost: 0.0592157 / Training Accuracy: 0.90625 / Validation Accuracy: 0.887\n",
      "Epoch: 4 / Batch: 28160/60000 / Cost: 0.0654512 / Training Accuracy: 0.900391 / Validation Accuracy: 0.891\n",
      "Epoch: 4 / Batch: 28672/60000 / Cost: 0.050624 / Training Accuracy: 0.931641 / Validation Accuracy: 0.891\n",
      "Epoch: 4 / Batch: 29184/60000 / Cost: 0.0707351 / Training Accuracy: 0.878906 / Validation Accuracy: 0.886\n",
      "Epoch: 4 / Batch: 29696/60000 / Cost: 0.0491282 / Training Accuracy: 0.925781 / Validation Accuracy: 0.891\n",
      "Epoch: 4 / Batch: 30208/60000 / Cost: 0.0566504 / Training Accuracy: 0.892578 / Validation Accuracy: 0.888\n",
      "Epoch: 4 / Batch: 30720/60000 / Cost: 0.0534755 / Training Accuracy: 0.908203 / Validation Accuracy: 0.892\n",
      "Epoch: 4 / Batch: 31232/60000 / Cost: 0.0496647 / Training Accuracy: 0.925781 / Validation Accuracy: 0.886\n",
      "Epoch: 4 / Batch: 31744/60000 / Cost: 0.0486939 / Training Accuracy: 0.919922 / Validation Accuracy: 0.895\n",
      "Epoch: 4 / Batch: 32256/60000 / Cost: 0.0505075 / Training Accuracy: 0.917969 / Validation Accuracy: 0.887\n",
      "Epoch: 4 / Batch: 32768/60000 / Cost: 0.0599978 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 33280/60000 / Cost: 0.057595 / Training Accuracy: 0.896484 / Validation Accuracy: 0.906\n",
      "Epoch: 4 / Batch: 33792/60000 / Cost: 0.0496331 / Training Accuracy: 0.925781 / Validation Accuracy: 0.898\n",
      "Epoch: 4 / Batch: 34304/60000 / Cost: 0.0500021 / Training Accuracy: 0.916016 / Validation Accuracy: 0.899\n",
      "Epoch: 4 / Batch: 34816/60000 / Cost: 0.0507564 / Training Accuracy: 0.916016 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 35328/60000 / Cost: 0.0525503 / Training Accuracy: 0.921875 / Validation Accuracy: 0.895\n",
      "Epoch: 4 / Batch: 35840/60000 / Cost: 0.0586813 / Training Accuracy: 0.914063 / Validation Accuracy: 0.897\n",
      "Epoch: 4 / Batch: 36352/60000 / Cost: 0.0566454 / Training Accuracy: 0.910156 / Validation Accuracy: 0.915\n",
      "Epoch: 4 / Batch: 36864/60000 / Cost: 0.0570768 / Training Accuracy: 0.900391 / Validation Accuracy: 0.907\n",
      "Epoch: 4 / Batch: 37376/60000 / Cost: 0.0559254 / Training Accuracy: 0.900391 / Validation Accuracy: 0.892\n",
      "Epoch: 4 / Batch: 37888/60000 / Cost: 0.0508112 / Training Accuracy: 0.910156 / Validation Accuracy: 0.901\n",
      "Epoch: 4 / Batch: 38400/60000 / Cost: 0.0593914 / Training Accuracy: 0.892578 / Validation Accuracy: 0.894\n",
      "Epoch: 4 / Batch: 38912/60000 / Cost: 0.0584761 / Training Accuracy: 0.908203 / Validation Accuracy: 0.91\n",
      "Epoch: 4 / Batch: 39424/60000 / Cost: 0.0566211 / Training Accuracy: 0.910156 / Validation Accuracy: 0.908\n",
      "Epoch: 4 / Batch: 39936/60000 / Cost: 0.0546272 / Training Accuracy: 0.904297 / Validation Accuracy: 0.902\n",
      "Epoch: 4 / Batch: 40448/60000 / Cost: 0.0599971 / Training Accuracy: 0.902344 / Validation Accuracy: 0.908\n",
      "Epoch: 4 / Batch: 40960/60000 / Cost: 0.0570957 / Training Accuracy: 0.908203 / Validation Accuracy: 0.91\n",
      "Epoch: 4 / Batch: 41472/60000 / Cost: 0.0483396 / Training Accuracy: 0.921875 / Validation Accuracy: 0.907\n",
      "Epoch: 4 / Batch: 41984/60000 / Cost: 0.0532 / Training Accuracy: 0.917969 / Validation Accuracy: 0.918\n",
      "Epoch: 4 / Batch: 42496/60000 / Cost: 0.0418782 / Training Accuracy: 0.933594 / Validation Accuracy: 0.918\n",
      "Epoch: 4 / Batch: 43008/60000 / Cost: 0.0493849 / Training Accuracy: 0.919922 / Validation Accuracy: 0.901\n",
      "Epoch: 4 / Batch: 43520/60000 / Cost: 0.0485362 / Training Accuracy: 0.90625 / Validation Accuracy: 0.911\n",
      "Epoch: 4 / Batch: 44032/60000 / Cost: 0.0528616 / Training Accuracy: 0.917969 / Validation Accuracy: 0.917\n",
      "Epoch: 4 / Batch: 44544/60000 / Cost: 0.0472742 / Training Accuracy: 0.916016 / Validation Accuracy: 0.899\n",
      "Epoch: 4 / Batch: 45056/60000 / Cost: 0.0489999 / Training Accuracy: 0.914063 / Validation Accuracy: 0.901\n",
      "Epoch: 4 / Batch: 45568/60000 / Cost: 0.0538229 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 4 / Batch: 46080/60000 / Cost: 0.0523695 / Training Accuracy: 0.900391 / Validation Accuracy: 0.912\n",
      "Epoch: 4 / Batch: 46592/60000 / Cost: 0.0415387 / Training Accuracy: 0.931641 / Validation Accuracy: 0.906\n",
      "Epoch: 4 / Batch: 47104/60000 / Cost: 0.0479084 / Training Accuracy: 0.914063 / Validation Accuracy: 0.909\n",
      "Epoch: 4 / Batch: 47616/60000 / Cost: 0.0495147 / Training Accuracy: 0.912109 / Validation Accuracy: 0.892\n",
      "Epoch: 4 / Batch: 48128/60000 / Cost: 0.0567142 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 48640/60000 / Cost: 0.0537763 / Training Accuracy: 0.923828 / Validation Accuracy: 0.911\n",
      "Epoch: 4 / Batch: 49152/60000 / Cost: 0.0547726 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 4 / Batch: 49664/60000 / Cost: 0.0507971 / Training Accuracy: 0.90625 / Validation Accuracy: 0.912\n",
      "Epoch: 4 / Batch: 50176/60000 / Cost: 0.0510235 / Training Accuracy: 0.923828 / Validation Accuracy: 0.915\n",
      "Epoch: 4 / Batch: 50688/60000 / Cost: 0.0527772 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 4 / Batch: 51200/60000 / Cost: 0.0464155 / Training Accuracy: 0.923828 / Validation Accuracy: 0.915\n",
      "Epoch: 4 / Batch: 51712/60000 / Cost: 0.0559957 / Training Accuracy: 0.902344 / Validation Accuracy: 0.915\n",
      "Epoch: 4 / Batch: 52224/60000 / Cost: 0.0502076 / Training Accuracy: 0.919922 / Validation Accuracy: 0.919\n",
      "Epoch: 4 / Batch: 52736/60000 / Cost: 0.051668 / Training Accuracy: 0.910156 / Validation Accuracy: 0.918\n",
      "Epoch: 4 / Batch: 53248/60000 / Cost: 0.0399731 / Training Accuracy: 0.935547 / Validation Accuracy: 0.908\n",
      "Epoch: 4 / Batch: 53760/60000 / Cost: 0.0418004 / Training Accuracy: 0.927734 / Validation Accuracy: 0.926\n",
      "Epoch: 4 / Batch: 54272/60000 / Cost: 0.0461172 / Training Accuracy: 0.919922 / Validation Accuracy: 0.92\n",
      "Epoch: 4 / Batch: 54784/60000 / Cost: 0.0449199 / Training Accuracy: 0.919922 / Validation Accuracy: 0.907\n",
      "Epoch: 4 / Batch: 55296/60000 / Cost: 0.0473635 / Training Accuracy: 0.917969 / Validation Accuracy: 0.928\n",
      "Epoch: 4 / Batch: 55808/60000 / Cost: 0.0432519 / Training Accuracy: 0.9375 / Validation Accuracy: 0.926\n",
      "Epoch: 4 / Batch: 56320/60000 / Cost: 0.0553057 / Training Accuracy: 0.886719 / Validation Accuracy: 0.913\n",
      "Epoch: 4 / Batch: 56832/60000 / Cost: 0.0386964 / Training Accuracy: 0.933594 / Validation Accuracy: 0.92\n",
      "Epoch: 4 / Batch: 57344/60000 / Cost: 0.036573 / Training Accuracy: 0.945313 / Validation Accuracy: 0.922\n",
      "Epoch: 4 / Batch: 57856/60000 / Cost: 0.0451139 / Training Accuracy: 0.939453 / Validation Accuracy: 0.902\n",
      "Epoch: 4 / Batch: 58368/60000 / Cost: 0.0461268 / Training Accuracy: 0.916016 / Validation Accuracy: 0.912\n",
      "Epoch: 4 / Batch: 58880/60000 / Cost: 0.0557696 / Training Accuracy: 0.896484 / Validation Accuracy: 0.924\n",
      "Epoch: 4 / Batch: 59392/60000 / Cost: 0.0474723 / Training Accuracy: 0.917969 / Validation Accuracy: 0.929\n",
      "Epoch: 4 / Batch: 59904/60000 / Cost: 0.0343067 / Training Accuracy: 0.947917 / Validation Accuracy: 0.908\n",
      "Epoch: 5 / Batch: 0/60000 / Cost: 0.0455686 / Training Accuracy: 0.923828 / Validation Accuracy: 0.911\n",
      "Epoch: 5 / Batch: 512/60000 / Cost: 0.0442585 / Training Accuracy: 0.923828 / Validation Accuracy: 0.918\n",
      "Epoch: 5 / Batch: 1024/60000 / Cost: 0.0506857 / Training Accuracy: 0.908203 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 1536/60000 / Cost: 0.0372419 / Training Accuracy: 0.927734 / Validation Accuracy: 0.902\n",
      "Epoch: 5 / Batch: 2048/60000 / Cost: 0.0405232 / Training Accuracy: 0.9375 / Validation Accuracy: 0.912\n",
      "Epoch: 5 / Batch: 2560/60000 / Cost: 0.0510238 / Training Accuracy: 0.916016 / Validation Accuracy: 0.925\n",
      "Epoch: 5 / Batch: 3072/60000 / Cost: 0.0413075 / Training Accuracy: 0.941406 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 3584/60000 / Cost: 0.0448061 / Training Accuracy: 0.931641 / Validation Accuracy: 0.917\n",
      "Epoch: 5 / Batch: 4096/60000 / Cost: 0.0415299 / Training Accuracy: 0.933594 / Validation Accuracy: 0.931\n",
      "Epoch: 5 / Batch: 4608/60000 / Cost: 0.0524327 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 5 / Batch: 5120/60000 / Cost: 0.0549604 / Training Accuracy: 0.916016 / Validation Accuracy: 0.919\n",
      "Epoch: 5 / Batch: 5632/60000 / Cost: 0.043919 / Training Accuracy: 0.925781 / Validation Accuracy: 0.922\n",
      "Epoch: 5 / Batch: 6144/60000 / Cost: 0.0459474 / Training Accuracy: 0.916016 / Validation Accuracy: 0.936\n",
      "Epoch: 5 / Batch: 6656/60000 / Cost: 0.0377071 / Training Accuracy: 0.9375 / Validation Accuracy: 0.938\n",
      "Epoch: 5 / Batch: 7168/60000 / Cost: 0.050345 / Training Accuracy: 0.919922 / Validation Accuracy: 0.93\n",
      "Epoch: 5 / Batch: 7680/60000 / Cost: 0.0386854 / Training Accuracy: 0.941406 / Validation Accuracy: 0.934\n",
      "Epoch: 5 / Batch: 8192/60000 / Cost: 0.0405312 / Training Accuracy: 0.929688 / Validation Accuracy: 0.942\n",
      "Epoch: 5 / Batch: 8704/60000 / Cost: 0.0402351 / Training Accuracy: 0.933594 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 9216/60000 / Cost: 0.0273379 / Training Accuracy: 0.962891 / Validation Accuracy: 0.937\n",
      "Epoch: 5 / Batch: 9728/60000 / Cost: 0.0395983 / Training Accuracy: 0.945313 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 10240/60000 / Cost: 0.0369871 / Training Accuracy: 0.941406 / Validation Accuracy: 0.947\n",
      "Epoch: 5 / Batch: 10752/60000 / Cost: 0.0401299 / Training Accuracy: 0.933594 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 11264/60000 / Cost: 0.0405342 / Training Accuracy: 0.941406 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 11776/60000 / Cost: 0.0343812 / Training Accuracy: 0.943359 / Validation Accuracy: 0.942\n",
      "Epoch: 5 / Batch: 12288/60000 / Cost: 0.0371231 / Training Accuracy: 0.939453 / Validation Accuracy: 0.948\n",
      "Epoch: 5 / Batch: 12800/60000 / Cost: 0.0386628 / Training Accuracy: 0.945313 / Validation Accuracy: 0.94\n",
      "Epoch: 5 / Batch: 13312/60000 / Cost: 0.0420455 / Training Accuracy: 0.933594 / Validation Accuracy: 0.94\n",
      "Epoch: 5 / Batch: 13824/60000 / Cost: 0.037041 / Training Accuracy: 0.939453 / Validation Accuracy: 0.935\n",
      "Epoch: 5 / Batch: 14336/60000 / Cost: 0.0429355 / Training Accuracy: 0.941406 / Validation Accuracy: 0.922\n",
      "Epoch: 5 / Batch: 14848/60000 / Cost: 0.041862 / Training Accuracy: 0.941406 / Validation Accuracy: 0.946\n",
      "Epoch: 5 / Batch: 15360/60000 / Cost: 0.0369055 / Training Accuracy: 0.941406 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 15872/60000 / Cost: 0.0428373 / Training Accuracy: 0.929688 / Validation Accuracy: 0.934\n",
      "Epoch: 5 / Batch: 16384/60000 / Cost: 0.0539404 / Training Accuracy: 0.908203 / Validation Accuracy: 0.933\n",
      "Epoch: 5 / Batch: 16896/60000 / Cost: 0.0382089 / Training Accuracy: 0.933594 / Validation Accuracy: 0.942\n",
      "Epoch: 5 / Batch: 17408/60000 / Cost: 0.0383945 / Training Accuracy: 0.9375 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 17920/60000 / Cost: 0.0369441 / Training Accuracy: 0.945313 / Validation Accuracy: 0.937\n",
      "Epoch: 5 / Batch: 18432/60000 / Cost: 0.035193 / Training Accuracy: 0.947266 / Validation Accuracy: 0.935\n",
      "Epoch: 5 / Batch: 18944/60000 / Cost: 0.0434436 / Training Accuracy: 0.929688 / Validation Accuracy: 0.937\n",
      "Epoch: 5 / Batch: 19456/60000 / Cost: 0.041364 / Training Accuracy: 0.9375 / Validation Accuracy: 0.946\n",
      "Epoch: 5 / Batch: 19968/60000 / Cost: 0.0341345 / Training Accuracy: 0.955078 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 20480/60000 / Cost: 0.0314532 / Training Accuracy: 0.945313 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 20992/60000 / Cost: 0.0358167 / Training Accuracy: 0.935547 / Validation Accuracy: 0.943\n",
      "Epoch: 5 / Batch: 21504/60000 / Cost: 0.0382908 / Training Accuracy: 0.929688 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 22016/60000 / Cost: 0.0333489 / Training Accuracy: 0.947266 / Validation Accuracy: 0.947\n",
      "Epoch: 5 / Batch: 22528/60000 / Cost: 0.0331588 / Training Accuracy: 0.9375 / Validation Accuracy: 0.942\n",
      "Epoch: 5 / Batch: 23040/60000 / Cost: 0.0388666 / Training Accuracy: 0.939453 / Validation Accuracy: 0.934\n",
      "Epoch: 5 / Batch: 23552/60000 / Cost: 0.0364768 / Training Accuracy: 0.949219 / Validation Accuracy: 0.936\n",
      "Epoch: 5 / Batch: 24064/60000 / Cost: 0.040956 / Training Accuracy: 0.931641 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 24576/60000 / Cost: 0.0390286 / Training Accuracy: 0.941406 / Validation Accuracy: 0.936\n",
      "Epoch: 5 / Batch: 25088/60000 / Cost: 0.0335107 / Training Accuracy: 0.955078 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 25600/60000 / Cost: 0.0377526 / Training Accuracy: 0.935547 / Validation Accuracy: 0.953\n",
      "Epoch: 5 / Batch: 26112/60000 / Cost: 0.034884 / Training Accuracy: 0.949219 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 26624/60000 / Cost: 0.0338239 / Training Accuracy: 0.949219 / Validation Accuracy: 0.948\n",
      "Epoch: 5 / Batch: 27136/60000 / Cost: 0.0387965 / Training Accuracy: 0.941406 / Validation Accuracy: 0.955\n",
      "Epoch: 5 / Batch: 27648/60000 / Cost: 0.0306935 / Training Accuracy: 0.949219 / Validation Accuracy: 0.953\n",
      "Epoch: 5 / Batch: 28160/60000 / Cost: 0.0300958 / Training Accuracy: 0.957031 / Validation Accuracy: 0.949\n",
      "Epoch: 5 / Batch: 28672/60000 / Cost: 0.0465225 / Training Accuracy: 0.923828 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 29184/60000 / Cost: 0.0406212 / Training Accuracy: 0.9375 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 29696/60000 / Cost: 0.0395258 / Training Accuracy: 0.931641 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 30208/60000 / Cost: 0.0407107 / Training Accuracy: 0.9375 / Validation Accuracy: 0.946\n",
      "Epoch: 5 / Batch: 30720/60000 / Cost: 0.0360215 / Training Accuracy: 0.931641 / Validation Accuracy: 0.938\n",
      "Epoch: 5 / Batch: 31232/60000 / Cost: 0.0395459 / Training Accuracy: 0.923828 / Validation Accuracy: 0.949\n",
      "Epoch: 5 / Batch: 31744/60000 / Cost: 0.0290078 / Training Accuracy: 0.953125 / Validation Accuracy: 0.937\n",
      "Epoch: 5 / Batch: 32256/60000 / Cost: 0.039452 / Training Accuracy: 0.933594 / Validation Accuracy: 0.927\n",
      "Epoch: 5 / Batch: 32768/60000 / Cost: 0.0349152 / Training Accuracy: 0.943359 / Validation Accuracy: 0.94\n",
      "Epoch: 5 / Batch: 33280/60000 / Cost: 0.0343164 / Training Accuracy: 0.947266 / Validation Accuracy: 0.944\n",
      "Epoch: 5 / Batch: 33792/60000 / Cost: 0.0361436 / Training Accuracy: 0.941406 / Validation Accuracy: 0.943\n",
      "Epoch: 5 / Batch: 34304/60000 / Cost: 0.0324133 / Training Accuracy: 0.957031 / Validation Accuracy: 0.949\n",
      "Epoch: 5 / Batch: 34816/60000 / Cost: 0.034162 / Training Accuracy: 0.951172 / Validation Accuracy: 0.94\n",
      "Epoch: 5 / Batch: 35328/60000 / Cost: 0.0403962 / Training Accuracy: 0.933594 / Validation Accuracy: 0.949\n",
      "Epoch: 5 / Batch: 35840/60000 / Cost: 0.0300656 / Training Accuracy: 0.957031 / Validation Accuracy: 0.949\n",
      "Epoch: 5 / Batch: 36352/60000 / Cost: 0.0463822 / Training Accuracy: 0.921875 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 36864/60000 / Cost: 0.0274995 / Training Accuracy: 0.960938 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 37376/60000 / Cost: 0.0282057 / Training Accuracy: 0.955078 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 37888/60000 / Cost: 0.0265896 / Training Accuracy: 0.966797 / Validation Accuracy: 0.952\n",
      "Epoch: 5 / Batch: 38400/60000 / Cost: 0.0450104 / Training Accuracy: 0.935547 / Validation Accuracy: 0.95\n",
      "Epoch: 5 / Batch: 38912/60000 / Cost: 0.0318261 / Training Accuracy: 0.949219 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 39424/60000 / Cost: 0.0376814 / Training Accuracy: 0.951172 / Validation Accuracy: 0.954\n",
      "Epoch: 5 / Batch: 39936/60000 / Cost: 0.0308375 / Training Accuracy: 0.951172 / Validation Accuracy: 0.953\n",
      "Epoch: 5 / Batch: 40448/60000 / Cost: 0.0286631 / Training Accuracy: 0.955078 / Validation Accuracy: 0.937\n",
      "Epoch: 5 / Batch: 40960/60000 / Cost: 0.034743 / Training Accuracy: 0.935547 / Validation Accuracy: 0.933\n",
      "Epoch: 5 / Batch: 41472/60000 / Cost: 0.028162 / Training Accuracy: 0.960938 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 41984/60000 / Cost: 0.0321255 / Training Accuracy: 0.941406 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 42496/60000 / Cost: 0.0296459 / Training Accuracy: 0.953125 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 43008/60000 / Cost: 0.0316726 / Training Accuracy: 0.947266 / Validation Accuracy: 0.95\n",
      "Epoch: 5 / Batch: 43520/60000 / Cost: 0.0343355 / Training Accuracy: 0.947266 / Validation Accuracy: 0.947\n",
      "Epoch: 5 / Batch: 44032/60000 / Cost: 0.0322272 / Training Accuracy: 0.947266 / Validation Accuracy: 0.946\n",
      "Epoch: 5 / Batch: 44544/60000 / Cost: 0.0341741 / Training Accuracy: 0.945313 / Validation Accuracy: 0.945\n",
      "Epoch: 5 / Batch: 45056/60000 / Cost: 0.0319362 / Training Accuracy: 0.955078 / Validation Accuracy: 0.942\n",
      "Epoch: 5 / Batch: 45568/60000 / Cost: 0.0306134 / Training Accuracy: 0.945313 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 46080/60000 / Cost: 0.040359 / Training Accuracy: 0.925781 / Validation Accuracy: 0.933\n",
      "Epoch: 5 / Batch: 46592/60000 / Cost: 0.0476072 / Training Accuracy: 0.929688 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 47104/60000 / Cost: 0.0284281 / Training Accuracy: 0.957031 / Validation Accuracy: 0.93\n",
      "Epoch: 5 / Batch: 47616/60000 / Cost: 0.0293157 / Training Accuracy: 0.953125 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 48128/60000 / Cost: 0.0278699 / Training Accuracy: 0.955078 / Validation Accuracy: 0.935\n",
      "Epoch: 5 / Batch: 48640/60000 / Cost: 0.038074 / Training Accuracy: 0.935547 / Validation Accuracy: 0.939\n",
      "Epoch: 5 / Batch: 49152/60000 / Cost: 0.0383049 / Training Accuracy: 0.949219 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 49664/60000 / Cost: 0.0269922 / Training Accuracy: 0.955078 / Validation Accuracy: 0.942\n",
      "Epoch: 5 / Batch: 50176/60000 / Cost: 0.040871 / Training Accuracy: 0.929688 / Validation Accuracy: 0.943\n",
      "Epoch: 5 / Batch: 50688/60000 / Cost: 0.0417856 / Training Accuracy: 0.929688 / Validation Accuracy: 0.943\n",
      "Epoch: 5 / Batch: 51200/60000 / Cost: 0.0379717 / Training Accuracy: 0.939453 / Validation Accuracy: 0.944\n",
      "Epoch: 5 / Batch: 51712/60000 / Cost: 0.0391013 / Training Accuracy: 0.943359 / Validation Accuracy: 0.947\n",
      "Epoch: 5 / Batch: 52224/60000 / Cost: 0.0385554 / Training Accuracy: 0.927734 / Validation Accuracy: 0.95\n",
      "Epoch: 5 / Batch: 52736/60000 / Cost: 0.0403719 / Training Accuracy: 0.935547 / Validation Accuracy: 0.952\n",
      "Epoch: 5 / Batch: 53248/60000 / Cost: 0.0358238 / Training Accuracy: 0.941406 / Validation Accuracy: 0.941\n",
      "Epoch: 5 / Batch: 53760/60000 / Cost: 0.0350231 / Training Accuracy: 0.945313 / Validation Accuracy: 0.949\n",
      "Epoch: 5 / Batch: 54272/60000 / Cost: 0.0317883 / Training Accuracy: 0.957031 / Validation Accuracy: 0.956\n",
      "Epoch: 5 / Batch: 54784/60000 / Cost: 0.0282539 / Training Accuracy: 0.951172 / Validation Accuracy: 0.953\n",
      "Epoch: 5 / Batch: 55296/60000 / Cost: 0.0310956 / Training Accuracy: 0.945313 / Validation Accuracy: 0.952\n",
      "Epoch: 5 / Batch: 55808/60000 / Cost: 0.0385641 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 5 / Batch: 56320/60000 / Cost: 0.0303804 / Training Accuracy: 0.941406 / Validation Accuracy: 0.961\n",
      "Epoch: 5 / Batch: 56832/60000 / Cost: 0.0342518 / Training Accuracy: 0.943359 / Validation Accuracy: 0.959\n",
      "Epoch: 5 / Batch: 57344/60000 / Cost: 0.0283991 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 5 / Batch: 57856/60000 / Cost: 0.0256668 / Training Accuracy: 0.957031 / Validation Accuracy: 0.953\n",
      "Epoch: 5 / Batch: 58368/60000 / Cost: 0.034515 / Training Accuracy: 0.943359 / Validation Accuracy: 0.956\n",
      "Epoch: 5 / Batch: 58880/60000 / Cost: 0.023845 / Training Accuracy: 0.960938 / Validation Accuracy: 0.951\n",
      "Epoch: 5 / Batch: 59392/60000 / Cost: 0.028176 / Training Accuracy: 0.958984 / Validation Accuracy: 0.952\n",
      "Epoch: 5 / Batch: 59904/60000 / Cost: 0.0493437 / Training Accuracy: 0.947917 / Validation Accuracy: 0.945\n",
      "Epoch: 6 / Batch: 0/60000 / Cost: 0.0294242 / Training Accuracy: 0.953125 / Validation Accuracy: 0.931\n",
      "Epoch: 6 / Batch: 512/60000 / Cost: 0.0413292 / Training Accuracy: 0.927734 / Validation Accuracy: 0.945\n",
      "Epoch: 6 / Batch: 1024/60000 / Cost: 0.0262225 / Training Accuracy: 0.960938 / Validation Accuracy: 0.942\n",
      "Epoch: 6 / Batch: 1536/60000 / Cost: 0.0329293 / Training Accuracy: 0.953125 / Validation Accuracy: 0.939\n",
      "Epoch: 6 / Batch: 2048/60000 / Cost: 0.0272111 / Training Accuracy: 0.960938 / Validation Accuracy: 0.944\n",
      "Epoch: 6 / Batch: 2560/60000 / Cost: 0.0325982 / Training Accuracy: 0.951172 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 3072/60000 / Cost: 0.0280467 / Training Accuracy: 0.953125 / Validation Accuracy: 0.947\n",
      "Epoch: 6 / Batch: 3584/60000 / Cost: 0.0295373 / Training Accuracy: 0.949219 / Validation Accuracy: 0.948\n",
      "Epoch: 6 / Batch: 4096/60000 / Cost: 0.034666 / Training Accuracy: 0.943359 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 4608/60000 / Cost: 0.0315629 / Training Accuracy: 0.945313 / Validation Accuracy: 0.958\n",
      "Epoch: 6 / Batch: 5120/60000 / Cost: 0.0325974 / Training Accuracy: 0.939453 / Validation Accuracy: 0.941\n",
      "Epoch: 6 / Batch: 5632/60000 / Cost: 0.0297676 / Training Accuracy: 0.943359 / Validation Accuracy: 0.935\n",
      "Epoch: 6 / Batch: 6144/60000 / Cost: 0.0262711 / Training Accuracy: 0.953125 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 6656/60000 / Cost: 0.0325277 / Training Accuracy: 0.955078 / Validation Accuracy: 0.952\n",
      "Epoch: 6 / Batch: 7168/60000 / Cost: 0.0226315 / Training Accuracy: 0.960938 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 7680/60000 / Cost: 0.0272578 / Training Accuracy: 0.958984 / Validation Accuracy: 0.942\n",
      "Epoch: 6 / Batch: 8192/60000 / Cost: 0.0268207 / Training Accuracy: 0.955078 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 8704/60000 / Cost: 0.0281792 / Training Accuracy: 0.955078 / Validation Accuracy: 0.947\n",
      "Epoch: 6 / Batch: 9216/60000 / Cost: 0.0336946 / Training Accuracy: 0.945313 / Validation Accuracy: 0.938\n",
      "Epoch: 6 / Batch: 9728/60000 / Cost: 0.0308909 / Training Accuracy: 0.949219 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 10240/60000 / Cost: 0.0291309 / Training Accuracy: 0.955078 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 10752/60000 / Cost: 0.0337569 / Training Accuracy: 0.951172 / Validation Accuracy: 0.94\n",
      "Epoch: 6 / Batch: 11264/60000 / Cost: 0.0306094 / Training Accuracy: 0.960938 / Validation Accuracy: 0.944\n",
      "Epoch: 6 / Batch: 11776/60000 / Cost: 0.0340966 / Training Accuracy: 0.947266 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 12288/60000 / Cost: 0.0275852 / Training Accuracy: 0.958984 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 12800/60000 / Cost: 0.0268645 / Training Accuracy: 0.957031 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 13312/60000 / Cost: 0.0212397 / Training Accuracy: 0.972656 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 13824/60000 / Cost: 0.0395383 / Training Accuracy: 0.939453 / Validation Accuracy: 0.951\n",
      "Epoch: 6 / Batch: 14336/60000 / Cost: 0.0247243 / Training Accuracy: 0.962891 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 14848/60000 / Cost: 0.0301824 / Training Accuracy: 0.958984 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 15360/60000 / Cost: 0.0256555 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 15872/60000 / Cost: 0.0295762 / Training Accuracy: 0.951172 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 16384/60000 / Cost: 0.039631 / Training Accuracy: 0.931641 / Validation Accuracy: 0.952\n",
      "Epoch: 6 / Batch: 16896/60000 / Cost: 0.0289027 / Training Accuracy: 0.953125 / Validation Accuracy: 0.948\n",
      "Epoch: 6 / Batch: 17408/60000 / Cost: 0.0282816 / Training Accuracy: 0.957031 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 17920/60000 / Cost: 0.0267382 / Training Accuracy: 0.962891 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 18432/60000 / Cost: 0.0346402 / Training Accuracy: 0.941406 / Validation Accuracy: 0.942\n",
      "Epoch: 6 / Batch: 18944/60000 / Cost: 0.0395351 / Training Accuracy: 0.941406 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 19456/60000 / Cost: 0.0282645 / Training Accuracy: 0.949219 / Validation Accuracy: 0.959\n",
      "Epoch: 6 / Batch: 19968/60000 / Cost: 0.0398708 / Training Accuracy: 0.935547 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 20480/60000 / Cost: 0.0324594 / Training Accuracy: 0.955078 / Validation Accuracy: 0.951\n",
      "Epoch: 6 / Batch: 20992/60000 / Cost: 0.0217402 / Training Accuracy: 0.96875 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 21504/60000 / Cost: 0.0259866 / Training Accuracy: 0.960938 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 22016/60000 / Cost: 0.0339879 / Training Accuracy: 0.935547 / Validation Accuracy: 0.947\n",
      "Epoch: 6 / Batch: 22528/60000 / Cost: 0.0273024 / Training Accuracy: 0.960938 / Validation Accuracy: 0.948\n",
      "Epoch: 6 / Batch: 23040/60000 / Cost: 0.032615 / Training Accuracy: 0.947266 / Validation Accuracy: 0.944\n",
      "Epoch: 6 / Batch: 23552/60000 / Cost: 0.0299028 / Training Accuracy: 0.945313 / Validation Accuracy: 0.947\n",
      "Epoch: 6 / Batch: 24064/60000 / Cost: 0.0336238 / Training Accuracy: 0.943359 / Validation Accuracy: 0.937\n",
      "Epoch: 6 / Batch: 24576/60000 / Cost: 0.02809 / Training Accuracy: 0.957031 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 25088/60000 / Cost: 0.0268137 / Training Accuracy: 0.955078 / Validation Accuracy: 0.961\n",
      "Epoch: 6 / Batch: 25600/60000 / Cost: 0.0310106 / Training Accuracy: 0.951172 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 26112/60000 / Cost: 0.0333133 / Training Accuracy: 0.943359 / Validation Accuracy: 0.961\n",
      "Epoch: 6 / Batch: 26624/60000 / Cost: 0.0304443 / Training Accuracy: 0.955078 / Validation Accuracy: 0.958\n",
      "Epoch: 6 / Batch: 27136/60000 / Cost: 0.031834 / Training Accuracy: 0.951172 / Validation Accuracy: 0.952\n",
      "Epoch: 6 / Batch: 27648/60000 / Cost: 0.0286895 / Training Accuracy: 0.953125 / Validation Accuracy: 0.941\n",
      "Epoch: 6 / Batch: 28160/60000 / Cost: 0.0297221 / Training Accuracy: 0.955078 / Validation Accuracy: 0.951\n",
      "Epoch: 6 / Batch: 28672/60000 / Cost: 0.0214759 / Training Accuracy: 0.964844 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 29184/60000 / Cost: 0.0338782 / Training Accuracy: 0.943359 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 29696/60000 / Cost: 0.0257432 / Training Accuracy: 0.962891 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 30208/60000 / Cost: 0.0330637 / Training Accuracy: 0.945313 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 30720/60000 / Cost: 0.0265892 / Training Accuracy: 0.962891 / Validation Accuracy: 0.959\n",
      "Epoch: 6 / Batch: 31232/60000 / Cost: 0.0298056 / Training Accuracy: 0.951172 / Validation Accuracy: 0.951\n",
      "Epoch: 6 / Batch: 31744/60000 / Cost: 0.02897 / Training Accuracy: 0.943359 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 32256/60000 / Cost: 0.0251889 / Training Accuracy: 0.966797 / Validation Accuracy: 0.951\n",
      "Epoch: 6 / Batch: 32768/60000 / Cost: 0.0372209 / Training Accuracy: 0.933594 / Validation Accuracy: 0.945\n",
      "Epoch: 6 / Batch: 33280/60000 / Cost: 0.0321349 / Training Accuracy: 0.949219 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 33792/60000 / Cost: 0.0236414 / Training Accuracy: 0.960938 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 34304/60000 / Cost: 0.0318897 / Training Accuracy: 0.945313 / Validation Accuracy: 0.936\n",
      "Epoch: 6 / Batch: 34816/60000 / Cost: 0.0269461 / Training Accuracy: 0.955078 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 35328/60000 / Cost: 0.0319169 / Training Accuracy: 0.947266 / Validation Accuracy: 0.948\n",
      "Epoch: 6 / Batch: 35840/60000 / Cost: 0.0300953 / Training Accuracy: 0.951172 / Validation Accuracy: 0.937\n",
      "Epoch: 6 / Batch: 36352/60000 / Cost: 0.0295663 / Training Accuracy: 0.957031 / Validation Accuracy: 0.936\n",
      "Epoch: 6 / Batch: 36864/60000 / Cost: 0.0237528 / Training Accuracy: 0.966797 / Validation Accuracy: 0.951\n",
      "Epoch: 6 / Batch: 37376/60000 / Cost: 0.0289583 / Training Accuracy: 0.953125 / Validation Accuracy: 0.945\n",
      "Epoch: 6 / Batch: 37888/60000 / Cost: 0.0353368 / Training Accuracy: 0.933594 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 38400/60000 / Cost: 0.0277846 / Training Accuracy: 0.962891 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 38912/60000 / Cost: 0.0272419 / Training Accuracy: 0.945313 / Validation Accuracy: 0.944\n",
      "Epoch: 6 / Batch: 39424/60000 / Cost: 0.0340201 / Training Accuracy: 0.943359 / Validation Accuracy: 0.947\n",
      "Epoch: 6 / Batch: 39936/60000 / Cost: 0.0219926 / Training Accuracy: 0.964844 / Validation Accuracy: 0.948\n",
      "Epoch: 6 / Batch: 40448/60000 / Cost: 0.0261848 / Training Accuracy: 0.962891 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 40960/60000 / Cost: 0.0298022 / Training Accuracy: 0.949219 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 41472/60000 / Cost: 0.0228631 / Training Accuracy: 0.957031 / Validation Accuracy: 0.939\n",
      "Epoch: 6 / Batch: 41984/60000 / Cost: 0.0326811 / Training Accuracy: 0.939453 / Validation Accuracy: 0.952\n",
      "Epoch: 6 / Batch: 42496/60000 / Cost: 0.0200861 / Training Accuracy: 0.972656 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 43008/60000 / Cost: 0.027881 / Training Accuracy: 0.958984 / Validation Accuracy: 0.948\n",
      "Epoch: 6 / Batch: 43520/60000 / Cost: 0.0252796 / Training Accuracy: 0.955078 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 44032/60000 / Cost: 0.0259498 / Training Accuracy: 0.951172 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 44544/60000 / Cost: 0.0327939 / Training Accuracy: 0.947266 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 45056/60000 / Cost: 0.0296799 / Training Accuracy: 0.951172 / Validation Accuracy: 0.946\n",
      "Epoch: 6 / Batch: 45568/60000 / Cost: 0.0212608 / Training Accuracy: 0.970703 / Validation Accuracy: 0.944\n",
      "Epoch: 6 / Batch: 46080/60000 / Cost: 0.0311324 / Training Accuracy: 0.951172 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 46592/60000 / Cost: 0.0282468 / Training Accuracy: 0.947266 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 47104/60000 / Cost: 0.0169364 / Training Accuracy: 0.980469 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 47616/60000 / Cost: 0.0244164 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 48128/60000 / Cost: 0.0307389 / Training Accuracy: 0.958984 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 48640/60000 / Cost: 0.0307565 / Training Accuracy: 0.951172 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 49152/60000 / Cost: 0.0223547 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 49664/60000 / Cost: 0.0238622 / Training Accuracy: 0.962891 / Validation Accuracy: 0.96\n",
      "Epoch: 6 / Batch: 50176/60000 / Cost: 0.0210735 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 50688/60000 / Cost: 0.0296986 / Training Accuracy: 0.955078 / Validation Accuracy: 0.96\n",
      "Epoch: 6 / Batch: 51200/60000 / Cost: 0.0296506 / Training Accuracy: 0.949219 / Validation Accuracy: 0.962\n",
      "Epoch: 6 / Batch: 51712/60000 / Cost: 0.0270636 / Training Accuracy: 0.955078 / Validation Accuracy: 0.959\n",
      "Epoch: 6 / Batch: 52224/60000 / Cost: 0.0294709 / Training Accuracy: 0.949219 / Validation Accuracy: 0.959\n",
      "Epoch: 6 / Batch: 52736/60000 / Cost: 0.0293027 / Training Accuracy: 0.947266 / Validation Accuracy: 0.959\n",
      "Epoch: 6 / Batch: 53248/60000 / Cost: 0.0205633 / Training Accuracy: 0.96875 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 53760/60000 / Cost: 0.0231221 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 6 / Batch: 54272/60000 / Cost: 0.0280958 / Training Accuracy: 0.947266 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 54784/60000 / Cost: 0.0267464 / Training Accuracy: 0.970703 / Validation Accuracy: 0.945\n",
      "Epoch: 6 / Batch: 55296/60000 / Cost: 0.023149 / Training Accuracy: 0.966797 / Validation Accuracy: 0.949\n",
      "Epoch: 6 / Batch: 55808/60000 / Cost: 0.0230327 / Training Accuracy: 0.964844 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 56320/60000 / Cost: 0.021171 / Training Accuracy: 0.96875 / Validation Accuracy: 0.95\n",
      "Epoch: 6 / Batch: 56832/60000 / Cost: 0.0316679 / Training Accuracy: 0.951172 / Validation Accuracy: 0.953\n",
      "Epoch: 6 / Batch: 57344/60000 / Cost: 0.0198535 / Training Accuracy: 0.96875 / Validation Accuracy: 0.954\n",
      "Epoch: 6 / Batch: 57856/60000 / Cost: 0.0269073 / Training Accuracy: 0.949219 / Validation Accuracy: 0.956\n",
      "Epoch: 6 / Batch: 58368/60000 / Cost: 0.024152 / Training Accuracy: 0.964844 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 58880/60000 / Cost: 0.0357409 / Training Accuracy: 0.941406 / Validation Accuracy: 0.955\n",
      "Epoch: 6 / Batch: 59392/60000 / Cost: 0.0290144 / Training Accuracy: 0.951172 / Validation Accuracy: 0.958\n",
      "Epoch: 6 / Batch: 59904/60000 / Cost: 0.0336882 / Training Accuracy: 0.947917 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 0/60000 / Cost: 0.0232511 / Training Accuracy: 0.970703 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 512/60000 / Cost: 0.0280211 / Training Accuracy: 0.958984 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 1024/60000 / Cost: 0.021676 / Training Accuracy: 0.970703 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 1536/60000 / Cost: 0.025532 / Training Accuracy: 0.958984 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 2048/60000 / Cost: 0.02675 / Training Accuracy: 0.966797 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 2560/60000 / Cost: 0.0278 / Training Accuracy: 0.951172 / Validation Accuracy: 0.953\n",
      "Epoch: 7 / Batch: 3072/60000 / Cost: 0.0247521 / Training Accuracy: 0.964844 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 3584/60000 / Cost: 0.0235975 / Training Accuracy: 0.96875 / Validation Accuracy: 0.948\n",
      "Epoch: 7 / Batch: 4096/60000 / Cost: 0.0251967 / Training Accuracy: 0.960938 / Validation Accuracy: 0.942\n",
      "Epoch: 7 / Batch: 4608/60000 / Cost: 0.0274672 / Training Accuracy: 0.951172 / Validation Accuracy: 0.946\n",
      "Epoch: 7 / Batch: 5120/60000 / Cost: 0.0260936 / Training Accuracy: 0.96875 / Validation Accuracy: 0.95\n",
      "Epoch: 7 / Batch: 5632/60000 / Cost: 0.0148189 / Training Accuracy: 0.982422 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 6144/60000 / Cost: 0.019886 / Training Accuracy: 0.972656 / Validation Accuracy: 0.95\n",
      "Epoch: 7 / Batch: 6656/60000 / Cost: 0.0252278 / Training Accuracy: 0.953125 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 7168/60000 / Cost: 0.0283472 / Training Accuracy: 0.953125 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 7680/60000 / Cost: 0.0255768 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 8192/60000 / Cost: 0.0255213 / Training Accuracy: 0.953125 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 8704/60000 / Cost: 0.0198681 / Training Accuracy: 0.972656 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 9216/60000 / Cost: 0.022353 / Training Accuracy: 0.962891 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 9728/60000 / Cost: 0.0244091 / Training Accuracy: 0.960938 / Validation Accuracy: 0.95\n",
      "Epoch: 7 / Batch: 10240/60000 / Cost: 0.02781 / Training Accuracy: 0.958984 / Validation Accuracy: 0.943\n",
      "Epoch: 7 / Batch: 10752/60000 / Cost: 0.0259952 / Training Accuracy: 0.960938 / Validation Accuracy: 0.95\n",
      "Epoch: 7 / Batch: 11264/60000 / Cost: 0.0223028 / Training Accuracy: 0.966797 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 11776/60000 / Cost: 0.023437 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 12288/60000 / Cost: 0.0307645 / Training Accuracy: 0.958984 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 12800/60000 / Cost: 0.0254521 / Training Accuracy: 0.955078 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 13312/60000 / Cost: 0.0222977 / Training Accuracy: 0.960938 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 13824/60000 / Cost: 0.0282733 / Training Accuracy: 0.957031 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 14336/60000 / Cost: 0.0208904 / Training Accuracy: 0.966797 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 14848/60000 / Cost: 0.0238718 / Training Accuracy: 0.964844 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 15360/60000 / Cost: 0.0234984 / Training Accuracy: 0.957031 / Validation Accuracy: 0.95\n",
      "Epoch: 7 / Batch: 15872/60000 / Cost: 0.0199097 / Training Accuracy: 0.966797 / Validation Accuracy: 0.954\n",
      "Epoch: 7 / Batch: 16384/60000 / Cost: 0.0223697 / Training Accuracy: 0.962891 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 16896/60000 / Cost: 0.0211386 / Training Accuracy: 0.960938 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 17408/60000 / Cost: 0.0220401 / Training Accuracy: 0.962891 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 17920/60000 / Cost: 0.0210873 / Training Accuracy: 0.962891 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 18432/60000 / Cost: 0.0295429 / Training Accuracy: 0.957031 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 18944/60000 / Cost: 0.0239389 / Training Accuracy: 0.958984 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 19456/60000 / Cost: 0.0189076 / Training Accuracy: 0.96875 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 19968/60000 / Cost: 0.0204231 / Training Accuracy: 0.962891 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 20480/60000 / Cost: 0.022388 / Training Accuracy: 0.966797 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 20992/60000 / Cost: 0.0236586 / Training Accuracy: 0.970703 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 21504/60000 / Cost: 0.0193972 / Training Accuracy: 0.96875 / Validation Accuracy: 0.953\n",
      "Epoch: 7 / Batch: 22016/60000 / Cost: 0.022046 / Training Accuracy: 0.958984 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 22528/60000 / Cost: 0.0215987 / Training Accuracy: 0.960938 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 23040/60000 / Cost: 0.0227685 / Training Accuracy: 0.957031 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 23552/60000 / Cost: 0.0254203 / Training Accuracy: 0.951172 / Validation Accuracy: 0.953\n",
      "Epoch: 7 / Batch: 24064/60000 / Cost: 0.0274867 / Training Accuracy: 0.958984 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 24576/60000 / Cost: 0.0177097 / Training Accuracy: 0.970703 / Validation Accuracy: 0.964\n",
      "Epoch: 7 / Batch: 25088/60000 / Cost: 0.0170147 / Training Accuracy: 0.974609 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 25600/60000 / Cost: 0.026894 / Training Accuracy: 0.957031 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 26112/60000 / Cost: 0.0217538 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 26624/60000 / Cost: 0.0202305 / Training Accuracy: 0.974609 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 27136/60000 / Cost: 0.0167085 / Training Accuracy: 0.96875 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 27648/60000 / Cost: 0.0220207 / Training Accuracy: 0.958984 / Validation Accuracy: 0.954\n",
      "Epoch: 7 / Batch: 28160/60000 / Cost: 0.0163053 / Training Accuracy: 0.984375 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 28672/60000 / Cost: 0.0243071 / Training Accuracy: 0.958984 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 29184/60000 / Cost: 0.0264513 / Training Accuracy: 0.962891 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 29696/60000 / Cost: 0.0233279 / Training Accuracy: 0.964844 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 30208/60000 / Cost: 0.0242624 / Training Accuracy: 0.957031 / Validation Accuracy: 0.964\n",
      "Epoch: 7 / Batch: 30720/60000 / Cost: 0.0257587 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 31232/60000 / Cost: 0.0277654 / Training Accuracy: 0.960938 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 31744/60000 / Cost: 0.0298239 / Training Accuracy: 0.945313 / Validation Accuracy: 0.963\n",
      "Epoch: 7 / Batch: 32256/60000 / Cost: 0.0246785 / Training Accuracy: 0.953125 / Validation Accuracy: 0.965\n",
      "Epoch: 7 / Batch: 32768/60000 / Cost: 0.0305053 / Training Accuracy: 0.955078 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 33280/60000 / Cost: 0.023995 / Training Accuracy: 0.964844 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 33792/60000 / Cost: 0.0252049 / Training Accuracy: 0.957031 / Validation Accuracy: 0.949\n",
      "Epoch: 7 / Batch: 34304/60000 / Cost: 0.02638 / Training Accuracy: 0.955078 / Validation Accuracy: 0.946\n",
      "Epoch: 7 / Batch: 34816/60000 / Cost: 0.0197677 / Training Accuracy: 0.972656 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 35328/60000 / Cost: 0.0248982 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 35840/60000 / Cost: 0.0237745 / Training Accuracy: 0.958984 / Validation Accuracy: 0.963\n",
      "Epoch: 7 / Batch: 36352/60000 / Cost: 0.0291194 / Training Accuracy: 0.943359 / Validation Accuracy: 0.937\n",
      "Epoch: 7 / Batch: 36864/60000 / Cost: 0.0297532 / Training Accuracy: 0.955078 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 37376/60000 / Cost: 0.0234447 / Training Accuracy: 0.970703 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 37888/60000 / Cost: 0.02246 / Training Accuracy: 0.962891 / Validation Accuracy: 0.955\n",
      "Epoch: 7 / Batch: 38400/60000 / Cost: 0.0293831 / Training Accuracy: 0.960938 / Validation Accuracy: 0.948\n",
      "Epoch: 7 / Batch: 38912/60000 / Cost: 0.0230237 / Training Accuracy: 0.964844 / Validation Accuracy: 0.95\n",
      "Epoch: 7 / Batch: 39424/60000 / Cost: 0.0317076 / Training Accuracy: 0.947266 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 39936/60000 / Cost: 0.0330693 / Training Accuracy: 0.943359 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 40448/60000 / Cost: 0.0182873 / Training Accuracy: 0.972656 / Validation Accuracy: 0.954\n",
      "Epoch: 7 / Batch: 40960/60000 / Cost: 0.0252446 / Training Accuracy: 0.955078 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 41472/60000 / Cost: 0.0245001 / Training Accuracy: 0.958984 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 41984/60000 / Cost: 0.0173733 / Training Accuracy: 0.972656 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 42496/60000 / Cost: 0.0261673 / Training Accuracy: 0.955078 / Validation Accuracy: 0.947\n",
      "Epoch: 7 / Batch: 43008/60000 / Cost: 0.0263795 / Training Accuracy: 0.957031 / Validation Accuracy: 0.952\n",
      "Epoch: 7 / Batch: 43520/60000 / Cost: 0.0269703 / Training Accuracy: 0.951172 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 44032/60000 / Cost: 0.0267595 / Training Accuracy: 0.951172 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 44544/60000 / Cost: 0.0259285 / Training Accuracy: 0.955078 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 45056/60000 / Cost: 0.0223648 / Training Accuracy: 0.960938 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 45568/60000 / Cost: 0.0271652 / Training Accuracy: 0.953125 / Validation Accuracy: 0.954\n",
      "Epoch: 7 / Batch: 46080/60000 / Cost: 0.0298316 / Training Accuracy: 0.953125 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 46592/60000 / Cost: 0.0215146 / Training Accuracy: 0.962891 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 47104/60000 / Cost: 0.0220098 / Training Accuracy: 0.962891 / Validation Accuracy: 0.949\n",
      "Epoch: 7 / Batch: 47616/60000 / Cost: 0.0269362 / Training Accuracy: 0.958984 / Validation Accuracy: 0.951\n",
      "Epoch: 7 / Batch: 48128/60000 / Cost: 0.0243921 / Training Accuracy: 0.955078 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 48640/60000 / Cost: 0.0252895 / Training Accuracy: 0.957031 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 49152/60000 / Cost: 0.0246565 / Training Accuracy: 0.955078 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 49664/60000 / Cost: 0.0207512 / Training Accuracy: 0.972656 / Validation Accuracy: 0.957\n",
      "Epoch: 7 / Batch: 50176/60000 / Cost: 0.0236236 / Training Accuracy: 0.957031 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 50688/60000 / Cost: 0.0292636 / Training Accuracy: 0.951172 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 51200/60000 / Cost: 0.0234684 / Training Accuracy: 0.960938 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 51712/60000 / Cost: 0.0240777 / Training Accuracy: 0.964844 / Validation Accuracy: 0.964\n",
      "Epoch: 7 / Batch: 52224/60000 / Cost: 0.0231868 / Training Accuracy: 0.957031 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 52736/60000 / Cost: 0.0205635 / Training Accuracy: 0.976563 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 53248/60000 / Cost: 0.0251981 / Training Accuracy: 0.957031 / Validation Accuracy: 0.958\n",
      "Epoch: 7 / Batch: 53760/60000 / Cost: 0.0249669 / Training Accuracy: 0.960938 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 54272/60000 / Cost: 0.0270747 / Training Accuracy: 0.955078 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 54784/60000 / Cost: 0.014988 / Training Accuracy: 0.974609 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 55296/60000 / Cost: 0.0266844 / Training Accuracy: 0.957031 / Validation Accuracy: 0.963\n",
      "Epoch: 7 / Batch: 55808/60000 / Cost: 0.0164189 / Training Accuracy: 0.976563 / Validation Accuracy: 0.963\n",
      "Epoch: 7 / Batch: 56320/60000 / Cost: 0.0290958 / Training Accuracy: 0.953125 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 56832/60000 / Cost: 0.0299997 / Training Accuracy: 0.955078 / Validation Accuracy: 0.961\n",
      "Epoch: 7 / Batch: 57344/60000 / Cost: 0.0214391 / Training Accuracy: 0.960938 / Validation Accuracy: 0.963\n",
      "Epoch: 7 / Batch: 57856/60000 / Cost: 0.0213909 / Training Accuracy: 0.964844 / Validation Accuracy: 0.962\n",
      "Epoch: 7 / Batch: 58368/60000 / Cost: 0.0283583 / Training Accuracy: 0.951172 / Validation Accuracy: 0.956\n",
      "Epoch: 7 / Batch: 58880/60000 / Cost: 0.0244521 / Training Accuracy: 0.958984 / Validation Accuracy: 0.959\n",
      "Epoch: 7 / Batch: 59392/60000 / Cost: 0.0159637 / Training Accuracy: 0.96875 / Validation Accuracy: 0.96\n",
      "Epoch: 7 / Batch: 59904/60000 / Cost: 0.00967945 / Training Accuracy: 1.0 / Validation Accuracy: 0.957\n",
      "Epoch: 8 / Batch: 0/60000 / Cost: 0.0226739 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 8 / Batch: 512/60000 / Cost: 0.0179485 / Training Accuracy: 0.964844 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 1024/60000 / Cost: 0.0201233 / Training Accuracy: 0.964844 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 1536/60000 / Cost: 0.0244757 / Training Accuracy: 0.966797 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 2048/60000 / Cost: 0.0219248 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 8 / Batch: 2560/60000 / Cost: 0.0214216 / Training Accuracy: 0.966797 / Validation Accuracy: 0.955\n",
      "Epoch: 8 / Batch: 3072/60000 / Cost: 0.0237914 / Training Accuracy: 0.958984 / Validation Accuracy: 0.956\n",
      "Epoch: 8 / Batch: 3584/60000 / Cost: 0.0247516 / Training Accuracy: 0.958984 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 4096/60000 / Cost: 0.0183013 / Training Accuracy: 0.974609 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 4608/60000 / Cost: 0.022175 / Training Accuracy: 0.96875 / Validation Accuracy: 0.955\n",
      "Epoch: 8 / Batch: 5120/60000 / Cost: 0.0193856 / Training Accuracy: 0.966797 / Validation Accuracy: 0.949\n",
      "Epoch: 8 / Batch: 5632/60000 / Cost: 0.0249399 / Training Accuracy: 0.947266 / Validation Accuracy: 0.954\n",
      "Epoch: 8 / Batch: 6144/60000 / Cost: 0.0150425 / Training Accuracy: 0.978516 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 6656/60000 / Cost: 0.0222638 / Training Accuracy: 0.960938 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 7168/60000 / Cost: 0.0249399 / Training Accuracy: 0.972656 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 7680/60000 / Cost: 0.020863 / Training Accuracy: 0.972656 / Validation Accuracy: 0.958\n",
      "Epoch: 8 / Batch: 8192/60000 / Cost: 0.0201457 / Training Accuracy: 0.966797 / Validation Accuracy: 0.956\n",
      "Epoch: 8 / Batch: 8704/60000 / Cost: 0.0186535 / Training Accuracy: 0.96875 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 9216/60000 / Cost: 0.0251824 / Training Accuracy: 0.960938 / Validation Accuracy: 0.964\n",
      "Epoch: 8 / Batch: 9728/60000 / Cost: 0.0187587 / Training Accuracy: 0.978516 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 10240/60000 / Cost: 0.0167958 / Training Accuracy: 0.972656 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 10752/60000 / Cost: 0.0189887 / Training Accuracy: 0.970703 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 11264/60000 / Cost: 0.0260217 / Training Accuracy: 0.951172 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 11776/60000 / Cost: 0.0221773 / Training Accuracy: 0.962891 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 12288/60000 / Cost: 0.0166021 / Training Accuracy: 0.976563 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 12800/60000 / Cost: 0.0217168 / Training Accuracy: 0.958984 / Validation Accuracy: 0.958\n",
      "Epoch: 8 / Batch: 13312/60000 / Cost: 0.0186162 / Training Accuracy: 0.976563 / Validation Accuracy: 0.952\n",
      "Epoch: 8 / Batch: 13824/60000 / Cost: 0.0213624 / Training Accuracy: 0.972656 / Validation Accuracy: 0.956\n",
      "Epoch: 8 / Batch: 14336/60000 / Cost: 0.0181881 / Training Accuracy: 0.972656 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 14848/60000 / Cost: 0.0214243 / Training Accuracy: 0.958984 / Validation Accuracy: 0.969\n",
      "Epoch: 8 / Batch: 15360/60000 / Cost: 0.017604 / Training Accuracy: 0.972656 / Validation Accuracy: 0.97\n",
      "Epoch: 8 / Batch: 15872/60000 / Cost: 0.0201281 / Training Accuracy: 0.976563 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 16384/60000 / Cost: 0.0206256 / Training Accuracy: 0.966797 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 16896/60000 / Cost: 0.0306573 / Training Accuracy: 0.945313 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 17408/60000 / Cost: 0.0160277 / Training Accuracy: 0.982422 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 17920/60000 / Cost: 0.0132114 / Training Accuracy: 0.972656 / Validation Accuracy: 0.968\n",
      "Epoch: 8 / Batch: 18432/60000 / Cost: 0.0125344 / Training Accuracy: 0.982422 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 18944/60000 / Cost: 0.0225054 / Training Accuracy: 0.960938 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 19456/60000 / Cost: 0.0136614 / Training Accuracy: 0.982422 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 19968/60000 / Cost: 0.0223861 / Training Accuracy: 0.96875 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 20480/60000 / Cost: 0.015086 / Training Accuracy: 0.978516 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 20992/60000 / Cost: 0.0220493 / Training Accuracy: 0.964844 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 21504/60000 / Cost: 0.0183771 / Training Accuracy: 0.970703 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 22016/60000 / Cost: 0.0192148 / Training Accuracy: 0.970703 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 22528/60000 / Cost: 0.017134 / Training Accuracy: 0.96875 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 23040/60000 / Cost: 0.020035 / Training Accuracy: 0.962891 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 23552/60000 / Cost: 0.0185264 / Training Accuracy: 0.970703 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 24064/60000 / Cost: 0.0179242 / Training Accuracy: 0.970703 / Validation Accuracy: 0.966\n",
      "Epoch: 8 / Batch: 24576/60000 / Cost: 0.0204365 / Training Accuracy: 0.966797 / Validation Accuracy: 0.964\n",
      "Epoch: 8 / Batch: 25088/60000 / Cost: 0.016157 / Training Accuracy: 0.974609 / Validation Accuracy: 0.956\n",
      "Epoch: 8 / Batch: 25600/60000 / Cost: 0.0154899 / Training Accuracy: 0.976563 / Validation Accuracy: 0.954\n",
      "Epoch: 8 / Batch: 26112/60000 / Cost: 0.0165057 / Training Accuracy: 0.976563 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 26624/60000 / Cost: 0.0154791 / Training Accuracy: 0.980469 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 27136/60000 / Cost: 0.0206926 / Training Accuracy: 0.966797 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 27648/60000 / Cost: 0.0167483 / Training Accuracy: 0.964844 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 28160/60000 / Cost: 0.0298393 / Training Accuracy: 0.947266 / Validation Accuracy: 0.957\n",
      "Epoch: 8 / Batch: 28672/60000 / Cost: 0.0194122 / Training Accuracy: 0.964844 / Validation Accuracy: 0.956\n",
      "Epoch: 8 / Batch: 29184/60000 / Cost: 0.0197515 / Training Accuracy: 0.964844 / Validation Accuracy: 0.958\n",
      "Epoch: 8 / Batch: 29696/60000 / Cost: 0.0206054 / Training Accuracy: 0.964844 / Validation Accuracy: 0.954\n",
      "Epoch: 8 / Batch: 30208/60000 / Cost: 0.0257309 / Training Accuracy: 0.957031 / Validation Accuracy: 0.955\n",
      "Epoch: 8 / Batch: 30720/60000 / Cost: 0.0235622 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 8 / Batch: 31232/60000 / Cost: 0.0178752 / Training Accuracy: 0.974609 / Validation Accuracy: 0.958\n",
      "Epoch: 8 / Batch: 31744/60000 / Cost: 0.0149061 / Training Accuracy: 0.96875 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 32256/60000 / Cost: 0.0179907 / Training Accuracy: 0.976563 / Validation Accuracy: 0.961\n",
      "Epoch: 8 / Batch: 32768/60000 / Cost: 0.0238223 / Training Accuracy: 0.96875 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 33280/60000 / Cost: 0.0169134 / Training Accuracy: 0.964844 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 33792/60000 / Cost: 0.0218346 / Training Accuracy: 0.964844 / Validation Accuracy: 0.958\n",
      "Epoch: 8 / Batch: 34304/60000 / Cost: 0.0164445 / Training Accuracy: 0.974609 / Validation Accuracy: 0.955\n",
      "Epoch: 8 / Batch: 34816/60000 / Cost: 0.0130162 / Training Accuracy: 0.976563 / Validation Accuracy: 0.954\n",
      "Epoch: 8 / Batch: 35328/60000 / Cost: 0.0199013 / Training Accuracy: 0.966797 / Validation Accuracy: 0.953\n",
      "Epoch: 8 / Batch: 35840/60000 / Cost: 0.015289 / Training Accuracy: 0.974609 / Validation Accuracy: 0.956\n",
      "Epoch: 8 / Batch: 36352/60000 / Cost: 0.014424 / Training Accuracy: 0.982422 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 36864/60000 / Cost: 0.0155995 / Training Accuracy: 0.978516 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 37376/60000 / Cost: 0.0168442 / Training Accuracy: 0.96875 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 37888/60000 / Cost: 0.0162285 / Training Accuracy: 0.978516 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 38400/60000 / Cost: 0.0172071 / Training Accuracy: 0.976563 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 38912/60000 / Cost: 0.0217326 / Training Accuracy: 0.970703 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 39424/60000 / Cost: 0.0214973 / Training Accuracy: 0.964844 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 39936/60000 / Cost: 0.0209964 / Training Accuracy: 0.96875 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 40448/60000 / Cost: 0.0157081 / Training Accuracy: 0.984375 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 40960/60000 / Cost: 0.0129232 / Training Accuracy: 0.976563 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 41472/60000 / Cost: 0.0173602 / Training Accuracy: 0.974609 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 41984/60000 / Cost: 0.0186935 / Training Accuracy: 0.966797 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 42496/60000 / Cost: 0.0204832 / Training Accuracy: 0.960938 / Validation Accuracy: 0.964\n",
      "Epoch: 8 / Batch: 43008/60000 / Cost: 0.0181495 / Training Accuracy: 0.970703 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 43520/60000 / Cost: 0.0262963 / Training Accuracy: 0.957031 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 44032/60000 / Cost: 0.018826 / Training Accuracy: 0.974609 / Validation Accuracy: 0.968\n",
      "Epoch: 8 / Batch: 44544/60000 / Cost: 0.0165978 / Training Accuracy: 0.974609 / Validation Accuracy: 0.97\n",
      "Epoch: 8 / Batch: 45056/60000 / Cost: 0.0152685 / Training Accuracy: 0.976563 / Validation Accuracy: 0.969\n",
      "Epoch: 8 / Batch: 45568/60000 / Cost: 0.0150425 / Training Accuracy: 0.976563 / Validation Accuracy: 0.966\n",
      "Epoch: 8 / Batch: 46080/60000 / Cost: 0.0172484 / Training Accuracy: 0.96875 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 46592/60000 / Cost: 0.0230473 / Training Accuracy: 0.962891 / Validation Accuracy: 0.957\n",
      "Epoch: 8 / Batch: 47104/60000 / Cost: 0.0158164 / Training Accuracy: 0.980469 / Validation Accuracy: 0.958\n",
      "Epoch: 8 / Batch: 47616/60000 / Cost: 0.0131865 / Training Accuracy: 0.986328 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 48128/60000 / Cost: 0.0143952 / Training Accuracy: 0.978516 / Validation Accuracy: 0.969\n",
      "Epoch: 8 / Batch: 48640/60000 / Cost: 0.0294327 / Training Accuracy: 0.951172 / Validation Accuracy: 0.963\n",
      "Epoch: 8 / Batch: 49152/60000 / Cost: 0.023831 / Training Accuracy: 0.964844 / Validation Accuracy: 0.966\n",
      "Epoch: 8 / Batch: 49664/60000 / Cost: 0.0204619 / Training Accuracy: 0.962891 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 50176/60000 / Cost: 0.0197553 / Training Accuracy: 0.974609 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 50688/60000 / Cost: 0.019983 / Training Accuracy: 0.970703 / Validation Accuracy: 0.959\n",
      "Epoch: 8 / Batch: 51200/60000 / Cost: 0.0271133 / Training Accuracy: 0.962891 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 51712/60000 / Cost: 0.0227278 / Training Accuracy: 0.962891 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 52224/60000 / Cost: 0.0225002 / Training Accuracy: 0.957031 / Validation Accuracy: 0.964\n",
      "Epoch: 8 / Batch: 52736/60000 / Cost: 0.0219446 / Training Accuracy: 0.966797 / Validation Accuracy: 0.966\n",
      "Epoch: 8 / Batch: 53248/60000 / Cost: 0.0154929 / Training Accuracy: 0.976563 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 53760/60000 / Cost: 0.0166195 / Training Accuracy: 0.972656 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 54272/60000 / Cost: 0.0110991 / Training Accuracy: 0.984375 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 54784/60000 / Cost: 0.0158719 / Training Accuracy: 0.970703 / Validation Accuracy: 0.965\n",
      "Epoch: 8 / Batch: 55296/60000 / Cost: 0.0193855 / Training Accuracy: 0.964844 / Validation Accuracy: 0.968\n",
      "Epoch: 8 / Batch: 55808/60000 / Cost: 0.0199603 / Training Accuracy: 0.972656 / Validation Accuracy: 0.968\n",
      "Epoch: 8 / Batch: 56320/60000 / Cost: 0.0157986 / Training Accuracy: 0.980469 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 56832/60000 / Cost: 0.0134018 / Training Accuracy: 0.980469 / Validation Accuracy: 0.966\n",
      "Epoch: 8 / Batch: 57344/60000 / Cost: 0.0161236 / Training Accuracy: 0.962891 / Validation Accuracy: 0.968\n",
      "Epoch: 8 / Batch: 57856/60000 / Cost: 0.0194581 / Training Accuracy: 0.966797 / Validation Accuracy: 0.969\n",
      "Epoch: 8 / Batch: 58368/60000 / Cost: 0.0163133 / Training Accuracy: 0.974609 / Validation Accuracy: 0.967\n",
      "Epoch: 8 / Batch: 58880/60000 / Cost: 0.0246043 / Training Accuracy: 0.960938 / Validation Accuracy: 0.962\n",
      "Epoch: 8 / Batch: 59392/60000 / Cost: 0.0145247 / Training Accuracy: 0.982422 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 59904/60000 / Cost: 0.0149475 / Training Accuracy: 0.979167 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 0/60000 / Cost: 0.0188943 / Training Accuracy: 0.978516 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 512/60000 / Cost: 0.0209539 / Training Accuracy: 0.962891 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 1024/60000 / Cost: 0.0126903 / Training Accuracy: 0.980469 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 1536/60000 / Cost: 0.0136311 / Training Accuracy: 0.980469 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 2048/60000 / Cost: 0.0193111 / Training Accuracy: 0.964844 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 2560/60000 / Cost: 0.0247125 / Training Accuracy: 0.957031 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 3072/60000 / Cost: 0.0110613 / Training Accuracy: 0.984375 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 3584/60000 / Cost: 0.0152937 / Training Accuracy: 0.976563 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 4096/60000 / Cost: 0.0171858 / Training Accuracy: 0.974609 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 4608/60000 / Cost: 0.0158076 / Training Accuracy: 0.96875 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 5120/60000 / Cost: 0.0157926 / Training Accuracy: 0.96875 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 5632/60000 / Cost: 0.0167672 / Training Accuracy: 0.970703 / Validation Accuracy: 0.97\n",
      "Epoch: 9 / Batch: 6144/60000 / Cost: 0.0161833 / Training Accuracy: 0.976563 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 6656/60000 / Cost: 0.0157416 / Training Accuracy: 0.96875 / Validation Accuracy: 0.954\n",
      "Epoch: 9 / Batch: 7168/60000 / Cost: 0.0237945 / Training Accuracy: 0.958984 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 7680/60000 / Cost: 0.0175065 / Training Accuracy: 0.970703 / Validation Accuracy: 0.956\n",
      "Epoch: 9 / Batch: 8192/60000 / Cost: 0.0225479 / Training Accuracy: 0.960938 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 8704/60000 / Cost: 0.0120907 / Training Accuracy: 0.978516 / Validation Accuracy: 0.959\n",
      "Epoch: 9 / Batch: 9216/60000 / Cost: 0.0202059 / Training Accuracy: 0.962891 / Validation Accuracy: 0.949\n",
      "Epoch: 9 / Batch: 9728/60000 / Cost: 0.0176827 / Training Accuracy: 0.966797 / Validation Accuracy: 0.958\n",
      "Epoch: 9 / Batch: 10240/60000 / Cost: 0.0194896 / Training Accuracy: 0.96875 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 10752/60000 / Cost: 0.0230742 / Training Accuracy: 0.96875 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 11264/60000 / Cost: 0.0194386 / Training Accuracy: 0.962891 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 11776/60000 / Cost: 0.0210084 / Training Accuracy: 0.962891 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 12288/60000 / Cost: 0.0142103 / Training Accuracy: 0.980469 / Validation Accuracy: 0.959\n",
      "Epoch: 9 / Batch: 12800/60000 / Cost: 0.0194144 / Training Accuracy: 0.970703 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 13312/60000 / Cost: 0.013602 / Training Accuracy: 0.984375 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 13824/60000 / Cost: 0.0128724 / Training Accuracy: 0.982422 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 14336/60000 / Cost: 0.0141197 / Training Accuracy: 0.980469 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 14848/60000 / Cost: 0.0117039 / Training Accuracy: 0.974609 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 15360/60000 / Cost: 0.0173402 / Training Accuracy: 0.970703 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 15872/60000 / Cost: 0.0210778 / Training Accuracy: 0.970703 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 16384/60000 / Cost: 0.0195249 / Training Accuracy: 0.96875 / Validation Accuracy: 0.959\n",
      "Epoch: 9 / Batch: 16896/60000 / Cost: 0.0169967 / Training Accuracy: 0.970703 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 17408/60000 / Cost: 0.0270403 / Training Accuracy: 0.945313 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 17920/60000 / Cost: 0.020855 / Training Accuracy: 0.958984 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 18432/60000 / Cost: 0.020064 / Training Accuracy: 0.964844 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 18944/60000 / Cost: 0.0165399 / Training Accuracy: 0.980469 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 19456/60000 / Cost: 0.0209494 / Training Accuracy: 0.966797 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 19968/60000 / Cost: 0.0227617 / Training Accuracy: 0.964844 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 20480/60000 / Cost: 0.0176586 / Training Accuracy: 0.970703 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 20992/60000 / Cost: 0.0170883 / Training Accuracy: 0.980469 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 21504/60000 / Cost: 0.0184348 / Training Accuracy: 0.96875 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 22016/60000 / Cost: 0.0124579 / Training Accuracy: 0.976563 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 22528/60000 / Cost: 0.025125 / Training Accuracy: 0.960938 / Validation Accuracy: 0.961\n",
      "Epoch: 9 / Batch: 23040/60000 / Cost: 0.0157906 / Training Accuracy: 0.982422 / Validation Accuracy: 0.958\n",
      "Epoch: 9 / Batch: 23552/60000 / Cost: 0.0198136 / Training Accuracy: 0.970703 / Validation Accuracy: 0.959\n",
      "Epoch: 9 / Batch: 24064/60000 / Cost: 0.0129755 / Training Accuracy: 0.980469 / Validation Accuracy: 0.961\n",
      "Epoch: 9 / Batch: 24576/60000 / Cost: 0.0152418 / Training Accuracy: 0.974609 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 25088/60000 / Cost: 0.0131915 / Training Accuracy: 0.984375 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 25600/60000 / Cost: 0.0195331 / Training Accuracy: 0.972656 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 26112/60000 / Cost: 0.0171338 / Training Accuracy: 0.976563 / Validation Accuracy: 0.97\n",
      "Epoch: 9 / Batch: 26624/60000 / Cost: 0.0162391 / Training Accuracy: 0.970703 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 27136/60000 / Cost: 0.0128666 / Training Accuracy: 0.980469 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 27648/60000 / Cost: 0.0187494 / Training Accuracy: 0.972656 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 28160/60000 / Cost: 0.00967301 / Training Accuracy: 0.988281 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 28672/60000 / Cost: 0.0162504 / Training Accuracy: 0.972656 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 29184/60000 / Cost: 0.014378 / Training Accuracy: 0.982422 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 29696/60000 / Cost: 0.0144619 / Training Accuracy: 0.980469 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 30208/60000 / Cost: 0.0180615 / Training Accuracy: 0.966797 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 30720/60000 / Cost: 0.0253377 / Training Accuracy: 0.960938 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 31232/60000 / Cost: 0.0119131 / Training Accuracy: 0.972656 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 31744/60000 / Cost: 0.0170045 / Training Accuracy: 0.974609 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 32256/60000 / Cost: 0.0215755 / Training Accuracy: 0.974609 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 32768/60000 / Cost: 0.0183071 / Training Accuracy: 0.970703 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 33280/60000 / Cost: 0.0230687 / Training Accuracy: 0.962891 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 33792/60000 / Cost: 0.0172079 / Training Accuracy: 0.980469 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 34304/60000 / Cost: 0.0134303 / Training Accuracy: 0.976563 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 34816/60000 / Cost: 0.0115265 / Training Accuracy: 0.986328 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 35328/60000 / Cost: 0.0157433 / Training Accuracy: 0.974609 / Validation Accuracy: 0.964\n",
      "Epoch: 9 / Batch: 35840/60000 / Cost: 0.0228742 / Training Accuracy: 0.960938 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 36352/60000 / Cost: 0.0174267 / Training Accuracy: 0.964844 / Validation Accuracy: 0.972\n",
      "Epoch: 9 / Batch: 36864/60000 / Cost: 0.0161768 / Training Accuracy: 0.96875 / Validation Accuracy: 0.971\n",
      "Epoch: 9 / Batch: 37376/60000 / Cost: 0.0138907 / Training Accuracy: 0.976563 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 37888/60000 / Cost: 0.0169278 / Training Accuracy: 0.978516 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 38400/60000 / Cost: 0.017452 / Training Accuracy: 0.970703 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 38912/60000 / Cost: 0.0225057 / Training Accuracy: 0.964844 / Validation Accuracy: 0.961\n",
      "Epoch: 9 / Batch: 39424/60000 / Cost: 0.019414 / Training Accuracy: 0.964844 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 39936/60000 / Cost: 0.0174644 / Training Accuracy: 0.980469 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 40448/60000 / Cost: 0.0144996 / Training Accuracy: 0.978516 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 40960/60000 / Cost: 0.0120299 / Training Accuracy: 0.980469 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 41472/60000 / Cost: 0.0153529 / Training Accuracy: 0.96875 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 41984/60000 / Cost: 0.0165707 / Training Accuracy: 0.970703 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 42496/60000 / Cost: 0.0148114 / Training Accuracy: 0.976563 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 43008/60000 / Cost: 0.0154053 / Training Accuracy: 0.982422 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 43520/60000 / Cost: 0.0146423 / Training Accuracy: 0.976563 / Validation Accuracy: 0.966\n",
      "Epoch: 9 / Batch: 44032/60000 / Cost: 0.0177414 / Training Accuracy: 0.972656 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 44544/60000 / Cost: 0.016554 / Training Accuracy: 0.976563 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 45056/60000 / Cost: 0.0152786 / Training Accuracy: 0.978516 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 45568/60000 / Cost: 0.0119827 / Training Accuracy: 0.978516 / Validation Accuracy: 0.961\n",
      "Epoch: 9 / Batch: 46080/60000 / Cost: 0.0139525 / Training Accuracy: 0.988281 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 46592/60000 / Cost: 0.0176325 / Training Accuracy: 0.972656 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 47104/60000 / Cost: 0.0139401 / Training Accuracy: 0.978516 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 47616/60000 / Cost: 0.0141229 / Training Accuracy: 0.976563 / Validation Accuracy: 0.962\n",
      "Epoch: 9 / Batch: 48128/60000 / Cost: 0.0206598 / Training Accuracy: 0.972656 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 48640/60000 / Cost: 0.017628 / Training Accuracy: 0.970703 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 49152/60000 / Cost: 0.0262864 / Training Accuracy: 0.949219 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 49664/60000 / Cost: 0.0201422 / Training Accuracy: 0.958984 / Validation Accuracy: 0.965\n",
      "Epoch: 9 / Batch: 50176/60000 / Cost: 0.020693 / Training Accuracy: 0.970703 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 50688/60000 / Cost: 0.0148257 / Training Accuracy: 0.970703 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 51200/60000 / Cost: 0.0202176 / Training Accuracy: 0.964844 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 51712/60000 / Cost: 0.0172286 / Training Accuracy: 0.974609 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 52224/60000 / Cost: 0.016805 / Training Accuracy: 0.972656 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 52736/60000 / Cost: 0.0148468 / Training Accuracy: 0.976563 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 53248/60000 / Cost: 0.0213105 / Training Accuracy: 0.972656 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 53760/60000 / Cost: 0.0235949 / Training Accuracy: 0.962891 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 54272/60000 / Cost: 0.0216283 / Training Accuracy: 0.960938 / Validation Accuracy: 0.957\n",
      "Epoch: 9 / Batch: 54784/60000 / Cost: 0.0210123 / Training Accuracy: 0.962891 / Validation Accuracy: 0.961\n",
      "Epoch: 9 / Batch: 55296/60000 / Cost: 0.0184629 / Training Accuracy: 0.966797 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 55808/60000 / Cost: 0.0174289 / Training Accuracy: 0.972656 / Validation Accuracy: 0.973\n",
      "Epoch: 9 / Batch: 56320/60000 / Cost: 0.017055 / Training Accuracy: 0.960938 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 56832/60000 / Cost: 0.017521 / Training Accuracy: 0.974609 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 57344/60000 / Cost: 0.0170001 / Training Accuracy: 0.976563 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 57856/60000 / Cost: 0.0189382 / Training Accuracy: 0.970703 / Validation Accuracy: 0.968\n",
      "Epoch: 9 / Batch: 58368/60000 / Cost: 0.0112097 / Training Accuracy: 0.988281 / Validation Accuracy: 0.969\n",
      "Epoch: 9 / Batch: 58880/60000 / Cost: 0.0153321 / Training Accuracy: 0.964844 / Validation Accuracy: 0.967\n",
      "Epoch: 9 / Batch: 59392/60000 / Cost: 0.0174419 / Training Accuracy: 0.976563 / Validation Accuracy: 0.963\n",
      "Epoch: 9 / Batch: 59904/60000 / Cost: 0.0139916 / Training Accuracy: 0.989583 / Validation Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Create Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "data = np.insert(train_x, img_flat_size, train_y, axis = 1)\n",
    "len_data = data.shape[0]\n",
    "\n",
    "# Training\n",
    "for i in range(num_epoch):\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    data_x = data[:, :img_flat_size]\n",
    "    data_y = data[:, img_flat_size]\n",
    "\n",
    "    data_y_onehot = np.zeros([data_y.shape[0], num_label])\n",
    "    for j in range(data_y.shape[0]):\n",
    "        data_y_onehot[j, int(data_y[j])] = 1\n",
    "    \n",
    "    data_y_onehot_val = np.zeros([validation_y.shape[0], num_label])\n",
    "    for j in range(validation_y.shape[0]):\n",
    "        data_y_onehot_val[j, int(validation_y[j])] = 1\n",
    "        \n",
    "    batch_count = 1\n",
    "    for j in range(0, len_data, batch_size):\n",
    "        if j + batch_size < len_data:\n",
    "            data_x_in = data_x[j : j + batch_size, :]\n",
    "            data_y_in = data_y_onehot[j : j + batch_size, :]\n",
    "        else:\n",
    "            data_x_in = data_x[j : len_data, :]\n",
    "            data_y_in = data_y_onehot[j : len_data, :]\n",
    "\n",
    "        optimizer.run(feed_dict = {x_image: data_x_in, y_target: data_y_in})\n",
    "        cost = sess.run(Cost, feed_dict = {x_image: data_x_in, y_target: data_y_in})\n",
    "        acc = sess.run(accuracy, feed_dict = {x_image: data_x_in, y_target: data_y_in})\n",
    "        val_acc = sess.run(accuracy, feed_dict = {x_image: validation_x, y_target: data_y_onehot_val})\n",
    "        \n",
    "        print(\"Epoch: \" + str(i+1) + ' / ' + \"Batch: \" + str(j) + '/' + str(len_data) + ' / ' + \"Cost: \" + str(cost) + ' / ' + \\\n",
    "              \"Training Accuracy: \" + str(acc) + ' / ' + \"Validation Accuracy: \" + str(val_acc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9675555555555555\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_y_onehot = np.zeros([test_y.shape[0], num_label])\n",
    "for i in range(test_y.shape[0]):\n",
    "    test_y_onehot[i, int(test_y[i])] = 1\n",
    "\n",
    "test_result = sess.run(output, feed_dict = {x_image: test_x})\n",
    "\n",
    "count_correct = 0\n",
    "for i in range(test_result.shape[0]):\n",
    "    prediction_y = np.argmax(test_result[i,:])\n",
    "    \n",
    "    if prediction_y == test_y[i]:\n",
    "        count_correct += 1\n",
    "\n",
    "test_acc = count_correct / test_result.shape[0]\n",
    "\n",
    "print(\"Test Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
